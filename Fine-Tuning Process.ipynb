{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11662247,"sourceType":"datasetVersion","datasetId":7318913}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:27:57.878039Z","iopub.execute_input":"2025-05-17T23:27:57.878704Z","iopub.status.idle":"2025-05-17T23:27:58.161107Z","shell.execute_reply.started":"2025-05-17T23:27:57.878670Z","shell.execute_reply":"2025-05-17T23:27:58.160386Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 1. Installing dependencies and libraries","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:28:43.979224Z","iopub.execute_input":"2025-05-17T23:28:43.980038Z","iopub.status.idle":"2025-05-17T23:28:49.579917Z","shell.execute_reply.started":"2025-05-17T23:28:43.980013Z","shell.execute_reply":"2025-05-17T23:28:49.579272Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install \\\n    datasets \\\n    evaluate \\\n    rouge_score\\\n    loralib \\\n    evaluate \\\n    accelerate \\\n    bitsandbytes \\\n    trl \\\n    peft \\\n    -U --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:29:14.611902Z","iopub.execute_input":"2025-05-17T23:29:14.612217Z","iopub.status.idle":"2025-05-17T23:30:25.537643Z","shell.execute_reply.started":"2025-05-17T23:29:14.612187Z","shell.execute_reply":"2025-05-17T23:30:25.536610Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [bitsandbytes][0m [bitsandbytes]er-cu12]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 2. Loading the first Dataset of Arabic SQuADv2.0","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\n\n# Load dataset\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:30:42.226389Z","iopub.execute_input":"2025-05-17T23:30:42.226687Z","iopub.status.idle":"2025-05-17T23:30:50.137775Z","shell.execute_reply.started":"2025-05-17T23:30:42.226661Z","shell.execute_reply":"2025-05-17T23:30:50.137230Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"013cb355ca43483e816f55478a21d791"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2020dd9c88fc4aabbbf253095c196749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85876de1e3014b23bafdd6552d7a17cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16e37749385494483d356f3eb93a8b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98e9dda752c846789f4335e6f2894ba0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e7bae0ffaea4231b98c7fbbe1e364d5"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# 3. Extracting the exemples from the nested structure of the dataset","metadata":{}},{"cell_type":"code","source":"def format_squad_dataset(dataset_split):\n    \"\"\"\n    Format a SQuAD-style dataset split into a list of dictionaries \n    with context, questions, and answers.\n\n    Args:\n        dataset_split: a split of the SQuAD-style dataset, e.g., ds[\"train\"] or ds[\"validation\"]\n\n    Returns:\\\n    \n        A list of formatted entries: [{\"context\": ..., \"questions\": [...]}]\n    \"\"\"\n    formatted = []\n\n    for article in dataset_split:\n        for paragraph in article[\"data\"]:\n            for p in paragraph[\"paragraphs\"]:\n                context = p[\"context\"]\n                questions = []\n\n                for qa in p[\"qas\"]:\n\n                    question = qa[\"question\"]\n\n                    questions.append(question)\n\n                if questions:\n                    formatted.append({\n                        \"context\": context,\n                        \"questions\": questions,\n                    })\n                    \n    return formatted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:31:19.920785Z","iopub.execute_input":"2025-05-17T23:31:19.921560Z","iopub.status.idle":"2025-05-17T23:31:19.926999Z","shell.execute_reply.started":"2025-05-17T23:31:19.921532Z","shell.execute_reply":"2025-05-17T23:31:19.926390Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def flatten_context_qa_pairs(formatted_data):\n    \"\"\"\n    Convert formatted context-question-answer data into a flat list of\n    input-target training pairs for seq2seq modeling.\n\n    Args:\n        formatted_data: List of dicts with 'context', 'questions'\n\n    Returns:\n        A list of dicts with 'input' and 'target' fields\n    \"\"\"\n    flat_data = []\n\n    for item in formatted_data:\n        context = item[\"context\"]\n        for question in item[\"questions\"]:\n            input_text = context\n            target_text = question\n            flat_data.append({\"input\": input_text, \"target\": target_text})\n\n    return flat_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:31:22.267110Z","iopub.execute_input":"2025-05-17T23:31:22.267402Z","iopub.status.idle":"2025-05-17T23:31:22.271836Z","shell.execute_reply.started":"2025-05-17T23:31:22.267383Z","shell.execute_reply":"2025-05-17T23:31:22.271178Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"formatted_train_dataset = format_squad_dataset(ds[\"train\"])\nformatted_val_dataset = format_squad_dataset(ds[\"validation\"])\ntrain_dataset = flatten_context_qa_pairs(formatted_train_dataset)\nval_dataset = flatten_context_qa_pairs(formatted_val_dataset)\nprint(f\"Total training pairs: {len(train_dataset)}\")\nprint(f\"Total validation pairs: {len(val_dataset)}\")\nprint(train_dataset[1])\nprint(val_dataset[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:32:55.256852Z","iopub.execute_input":"2025-05-17T23:32:55.257414Z","iopub.status.idle":"2025-05-17T23:32:57.726001Z","shell.execute_reply.started":"2025-05-17T23:32:55.257385Z","shell.execute_reply":"2025-05-17T23:32:57.725293Z"}},"outputs":[{"name":"stdout","text":"Total training pairs: 76840\nTotal validation pairs: 9605\n{'input': '( لم يكن زلزال Ms 6 . 1 في 30 أغسطس 2008 في جنوب سيتشوان جزءا من هذه السلسلة لأنه كان ناجما عن صدع مختلف . انظر زلزال بانتشيهوا 2008 للحصول على التفاصيل . )', 'target': 'أين يجب أن تبحث عن مزيد من التفاصيل ؟'}\n{'input': 'غادر فريق الإغاثة الطارئة من الزلازل المكون من 184 شخصا ( يتألف من 12 شخصا من مكتب الدولة لرصد الزلازل و 150 من قيادة منطقة بكين العسكرية و 22 من مستشفى الشرطة العامة المسلحة ) بكين من مطار نانيوان في أواخر 12 مايو في طائرتي نقل عسكريتين للسفر إلى مقاطعة ونتشوان .', 'target': 'كم عدد الأشخاص الذين شكلوا فريق الإغاثة ؟'}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# 4. Loading of the AraT5v2-base-1024 model and tokenizing the datasets","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer, AutoModelForSeq2SeqLM\nfrom datasets import Dataset\n\n# Load tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\", legacy=False)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\")\n# Convert list to Hugging Face Dataset\nhf_train_dataset = Dataset.from_list(train_dataset)\nhf_val_dataset = Dataset.from_list(val_dataset)\n\n# Tokenize function\ndef tokenize(example):\n    model_input = tokenizer(\n        example[\"input\"],\n        max_length=1024,\n        padding=\"max_length\",\n        truncation=True\n    )\n    labels = tokenizer(\n        example[\"target\"],\n        max_length=64,\n        padding=\"max_length\",\n        truncation=True\n    )\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\n# Apply tokenizer\ntokenized_train_dataset = hf_train_dataset.map(tokenize, batched=False)\ntokenized_val_dataset = hf_val_dataset.map(tokenize, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:34:21.708591Z","iopub.execute_input":"2025-05-17T23:34:21.708907Z","iopub.status.idle":"2025-05-17T23:37:45.024153Z","shell.execute_reply.started":"2025-05-17T23:34:21.708886Z","shell.execute_reply":"2025-05-17T23:37:45.023182Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59f2a1a18d0b4400b88b1ebc582b4230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851156d6c78d40ad85d1903395d97224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be68d6502a8a411faad8d680a975189e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/8.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1069718534cf4722b8b5d0337fcfccb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3556a667fcec4f32a4346566b38028c9"}},"metadata":{}},{"name":"stderr","text":"2025-05-17 23:34:36.387789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747524876.602170      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747524876.660683      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af753f0f09084c299d83f04ee4f68a88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c563380f633e44b492ef3bfceead80f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06c51c561f0444ea9c7624c193b8ed64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/76840 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54e835a74770455fbd04dfb6359712bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9605 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da2301d32844ccd828b5781b5e00a0f"}},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# 5. Setting the GPUs for training","metadata":{}},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:37:45.025752Z","iopub.execute_input":"2025-05-17T23:37:45.025967Z","iopub.status.idle":"2025-05-17T23:37:45.813200Z","shell.execute_reply.started":"2025-05-17T23:37:45.025944Z","shell.execute_reply":"2025-05-17T23:37:45.812294Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nDevice: cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# 6. First phase of fine-tuning using HuggingFace Trainer with 10 epochs in Google collab pro for Task specification","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./araT5-qg\",\n    run_name=\"araT5-qg-run-1\",\n    learning_rate=2e-5,                           # standard LR for T5 fine-tuning\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    save_total_limit=1,                           # keep only 2 latest checkpoints\n    eval_strategy=\"epoch\",           # use eval_strategy (not evaluation_strategy)\n    save_strategy=\"epoch\",\n    fp16=True, \n    metric_for_best_model=\"loss\",\n    greater_is_better=False,\n    load_best_model_at_end=False,\n    report_to=\"none\",                             # no wandb/huggingface reporting\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n)\n\n# Start training\ntrainer.train()\n\n# Save final model and tokenizer\nmodel.save_pretrained(\"./araT5-qg-final\")\ntokenizer.save_pretrained(\"./araT5-qg-final\")\n\nprint(\"✅ Training complete! Model and tokenizer saved to './araT5-qg-final'\")\n\n# I runned this for the training ofc, but this just a demo..","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Hosting the first model on HuggingFace Hub","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\ntoken = \"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\"\nlogin(token)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi(token=os.getenv(\"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\"))\napi.upload_folder(\n    folder_path=\"/kaggle/working/araT5-qg-final\",\n    repo_id=\"NadirFartas/AraT5-V2-QG\",\n    repo_type=\"model\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Loading the second Dataset corpus-texte-questions.xml ","metadata":{}},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\n\n# Load XML\ntree = ET.parse('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml')\nroot = tree.getroot()\n\n# Print tag names of the first few elements\nfor child in root.iter():\n    print(child.tag)\n    break  # remove this break to see more tags if needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:40:53.847192Z","iopub.execute_input":"2025-05-17T23:40:53.847799Z","iopub.status.idle":"2025-05-17T23:40:53.955172Z","shell.execute_reply.started":"2025-05-17T23:40:53.847778Z","shell.execute_reply":"2025-05-17T23:40:53.954567Z"}},"outputs":[{"name":"stdout","text":"corpus\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"with open('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml', 'r', encoding='utf-8') as f:\n    for _ in range(20):\n        print(f.readline().strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:41:14.907390Z","iopub.execute_input":"2025-05-17T23:41:14.908052Z","iopub.status.idle":"2025-05-17T23:41:14.913163Z","shell.execute_reply.started":"2025-05-17T23:41:14.908030Z","shell.execute_reply":"2025-05-17T23:41:14.912589Z"}},"outputs":[{"name":"stdout","text":"<?xml version='1.0' encoding='utf-8'?>\n<corpus><texte id=\"0\"><titre>الأسد والفأر\n</titre><body>\nوسط غابة كبيرة كان هناك\nالاسد ملك الغابة نائما تحت\nظل شجرة وكان هناك فأر\nصغير يلعب في الجوارثم لاحظ\nأن الملك نائم لذلك قرر أن يلعب قليلا صعد على ظهره\nوبدأ يتزحلق عبر ذيله إلى الأسفل أعادها مرة واثنتان وثلاث استمتع الفأر بالأمر، انزعج الأسد واستيقظ ثم\nأمسك بالفأر الصغيرأراد أكله استوقفه الفأر الصغير باكيا يترجاه لكي لايكون\nوجبة خفيفة له ترجاه الفأر ووعده بأن لايزعجه مرة أخرى\nبل لربما يحتاجه في وقت من الأوقات تأثر الأسد بما سمعه ثم ترك الفأر يرحل وبعد بضعة أيام وككل يوم\nملك الغابة يأخذ قيلولته إذ بالصيادي يلقي شبكته عليه ليمسك به فعلا قد وقع في الفخ\nبدأ الأسد بالزئير ليسمعه كل من في الغابة حتى الفأر الصغير سمع زئيره ليتذكر أنه\nمدين للأسد وعليه المساعدةوأن يرد المعروف بمثله لم يتردد صديقنا\nوذهب مسرعا ليرى ماحصل وعندما وصل وجد الأسد تحت الشباك\nتسلقها الفأر وبدأ بتمزيقها بأسنانه الحادة\nحتى مزقها بالكامل وأخيرا أنقذ الأسد من الفخ ورد له صنيعه ومن ذلك الحين والأسد صديق الفأر.\nهناك أصدقاء يعرفون عند الشدائد فلنتمسك بهم.\n</body><questions>\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# 9. Extracting the exemples from the stucture of .xml file","metadata":{}},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimport re\n\ndef parse_custom_xml(file_path):\n    tree = ET.parse(file_path)\n    root = tree.getroot()\n\n    data = []\n    for texte in root.findall(\"texte\"):\n        raw_context = texte.find(\"body\").text or \"\"\n        context = re.sub(r'\\s+', ' ', raw_context).strip()\n        questions_block = texte.find(\"questions\").text\n\n        # Check and split questions using dash\n        if questions_block:\n            questions = [q.strip() for q in questions_block.strip().split(\"-\") if q.strip()]\n            for question in questions:\n                data.append({\"input\": context, \"target\": question})\n\n    return data\ndata = parse_custom_xml(\"/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml\")\ntrain_data = data[:]\nprint(f\"Total examples extracted: {len(data)}\")\nprint(data[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:41:41.908443Z","iopub.execute_input":"2025-05-17T23:41:41.909148Z","iopub.status.idle":"2025-05-17T23:41:42.083347Z","shell.execute_reply.started":"2025-05-17T23:41:41.909102Z","shell.execute_reply":"2025-05-17T23:41:42.082767Z"}},"outputs":[{"name":"stdout","text":"Total examples extracted: 1506\n{'input': 'في يوم من الأيام وفي أحد غابات إفريقيا، بينما كان أحد الفهود يتجول قرب ضفة النهر باحثا عن فريسة يسد بها رمقه، لمح قطيعا من الغزلان يرعى العشب على الضفة المقابلة. فقال في نفسه وهو ينظر إليها: \"ليتني أعرف السباحة، فأعبر النهر وأفترس غزالا أملئ به معدتي الخاوية.\" التفت الفهد يمنةً ويسرةً باحثاً عن شيء يمكنّه من العبور إلى الضفّة المقابلة، ولكن دون جدوى . ثم نظر وسط النهر فرأى فرس نهر يسبح في الماء ويأكل من الأعشاب التي نمت في قاعه. فكر الفهد قليلا ثم توجه إلى ضفة النهر وخاطب الفرس قائلا: \" السلام عليك يا ابن عمي \" فأجاب فرس النهر وقد بدت عليه علامات التعجب: \"وعليك السلام. كيف تكون ابن عمي وأنت لست من فصيلتي؟ فأنت تملك جسما رشيقا ومرقطا بينما جسمي ممتلئ وخال من البقع\" فأجاب الفهد في خبث: \" أنا من بلد بعيد حيث تكون أفراس النهر مرقطة ونحيلة.\" تظاهر فرس النهر بتصديق كلام الفهد ثم قال: \"حسن يا ابن عمي كيف يمكنني خدمتك؟\" فقال الفهد: \"هل يمكنك مساعدتي ونقلي على ظهرك الى الضفة المقابلة للنهر؟\" فكر فرس النهر قليلا ثم وافق وحمل الفهد على ضهره ليعبر به النهر. وفي منتصف الطريق توقف عن السباحة ثم قال: \"بما أنك فرس نهر فبإمكانك السباحة والغطس مثلي. أليس كذلك؟\" فأجاب الفهد مرتبكا : \"إم م م ... بالطبع يمكنني السباحة.\" وبينما كان الفهد يهمهم ويبحث في رأسه عن كلام مقنع، اذ بفرس النهر يغطس به الى اعماق النهر. فكانت تلك الغطسة درسا قاسيا للفهد الذي نجا بأعجوبة من الغرق. وهكذا نال الفهد الخبيث جزاء خداعه لفرس النهر واستخفافه بذكائه.', 'target': 'هل انخدع فرس النهر بكذبة الفهد؟'}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def split_questions(dataset):\n    new_dataset = []\n\n    for item in dataset:\n        context = item['input']\n        target_text = item['target']\n\n        # Split by newline or another appropriate separator\n        # This example splits by \\n - adapt based on your actual data structure\n        questions = [q.strip() for q in target_text.split('\\n') if q.strip()]\n\n        # Create a new entry for each question\n        for question in questions:\n            new_dataset.append({\n                'input': context,\n                'target': question\n            })\n\n    return new_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:42:14.637343Z","iopub.execute_input":"2025-05-17T23:42:14.637970Z","iopub.status.idle":"2025-05-17T23:42:14.642218Z","shell.execute_reply.started":"2025-05-17T23:42:14.637947Z","shell.execute_reply":"2025-05-17T23:42:14.641441Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"dataV = split_questions(data)\nprint(f\"Total examples extracted: {len(dataV)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:42:52.368320Z","iopub.execute_input":"2025-05-17T23:42:52.368912Z","iopub.status.idle":"2025-05-17T23:42:52.375996Z","shell.execute_reply.started":"2025-05-17T23:42:52.368889Z","shell.execute_reply":"2025-05-17T23:42:52.375178Z"}},"outputs":[{"name":"stdout","text":"Total examples extracted: 4806\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# 10. Splitting the dataset for Train, Validation and test data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Three-way split (train/val/test)\ntrain_data, temp_data = train_test_split(dataV, test_size=0.2, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\nprint(f\"Training samples: {len(train_data)} ({len(train_data)/len(dataV):.1%})\")\nprint(f\"Validation samples: {len(val_data)} ({len(val_data)/len(dataV):.1%})\")\nprint(f\"Test samples: {len(test_data)} ({len(test_data)/len(dataV):.1%})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:43:20.647641Z","iopub.execute_input":"2025-05-17T23:43:20.648254Z","iopub.status.idle":"2025-05-17T23:43:20.669009Z","shell.execute_reply.started":"2025-05-17T23:43:20.648227Z","shell.execute_reply":"2025-05-17T23:43:20.668294Z"}},"outputs":[{"name":"stdout","text":"Training samples: 3844 (80.0%)\nValidation samples: 481 (10.0%)\nTest samples: 481 (10.0%)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(\"train data\" ,train_data[1])\nprint(\"val data\" ,val_data[1])\nprint(\"test data\" ,test_data[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:43:37.325228Z","iopub.execute_input":"2025-05-17T23:43:37.325691Z","iopub.status.idle":"2025-05-17T23:43:37.330392Z","shell.execute_reply.started":"2025-05-17T23:43:37.325667Z","shell.execute_reply":"2025-05-17T23:43:37.329692Z"}},"outputs":[{"name":"stdout","text":"train data {'input': 'كان أمين يلعب تحت الشجرة ، وإذا بصوت يأتي من الأعلى إنه صديقه النسر، لقد بسط جناحيه كطائرة ضخمة و نزل بين قدميه، فسأله أمين : إلى أين الرحلة هذه المرة ؟ « سأحملك إلى بلد إفريقي، شمسه ساطعة طقسه دافئ ، إن عرفته أعطيتك ما تريد» قالها وهو يبتسم ثم حنى ظهره قليلا ، فقفز فوقه أمين ثم حلق به في السماء العالية. خفض أمين بصره، فرأى مناظر خلابة، البراري و البحيرات و التلال و السهول و شاهد واحة برية تعج بأنواع الحيوانات : الأسود و النمور و الفيلة و الظباء وحمر الوحش و هي تجوب الأراضي... وأخذ يراقب تحركاتها في شغف ، فلم يسبق له أن رآها عن كثب ، وهنا صاح أمين في النسر قائلا : أنزلني من فضلك، لقد عرفتها ، لقد عرفتها! «ماذا عرفت يا ولد ؟ هل تحمل خريطة في رأسك؟!» - لقد وصلنا إلى كينيا بلاد الماساي وقماش الساموبا المزركش بالألوان البديعة.', 'target': 'كيف كانت المناظر التي رآها أمين؟'}\nval data {'input': 'سكنت عائلة البيت المقابل لبيتنا، ولا تتصورا فرحتي فى ذلك اليوم بأولاد جيراننا. لكن ما لبثت هذه الفرحة أن انقلبت إلى كابوس مزعج يطارد كل سكان العمارة، لأن هؤلاء الأطفال ملؤوا السلم صخبا. هذا يقضي طول النهار صاعدا، نازلا، و الثاني يدق الأبواب تم يختفي ضاحكا، و الثالث مكانه المفضل صناديق البريد التي ييبقى طول الوقت مطبلا عليها، أخوهم الرابع هوايته المفضلة الرسم على الأبواب والجدران، (أما الصغير الذي لم يتعلم المشي بعد فتخرجه أمه من البيت و تجلسه أمام الباب حيث يقضي النهار طوله بين بكاء و أصوات لا يفهمها إلا هو)، هذا حال عمارتنا التي بدأنا نفكر في الرحيل عنها و تركها لهذه العائلة المزعجة.', 'target': 'استخرج من النص ضد كلمة: يظهر ثم وظفها في جملة مفيدة؟.'}\ntest data {'input': 'وفي عصر من العصور القديمة ، كان هناك ملك عظيم وهو الملك النعمان بن حسان ، كان لديه مُلك عظيم ، ولكنه كان تعيس ويعيش في حزن دائم .وقد سمع عن بلاد الأسرار وما بها من عجائب وأشياء غريبة ؛ فأراد أن يعرف كل شيء عن تلك العجائب . لم يكن أحد يعلم بوجود بلاد الأسرار سوى ساحر وحيد بالجبل ، تناقل الناس سيرته حتى وصل أمره للملك النعمان ، فأرسل النعمان أحد ضباطه إلى الساحر لكي يعرف منه السر وراء تلك البلاد . فأخذ يتسلق الأحجار والصخور حتى وصل لبيت الساحر المشهور ، ورفع يده ليطرق الباب ، ففتح الباب قبل أن يطرقه ثم سمع صوت ينادي عليه باسمه .وما إن دخل إلى منتصف المكان حتى تحرك البساط من تحت قدميه ، وأخذ يهبط به إلى الأسفل حتى نزل تحت الأرض لمسافة بعيدة وسمع صوت يقول له ماذا تريد ؟ . رأى الساحر جالس على عرش كبير .قال له الساحر :أنا أعلم أنك من جند النعمان ، وجئت لتعرف سر الحصان المسحور ، فبلاد الأسرار بلاد بعيدة ، ستقطع فيها الصحارى وتجوب الجبال والوديان لتصل إليها وهناك ستجد الحصان المسحور ، ولكني أحذرك وأحذر النعمان ، فالطمع نهايته محملة بالأخطار ، والوصول إلى ذلك الحصان من الأمور الصعبة. عاد الجندي وأخبر النعمان بما أخبره به ساحر الجبل ولكنه لم يكن يفكر سوى في الحصان الطيار المسحور وبلاد الأسرار ، ثم تخيل نفسه راكبًا على ظهر الحصان ويطير بين الناس فيحيوه بتحية الملوك . فنادى الملك على قائد الجيوش ، وطلب منه أن يعد نفسه للسفر بفرقة مكونة من مائة جندي ليعبروا البحار والصحارى ويأتوه بالحصان العجيب، وبالفعل خرج قائد الجيوش ومعه بقية الجنود حتى ابتعدوا عن بلادهم ، وامتدت أمامهم الصحراء دون نهاية . ونفذ ما معهم من طعام وشراب وهاجمتهم وحوش الصحراء فقتلت منهم البعض ، وقتل الجوع البعض الأخر ، فقرروا العودة إلى النعمان ليخبروه بمشقة الطريق واستحالة الوصل ، ولكن لم يصل منهم أحد سوى قائد الجيوش . غضب النعمان أشد الغضب ، وطلب من قائد الجيوش أن يذهب مرة أخرى ومعه من الجنود خمسمائة ويحضر الحصان ، فخرج القائد وظن أنه لن يعود ، وأخذ معه كل الجنود ، وساروا في الصحراء إلى أن نفذ منهم الطعام والماء وهاجمتهم الوحوش ، وقتلت منهم الكثير ، ولم يتبقى منهم الا قلة قليلة استطاعت عبور النهر . ولكن قبل أن يصلوا إلى نهايته ، هاجمتهم التماسيح فأظهروا شجاعة في القتال ولكن لم يدم بهم الحال طويلًا ، ولم يستطيعوا الصمود ؛ فلم يبقى من الجند إلا عشرون فقط ، حاولوا الفرار هاربين ، لعلهم يصلوا إلى أرض النعمان سالمين ، ولكن مصاعب الطريق أرهقتهم ، فلم يصل منهم الا خمسة جنود فقط . وهناك ثار النعمان ، وأخذ يردد وهو في حالة غضب شديد ، سأذهب بنفسي لبلاد الأسرار لأحضر هذا الحصان المسحور ،فقد أعماه الطمع وضيع أكفأ الجنود ، ولكن قبل أن يذهب مر على ساحر الجبل ، لعله يساعده بسر من بلاد الأسرار ، فأخبره الساحر أنه لا يعرف سوى ما قال ، وأن الوصول للحصان صعب . ونصحه بالتراجع عن الذهاب لبلاد الأسرار ، وحمله موت الجنود الأبرياء ؛ فهم من يحمون البلاد ، ويدافعون عنها وبهذا سيبعدهم عن عملهم ويعجل بموتهم . خرج النعمان يفكر بكلام الساحر وكل ما قال ، لكن سرعان ما غلبه الطمع وصمم أن يحصل على الحصان الطيار ، فخرج مع الجيوش وجاب الصحارى والمخاطر والأهوال ، ومات كل من معه ولم يبقى سواه في وادي الأسرار . عندما وصل فقد الوعي من فرط التعب ، ولما استفاق رأى أميرة ليس هناك أجمل منها في الوجود ترتدي زي أخضر اللون ، وحلي من ذهب ، ومعها حصان أبيض بلون السحاب ، له جناحان يرفرف بهما ، فيملأ صفير العصافير المكان . وسألته الأميرة من هو ؟ ومن أين جاء ؟ وماذا يريد من بلاد الأسرار ؟ ، فأجابها أنه جاء من أجل الحصان المسحور . غضبت الأميرة كثيرًا وقالت له :ولكنه ملكي وليس ملكك وهذه تسمى في بلادنا سرقة ، فلم يعبأ بكلامها النعمان وجذب الحصان ليركبه ويطير ، فدعت عليه الأميرة أن يضيق في وجهه الطريق ويكثر عليه الأعداء ، فضحك النعمان منها وأخذ الحصان وانطلق . وما أن وصل إلى أرضه حتى وجد الحال غير الحال ، فقد دخل الأعداء بلاده واحتلوا قصره ، فأخبر الناس أنه النعمان فلم يصدقوه وقالوا أن النعمان مات ولو كان حيا لقتلوه ؛ فقد تسبب بقتل الجنود وهجوم الأعداء على بلادهم . فحزن النعمان كثيرًا على ما وصل به الحال وما حل بشعبه من فقر وسؤال ، وأدرك أن هذا بسبب دعاء الأميرة عليه وعاد إليها بالحصان المسحور ، فلما وصل فرحت بعودة الحصان . طلب منها النعمان الصفح والغفران وحكى لها قصة بلاده ، و ما آل إليه الحال ، فأعطته الحصان وطلبت منه أن يعود ويجمع الناس حوله ويشكل جيشًا من الجنود ، ويحارب العدو ويطرده من البلاد . وبالفعل عاد النعمان ومعه الحصان المسحور وجمع الناس والجيش حوله ، وحكى لهم ما حدث ووعدهم بتحرير البلاد وطرد العدو منها ، ففرحوا به وساعدوه وما أن استعدت قوات النعمان حتى هجم على القصر وركب الحصان ، وحلق فوق الأعداء فخافوا مما رأوه وهربوا مسرعين . وبعد أن عاد الأمن إلى بلاد النعمان ذهب إلى الأميرة وطلب منها أن تعود معه إلى بلاده وتتزوج منه ، فوافقت الأميرة الجميلة ورجعت هي والحصان العجيب مع الملك النعمان ، وأنجبت منه البنين والبنات وعاشا في سعادة وهناء .', 'target': 'ماذا حذر الساحر النعمان و ضابطه؟'}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# 11. Loading the first model and Tokenizing the Dataset","metadata":{}},{"cell_type":"code","source":"from transformers import T5Tokenizer, AutoModelForSeq2SeqLM, AutoTokenizer\nfrom datasets import Dataset\n\n# Load tokenizer\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"NadirFartas/AraT5_V2_10epoch\")\ntokenizer = AutoTokenizer.from_pretrained(\"NadirFartas/AraT5_V2_10epoch\")\n# Convert list to Hugging Face Dataset\nhf_train_dataset = Dataset.from_list(train_data)\nhf_val_dataset = Dataset.from_list(val_data)\n\n# Tokenize function\ndef tokenize(example):\n    model_input = tokenizer(\n        example[\"input\"],\n        max_length=512,\n        padding=\"max_length\",\n        truncation=True\n    )\n    labels = tokenizer(\n        example[\"target\"],\n        max_length=64,\n        padding=\"max_length\",\n        truncation=True\n    )\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\n# Apply tokenizer\ntokenized_train_dataset = hf_train_dataset.map(tokenize, batched=False)\ntokenized_val_dataset = hf_val_dataset.map(tokenize, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:44:13.424880Z","iopub.execute_input":"2025-05-17T23:44:13.425598Z","iopub.status.idle":"2025-05-17T23:44:52.557989Z","shell.execute_reply.started":"2025-05-17T23:44:13.425574Z","shell.execute_reply":"2025-05-17T23:44:52.557391Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24541ca198da43c19e108720f17c5d45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb35a3e334cd405590c27de79c987c9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec9c91d951d2445bb695ee93d0c9c469"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b0d93c1ef44b9dad3c5306bb9d1fb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3d893e744a46acab762ce22e914cf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df2d531b7354972a1a43b426fbdf6af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcacfbc7e3e64966b23fdb9c510ed95c"}},"metadata":{}},{"name":"stderr","text":"You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3844 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"219b233d6cb6439e99c0060117c2a6fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/481 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"581a9fe802eb4ae389df61b916dde2d4"}},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# 12. Clearing memory and preparing GPU usage","metadata":{}},{"cell_type":"code","source":"import gc\nimport torch\n\n# Clear memory\ngc.collect()\ntorch.cuda.empty_cache()\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T23:45:18.773599Z","iopub.execute_input":"2025-05-17T23:45:18.774213Z","iopub.status.idle":"2025-05-17T23:45:19.685978Z","shell.execute_reply.started":"2025-05-17T23:45:18.774185Z","shell.execute_reply":"2025-05-17T23:45:19.685434Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nDevice: cuda\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# 13. Second phase of fine-tuning of the first model using Kaggle free resources with 11 epochs for topic and task adaptaion ","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./araT5-qg\",\n    run_name=\"araT5-qg-run-1\",\n    learning_rate=2e-5,                           # standard LR for T5 fine-tuning\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n    num_train_epochs=14,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",\n    logging_steps=250,\n    save_total_limit=1,                           # keep only 2 latest checkpoints\n    eval_strategy=\"epoch\",           # use eval_strategy (not evaluation_strategy)\n    save_strategy=\"epoch\",\n    fp16=True,\n    greater_is_better=False,\n    report_to=\"none\",                             # no wandb/huggingface reporting\n    save_safetensors=True,\n\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)\n\n# Start training\ntrainer.train()\n\n# Save final model and tokenizer\nmodel.save_pretrained(\"./araT5-qg-final\")\ntokenizer.save_pretrained(\"./araT5-qg-final\")\n\nprint(\"✅ Training complete! Model and tokenizer saved to '/content/drive/MyDrive/araT5-qg-final'\")\n\n# I runned this as well for the second fine-tuning, but this is a demo...","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 14. Hosting the final model in HuggingFace Hub","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nlogin(\"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\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi(token=os.getenv(\"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\"))\napi.upload_folder(\n    folder_path=\"/kaggle/working/araT5-qg-final\",\n    repo_id=\"NadirFartas/AraT5-trained-11epochs\",\n    repo_type=\"model\",\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}