{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11662247,"sourceType":"datasetVersion","datasetId":7318913}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:16:59.957688Z","iopub.execute_input":"2025-05-04T03:16:59.958030Z","iopub.status.idle":"2025-05-04T03:17:00.297046Z","shell.execute_reply.started":"2025-05-04T03:16:59.958002Z","shell.execute_reply":"2025-05-04T03:17:00.296259Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:17:00.298267Z","iopub.execute_input":"2025-05-04T03:17:00.298659Z","iopub.status.idle":"2025-05-04T03:17:10.204569Z","shell.execute_reply.started":"2025-05-04T03:17:00.298635Z","shell.execute_reply":"2025-05-04T03:17:10.203840Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1.1\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!pip install \\\n    datasets \\\n    evaluate \\\n    rouge_score\\\n    loralib \\\n    evaluate \\\n    accelerate \\\n    bitsandbytes \\\n    trl \\\n    peft \\\n    -U --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:17:10.205402Z","iopub.execute_input":"2025-05-04T03:17:10.205588Z","iopub.status.idle":"2025-05-04T03:18:40.006827Z","shell.execute_reply.started":"2025-05-04T03:17:10.205568Z","shell.execute_reply":"2025-05-04T03:18:40.006147Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/16\u001b[0m [bitsandbytes][0m [bitsandbytes]er-cu12]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"def format_squad_dataset(dataset_split):\n    \"\"\"\n    Format a SQuAD-style dataset split into a list of dictionaries \n    with context, questions, and answers.\n\n    Args:\n        dataset_split: a split of the SQuAD-style dataset, e.g., ds[\"train\"] or ds[\"validation\"]\n\n    Returns:\\\n    \n        A list of formatted entries: [{\"context\": ..., \"questions\": [...]}]\n    \"\"\"\n    formatted = []\n\n    for article in dataset_split:\n        for paragraph in article[\"data\"]:\n            for p in paragraph[\"paragraphs\"]:\n                context = p[\"context\"]\n                questions = []\n\n                for qa in p[\"qas\"]:\n\n                    question = qa[\"question\"]\n\n                    questions.append(question)\n\n                if questions:\n                    formatted.append({\n                        \"context\": context,\n                        \"questions\": questions,\n                    })\n                    \n    return formatted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:07:11.070845Z","iopub.execute_input":"2025-05-05T00:07:11.071332Z","iopub.status.idle":"2025-05-05T00:07:11.075858Z","shell.execute_reply.started":"2025-05-05T00:07:11.071298Z","shell.execute_reply":"2025-05-05T00:07:11.075209Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\n\n# Load dataset\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")\nformatted_train_dataset = format_squad_dataset(ds[\"train\"])\nformatted_val_dataset = format_squad_dataset(ds[\"validation\"])\n\nprint(f\"âœ… Done. Formatted {len(formatted_train_dataset)} training context blocks.\")\nprint(f\"âœ… Done. Formatted {len(formatted_val_dataset)} validation context blocks.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:18:40.015313Z","iopub.execute_input":"2025-05-04T03:18:40.015527Z","iopub.status.idle":"2025-05-04T03:18:49.933034Z","shell.execute_reply.started":"2025-05-04T03:18:40.015513Z","shell.execute_reply":"2025-05-04T03:18:49.932266Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d38619f7cdf8407086df0dd6d5e385d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14dbb1fe2574083b3dc3c653c4ae0a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebbd9ea7f3fd4c6ca27d88a55db47e24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bef115618bbd49479bd1bb6b397f802a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df157078eaf24f90b1267c596b8a1373"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5ac9f773a54204b924e30cbbf2b0b2"}},"metadata":{}},{"name":"stdout","text":"âœ… Done. Formatted 18117 training context blocks.\nâœ… Done. Formatted 7290 validation context blocks.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"def flatten_context_qa_pairs(formatted_data):\n    \"\"\"\n    Convert formatted context-question-answer data into a flat list of\n    input-target training pairs for seq2seq modeling.\n\n    Args:\n        formatted_data: List of dicts with 'context', 'questions'\n\n    Returns:\n        A list of dicts with 'input' and 'target' fields\n    \"\"\"\n    flat_data = []\n\n    for item in formatted_data:\n        context = item[\"context\"]\n        for question in item[\"questions\"]:\n            input_text = context\n            target_text = question\n            flat_data.append({\"input\": input_text, \"target\": target_text})\n\n    return flat_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:07:07.808902Z","iopub.execute_input":"2025-05-05T00:07:07.809168Z","iopub.status.idle":"2025-05-05T00:07:07.813236Z","shell.execute_reply.started":"2025-05-05T00:07:07.809149Z","shell.execute_reply":"2025-05-05T00:07:07.812677Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_dataset = flatten_context_qa_pairs(formatted_train_dataset)\nval_dataset = flatten_context_qa_pairs(formatted_val_dataset)\nprint(f\"Total training pairs: {len(train_dataset)}\")\nprint(f\"Total validation pairs: {len(val_dataset)}\")\nprint(train_dataset[1])\nprint(val_dataset[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:18:49.939840Z","iopub.execute_input":"2025-05-04T03:18:49.940086Z","iopub.status.idle":"2025-05-04T03:18:50.629450Z","shell.execute_reply.started":"2025-05-04T03:18:49.940071Z","shell.execute_reply":"2025-05-04T03:18:50.628732Z"}},"outputs":[{"name":"stdout","text":"Total training pairs: 76840\nTotal validation pairs: 9605\n{'input': '( Ù„Ù… ÙŠÙƒÙ† Ø²Ù„Ø²Ø§Ù„ Ms 6 . 1 ÙÙŠ 30 Ø£ØºØ³Ø·Ø³ 2008 ÙÙŠ Ø¬Ù†ÙˆØ¨ Ø³ÙŠØªØ´ÙˆØ§Ù† Ø¬Ø²Ø¡Ø§ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù„Ø£Ù†Ù‡ ÙƒØ§Ù† Ù†Ø§Ø¬Ù…Ø§ Ø¹Ù† ØµØ¯Ø¹ Ù…Ø®ØªÙ„Ù . Ø§Ù†Ø¸Ø± Ø²Ù„Ø²Ø§Ù„ Ø¨Ø§Ù†ØªØ´ÙŠÙ‡ÙˆØ§ 2008 Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ . )', 'target': 'Ø£ÙŠÙ† ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ø­Ø« Ø¹Ù† Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ ØŸ'}\n{'input': 'ØºØ§Ø¯Ø± ÙØ±ÙŠÙ‚ Ø§Ù„Ø¥ØºØ§Ø«Ø© Ø§Ù„Ø·Ø§Ø±Ø¦Ø© Ù…Ù† Ø§Ù„Ø²Ù„Ø§Ø²Ù„ Ø§Ù„Ù…ÙƒÙˆÙ† Ù…Ù† 184 Ø´Ø®ØµØ§ ( ÙŠØªØ£Ù„Ù Ù…Ù† 12 Ø´Ø®ØµØ§ Ù…Ù† Ù…ÙƒØªØ¨ Ø§Ù„Ø¯ÙˆÙ„Ø© Ù„Ø±ØµØ¯ Ø§Ù„Ø²Ù„Ø§Ø²Ù„ Ùˆ 150 Ù…Ù† Ù‚ÙŠØ§Ø¯Ø© Ù…Ù†Ø·Ù‚Ø© Ø¨ÙƒÙŠÙ† Ø§Ù„Ø¹Ø³ÙƒØ±ÙŠØ© Ùˆ 22 Ù…Ù† Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø´Ø±Ø·Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ø§Ù„Ù…Ø³Ù„Ø­Ø© ) Ø¨ÙƒÙŠÙ† Ù…Ù† Ù…Ø·Ø§Ø± Ù†Ø§Ù†ÙŠÙˆØ§Ù† ÙÙŠ Ø£ÙˆØ§Ø®Ø± 12 Ù…Ø§ÙŠÙˆ ÙÙŠ Ø·Ø§Ø¦Ø±ØªÙŠ Ù†Ù‚Ù„ Ø¹Ø³ÙƒØ±ÙŠØªÙŠÙ† Ù„Ù„Ø³ÙØ± Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹Ø© ÙˆÙ†ØªØ´ÙˆØ§Ù† .', 'target': 'ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø®Ø§Øµ Ø§Ù„Ø°ÙŠÙ† Ø´ÙƒÙ„ÙˆØ§ ÙØ±ÙŠÙ‚ Ø§Ù„Ø¥ØºØ§Ø«Ø© ØŸ'}\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from transformers import T5Tokenizer, AutoModelForSeq2SeqLM\nfrom datasets import Dataset\n\n# Load tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\", legacy=False)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\")\n# Convert list to Hugging Face Dataset\nhf_train_dataset = Dataset.from_list(train_dataset)\nhf_val_dataset = Dataset.from_list(val_dataset)\n\n# Tokenize function\ndef tokenize(example):\n    model_input = tokenizer(\n        example[\"input\"], \n        max_length=512, \n        padding=\"max_length\", \n        truncation=True\n    )\n    labels = tokenizer(\n        example[\"target\"], \n        max_length=64, \n        padding=\"max_length\", \n        truncation=True\n    )\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\n# Apply tokenizer\ntokenized_train_dataset = hf_train_dataset.map(tokenize, batched=False)\ntokenized_val_dataset = hf_val_dataset.map(tokenize, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:18:50.630131Z","iopub.execute_input":"2025-05-04T03:18:50.630314Z","iopub.status.idle":"2025-05-04T03:22:08.297308Z","shell.execute_reply.started":"2025-05-04T03:18:50.630300Z","shell.execute_reply":"2025-05-04T03:22:08.296385Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88f27c54397344379535dcd9578d54e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"004f99820f7141f1a2ed3e32bb8608d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e4f2bd568b84410984865d2a9dc2bda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/8.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d98eda1680a142f997df606e8153c3bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c60ad62243e74223ad35a73e0b85bd3a"}},"metadata":{}},{"name":"stderr","text":"2025-05-04 03:19:14.304570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746328754.760556      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746328754.903838      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20dda1c408084c4094bf28e8c20da1ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45749d43c0604698a9d0c7b34a22a337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b15cbf8af94d7190eff842bfd473bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/76840 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3efa86c4d3454ba9edbcb4836a207c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9605 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9db55239baba45ab8777c31e94b964c6"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nsecret_label = \"HF Hub\"\nsecret_value = UserSecretsClient().get_secret(secret_label)\nlogin(token=secret_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:22:08.298409Z","iopub.execute_input":"2025-05-04T03:22:08.298687Z","iopub.status.idle":"2025-05-04T03:22:08.981168Z","shell.execute_reply.started":"2025-05-04T03:22:08.298669Z","shell.execute_reply":"2025-05-04T03:22:08.980227Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:22:08.984852Z","iopub.execute_input":"2025-05-04T03:22:08.985383Z","iopub.status.idle":"2025-05-04T03:22:09.744141Z","shell.execute_reply.started":"2025-05-04T03:22:08.985357Z","shell.execute_reply":"2025-05-04T03:22:09.743271Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nDevice: cuda\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./araT5-qg\",\n    run_name=\"araT5-qg-run-1\",\n    learning_rate=2e-5,                           # standard LR for T5 fine-tuning\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    save_total_limit=1,                           # keep only 2 latest checkpoints\n    eval_strategy=\"epoch\",           # use eval_strategy (not evaluation_strategy)\n    save_strategy=\"epoch\",\n    fp16=True, \n    metric_for_best_model=\"loss\",\n    greater_is_better=False,\n    load_best_model_at_end=False,\n    report_to=\"none\",                             # no wandb/huggingface reporting\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n)\n\n# Start training\ntrainer.train()\n\n# Save final model and tokenizer\nmodel.save_pretrained(\"./araT5-qg-final\")\ntokenizer.save_pretrained(\"./araT5-qg-final\")\n\nprint(\"âœ… Training complete! Model and tokenizer saved to './araT5-qg-final'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:22:09.745123Z","iopub.execute_input":"2025-05-04T03:22:09.745385Z","iopub.status.idle":"2025-05-04T10:51:06.183453Z","shell.execute_reply.started":"2025-05-04T03:22:09.745368Z","shell.execute_reply":"2025-05-04T10:51:06.182531Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2099068984.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='14409' max='14409' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [14409/14409 7:28:46, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.561800</td>\n      <td>0.458341</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.526300</td>\n      <td>0.445013</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.499700</td>\n      <td>0.441425</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"âœ… Training complete! Model and tokenizer saved to './araT5-qg-final'\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"%cd /kaggle/working/araT5-qg-final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:09:59.964970Z","iopub.execute_input":"2025-05-04T11:09:59.965834Z","iopub.status.idle":"2025-05-04T11:09:59.971108Z","shell.execute_reply.started":"2025-05-04T11:09:59.965804Z","shell.execute_reply":"2025-05-04T11:09:59.970259Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/araT5-qg-final\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"!git init","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:17.651518Z","iopub.execute_input":"2025-05-04T11:05:17.652159Z","iopub.status.idle":"2025-05-04T11:05:17.856600Z","shell.execute_reply.started":"2025-05-04T11:05:17.652136Z","shell.execute_reply":"2025-05-04T11:05:17.855816Z"}},"outputs":[{"name":"stdout","text":"Reinitialized existing Git repository in /kaggle/working/araT5-qg-final/.git/\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"!git remote add origin https://huggingface.co/NadirFartas/NadirFartas/AraT5-V2-QG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:20.005847Z","iopub.execute_input":"2025-05-04T11:05:20.006627Z","iopub.status.idle":"2025-05-04T11:05:20.209809Z","shell.execute_reply.started":"2025-05-04T11:05:20.006586Z","shell.execute_reply":"2025-05-04T11:05:20.208884Z"}},"outputs":[{"name":"stdout","text":"error: remote origin already exists.\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"!git remote set-url origin https://NadirFartas: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@huggingface.co/NadirFartas/AraT5-V2-QG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:26.767710Z","iopub.execute_input":"2025-05-04T11:05:26.768537Z","iopub.status.idle":"2025-05-04T11:05:26.969847Z","shell.execute_reply.started":"2025-05-04T11:05:26.768506Z","shell.execute_reply":"2025-05-04T11:05:26.968798Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Configure your identity\n!git config user.email \"fartasnadir2003@gmail.com\"\n!git config user.name \"NadirFartas\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:28.843551Z","iopub.execute_input":"2025-05-04T11:05:28.843836Z","iopub.status.idle":"2025-05-04T11:05:29.239653Z","shell.execute_reply.started":"2025-05-04T11:05:28.843813Z","shell.execute_reply":"2025-05-04T11:05:29.238570Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Add and commit files\n!git add .\n!git commit -m \"Initial commit of AraT5 version 2 fine-tuned model\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:31.134529Z","iopub.execute_input":"2025-05-04T11:05:31.135080Z","iopub.status.idle":"2025-05-04T11:05:31.532876Z","shell.execute_reply.started":"2025-05-04T11:05:31.135049Z","shell.execute_reply":"2025-05-04T11:05:31.532146Z"}},"outputs":[{"name":"stdout","text":"On branch main\nnothing to commit, working tree clean\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"!git branch -M main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:34.038330Z","iopub.execute_input":"2025-05-04T11:05:34.039046Z","iopub.status.idle":"2025-05-04T11:05:34.241921Z","shell.execute_reply.started":"2025-05-04T11:05:34.039019Z","shell.execute_reply":"2025-05-04T11:05:34.241079Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"!git fetch origin\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:07:29.615811Z","iopub.execute_input":"2025-05-04T11:07:29.616770Z","iopub.status.idle":"2025-05-04T11:07:30.157723Z","shell.execute_reply.started":"2025-05-04T11:07:29.616738Z","shell.execute_reply":"2025-05-04T11:07:30.156729Z"}},"outputs":[{"name":"stdout","text":"warning: no common commits\nremote: Enumerating objects: 4, done.\u001b[K\nremote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\nUnpacking objects: 100% (4/4), 1.13 KiB | 386.00 KiB/s, done.\nFrom https://huggingface.co/NadirFartas/AraT5-V2-QG\n * [new branch]      main       -> origin/main\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi(token=os.getenv(\"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\"))\napi.upload_folder(\n    folder_path=\"/kaggle/working/araT5-qg-final\",\n    repo_id=\"NadirFartas/AraT5-V2-QG\",\n    repo_type=\"model\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:12:01.526852Z","iopub.execute_input":"2025-05-04T11:12:01.527229Z","iopub.status.idle":"2025-05-04T11:12:39.784028Z","shell.execute_reply.started":"2025-05-04T11:12:01.527204Z","shell.execute_reply":"2025-05-04T11:12:39.783128Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4432dbea3f8b494ab26ee6d2f07c9749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e927e17c9a7a4ab7a9d12d0ff6b443c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c32cb9df91b4469bd5b20a20988916c"}},"metadata":{}},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/NadirFartas/AraT5-V2-QG/commit/9f71d604950d675857ac06365780e4cd7ece72e0', commit_message='Upload folder using huggingface_hub', commit_description='', oid='9f71d604950d675857ac06365780e4cd7ece72e0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NadirFartas/AraT5-V2-QG', endpoint='https://huggingface.co', repo_type='model', repo_id='NadirFartas/AraT5-V2-QG'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"!git push origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:09:52.056753Z","iopub.execute_input":"2025-05-04T11:09:52.057518Z","iopub.status.idle":"2025-05-04T11:09:52.476115Z","shell.execute_reply.started":"2025-05-04T11:09:52.057487Z","shell.execute_reply":"2025-05-04T11:09:52.475134Z"}},"outputs":[{"name":"stdout","text":"To https://huggingface.co/NadirFartas/AraT5-V2-QG\n \u001b[31m! [rejected]       \u001b[m main -> main (non-fast-forward)\n\u001b[31merror: failed to push some refs to 'https://huggingface.co/NadirFartas/AraT5-V2-QG'\n\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"print(ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:14:53.583005Z","iopub.execute_input":"2025-05-04T11:14:53.583382Z","iopub.status.idle":"2025-05-04T11:14:53.588200Z","shell.execute_reply.started":"2025-05-04T11:14:53.583357Z","shell.execute_reply":"2025-05-04T11:14:53.587313Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['version', 'data'],\n        num_rows: 1\n    })\n    validation: Dataset({\n        features: ['version', 'data'],\n        num_rows: 1\n    })\n    test: Dataset({\n        features: ['version', 'data'],\n        num_rows: 1\n    })\n})\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"# Testing the Model with both 3 epochs and 10 epochs","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom datasets import load_dataset\nimport json\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"NadirFartas/AraT5-V2-QG\")\ntokenizer = AutoTokenizer.from_pretrained(\"NadirFartas/AraT5-V2-QG\")\nmodel2 = AutoModelForSeq2SeqLM.from_pretrained(\"NadirFartas/AraT5_V2_10epoch\")\ntokenizer2 = AutoTokenizer.from_pretrained(\"NadirFartas/AraT5_V2_10epoch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:04:24.148342Z","iopub.execute_input":"2025-05-05T00:04:24.148602Z","iopub.status.idle":"2025-05-05T00:05:55.502478Z","shell.execute_reply.started":"2025-05-05T00:04:24.148584Z","shell.execute_reply":"2025-05-05T00:05:55.501585Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd3879b01a14d44ac3208b85618f7f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2560126ec24c0592fc3dd9e6b6d78a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2dff5797216412baf317745e587041e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12dd268b2f594fabab66128cd2691c9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f08e6e058c784f6a89d0af4640c57d6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3c9543bd8a41c4b3f7dcc28aed09db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea89ef5c75454a21b12e665bad34e9bf"}},"metadata":{}},{"name":"stderr","text":"2025-05-05 00:04:46.927477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746403487.213894      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746403487.286946      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c727ef83fb94be8999f81db877aee1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1bbc5ecc064f62b7f6c8b300c201da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3111395f5d964be5821792c17bf246b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05560cfd94fd4e449d57bd1591de8057"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"726450131ea84d0ebd3fe58d02124d48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f72d756a6794bf0a56d9af625ec2cd4"}},"metadata":{}},{"name":"stderr","text":"You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e360e141aa4346288c336b0ca270d3c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52991b3e813645799115f6c2233c2edd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d4c50725304791bf79d868888ed474"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac3241f36fc0428c8fd4b22b45d8fb6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e6e1f6c7dfb4fafa00bee45f31a73ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1592253547e54524b16fb9aa3e9b37e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ecd99f83244bb2bd4c188ffa39dfe4"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"formatted_test_dataset = format_squad_dataset(ds[\"test\"])\ntest_dataset = flatten_context_qa_pairs(formatted_test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:07:26.826477Z","iopub.execute_input":"2025-05-05T00:07:26.827157Z","iopub.status.idle":"2025-05-05T00:07:27.123388Z","shell.execute_reply.started":"2025-05-05T00:07:26.827131Z","shell.execute_reply":"2025-05-05T00:07:27.122641Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(f\"Total test pairs: {len(test_dataset)}\")\nprint(test_dataset[4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:07:30.029272Z","iopub.execute_input":"2025-05-05T00:07:30.029596Z","iopub.status.idle":"2025-05-05T00:07:30.033915Z","shell.execute_reply.started":"2025-05-05T00:07:30.029574Z","shell.execute_reply":"2025-05-05T00:07:30.033306Z"}},"outputs":[{"name":"stdout","text":"Total test pairs: 9606\n{'input': 'Ø¨Ø­Ù„ÙˆÙ„ 15 Ù…Ø§ÙŠÙˆ ØŒ Ø£Ù…Ø± Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¯ÙˆÙ„Ø© ÙˆÙ† Ø¬ÙŠØ§Ø¨Ø§Ùˆ Ø¨Ù†Ø´Ø± 90 Ø·Ø§Ø¦Ø±Ø© Ù‡Ù„ÙŠÙƒÙˆØ¨ØªØ± Ø¥Ø¶Ø§ÙÙŠØ© ØŒ Ù…Ù†Ù‡Ø§ 60 Ø·Ø§Ø¦Ø±Ø© Ù…Ù‚Ø¯Ù…Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ø§Ù„ØµÙŠÙ†ÙŠ ØŒ Ùˆ 30 Ø·Ø§Ø¦Ø±Ø© Ù…Ù† Ø§Ù„Ù…Ù‚Ø±Ø± Ø£Ù† ØªÙˆÙØ±Ù‡Ø§ ØµÙ†Ø§Ø¹Ø© Ø§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„Ù…Ø¯Ù†ÙŠ ØŒ Ù„ÙŠØµÙ„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ù†Ø´Ø±Ù‡Ø§ ÙÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥ØºØ§Ø«Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø¬ÙˆÙŠØ© ÙˆØ§Ù„Ø¬ÙŠØ´ ÙˆØ§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„Ù…Ø¯Ù†ÙŠ Ø¥Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† 150 ØŒ Ù…Ù…Ø§ Ø£Ø¯Ù‰ Ø¥Ù„Ù‰ Ø£ÙƒØ¨Ø± Ø¹Ù…Ù„ÙŠØ© Ù†Ù‚Ù„ Ø¬ÙˆÙŠ ØºÙŠØ± Ù‚ØªØ§Ù„ÙŠØ© ÙÙŠ ØªØ§Ø±ÙŠØ® Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ .', 'target': 'Ù…Ø§Ø°Ø§ Ø·Ù„Ø¨ Ø±Ø¦ÙŠØ³ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ ÙˆÙ† Ø¬ÙŠØ§Ø¨Ø§Ùˆ ØŸ'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"**Exemple 1**","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef generate_question_from_input(input_text, modelS, tokenizerS, max_length=64):\n    inputs = tokenizerS.encode(input_text, return_tensors=\"pt\", truncation=True).to(modelS.device)\n    outputs = modelS.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)\n    question = tokenizerS.decode(outputs[0], skip_special_tokens=True)\n    return question\n\n# Pick a test example\nsample = test_dataset[3]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text, model, tokenizer)\ngenerated_question2 = generate_question_from_input(input_text, model2, tokenizer2)\n\n# Show results\nprint(\"ğŸ“¥ Input to the model:\\n\", input_text)\nprint(\"\\nâœ… Dataset Question:\\n\", real_question)\nprint(\"\\nğŸ¤– 3 epochs Generated Questions:\\n\", generated_question)\nprint(\"\\nğŸ¤– 10 epochs Generated Questions:\\n\", generated_question2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:11:53.511156Z","iopub.execute_input":"2025-05-05T00:11:53.511484Z","iopub.status.idle":"2025-05-05T00:11:56.494189Z","shell.execute_reply.started":"2025-05-05T00:11:53.511461Z","shell.execute_reply":"2025-05-05T00:11:56.493495Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Input to the model:\n Ø¨Ø­Ù„ÙˆÙ„ 15 Ù…Ø§ÙŠÙˆ ØŒ Ø£Ù…Ø± Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¯ÙˆÙ„Ø© ÙˆÙ† Ø¬ÙŠØ§Ø¨Ø§Ùˆ Ø¨Ù†Ø´Ø± 90 Ø·Ø§Ø¦Ø±Ø© Ù‡Ù„ÙŠÙƒÙˆØ¨ØªØ± Ø¥Ø¶Ø§ÙÙŠØ© ØŒ Ù…Ù†Ù‡Ø§ 60 Ø·Ø§Ø¦Ø±Ø© Ù…Ù‚Ø¯Ù…Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ø§Ù„ØµÙŠÙ†ÙŠ ØŒ Ùˆ 30 Ø·Ø§Ø¦Ø±Ø© Ù…Ù† Ø§Ù„Ù…Ù‚Ø±Ø± Ø£Ù† ØªÙˆÙØ±Ù‡Ø§ ØµÙ†Ø§Ø¹Ø© Ø§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„Ù…Ø¯Ù†ÙŠ ØŒ Ù„ÙŠØµÙ„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ù†Ø´Ø±Ù‡Ø§ ÙÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥ØºØ§Ø«Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø¬ÙˆÙŠØ© ÙˆØ§Ù„Ø¬ÙŠØ´ ÙˆØ§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„Ù…Ø¯Ù†ÙŠ Ø¥Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† 150 ØŒ Ù…Ù…Ø§ Ø£Ø¯Ù‰ Ø¥Ù„Ù‰ Ø£ÙƒØ¨Ø± Ø¹Ù…Ù„ÙŠØ© Ù†Ù‚Ù„ Ø¬ÙˆÙŠ ØºÙŠØ± Ù‚ØªØ§Ù„ÙŠØ© ÙÙŠ ØªØ§Ø±ÙŠØ® Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ .\n\nâœ… Dataset Question:\n ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªÙŠ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ ØŸ\n\nğŸ¤– 3 epochs Generated Questions:\n ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ù†Ø´Ø±Ù‡Ø§ ÙÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥ØºØ§Ø«Ø© ØŸ\n\nğŸ¤– 10 epochs Generated Questions:\n ÙƒÙ… Ø¹Ø¯Ø¯ Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„Ù‡Ù„ÙŠÙƒÙˆØ¨ØªØ± Ø§Ù„ØªÙŠ ØªÙ… Ù†Ø´Ø±Ù‡Ø§ ÙÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥ØºØ§Ø«Ø© ØŸ\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"**Exemple 2**","metadata":{}},{"cell_type":"code","source":"# Pick a test example\nsample = test_dataset[333]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text, model, tokenizer)\ngenerated_question2 = generate_question_from_input(input_text, model2, tokenizer2)\n\n# Show results\nprint(\"ğŸ“¥ Input to the model:\\n\", input_text)\nprint(\"\\nâœ… Dataset Question:\\n\", real_question)\nprint(\"\\nğŸ¤– 3 epochs Generated Questions:\\n\", generated_question)\nprint(\"\\nğŸ¤– 10 epochs Generated Questions:\\n\", generated_question2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:14:29.619412Z","iopub.execute_input":"2025-05-05T00:14:29.619701Z","iopub.status.idle":"2025-05-05T00:14:31.965843Z","shell.execute_reply.started":"2025-05-05T00:14:29.619680Z","shell.execute_reply":"2025-05-05T00:14:31.965044Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Input to the model:\n ØªØ¹ØªÙ…Ø¯ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„ØµØ§ÙÙŠØ© Ù„Ø§Ù†Ø¹ÙƒØ§Ø³ Ø§Ù„Ø£Ø±Ø¶ Ø¹Ù„Ù‰ ØªØ¶Ø§Ø±ÙŠØ³ Ø§Ù„Ø³Ø·Ø­ . Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ù…Ø®Ø§Ù„ÙØ§Øª Ø§Ù„Ø³Ø·Ø­ Ø£ØµØºØ± Ø¨ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙŠ ØŒ ÙÙ†Ø­Ù† ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³ Ø§Ù„Ù…Ù†Ø¸Ø§Ø±ÙŠ ØŒ ÙˆÙŠØ±Ù‰ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ ÙƒÙ„Ø§ Ù…Ù† Ø§Ù„Ù‡ÙˆØ§Ø¦ÙŠ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ ÙˆØµÙˆØ±Ø© Ù„Ù„Ù‡ÙˆØ§Ø¦ÙŠ ØªØ­Øª Ø§Ù„Ø£Ø±Ø¶ Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³ . ÙˆÙ„ÙƒÙ† Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø£Ø±Ø¶ Ø¨Ù‡Ø§ Ù…Ø®Ø§Ù„ÙØ§Øª Ù„ÙŠØ³Øª ØµØºÙŠØ±Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙŠ ØŒ ÙÙ„Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³Ø§Øª Ù…ØªÙ…Ø§Ø³ÙƒØ© ÙˆÙ„ÙƒÙ†Ù‡Ø§ Ø³ØªØªØ­ÙˆÙ„ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ù…Ø±Ø§Ø­Ù„ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© . Ù…Ø¹ Ø§Ù„Ø£Ø·ÙˆØ§Ù„ Ø§Ù„Ù…ÙˆØ¬ÙŠØ© Ø§Ù„Ø£Ù‚ØµØ± ( Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª Ø§Ù„Ø£Ø¹Ù„Ù‰ ) ØŒ Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… .\n\nâœ… Dataset Question:\n Ù…Ø§ Ù‡Ùˆ Ø³Ø¨Ø¨ Ø±Ø¤ÙŠØ© Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ Ù„ÙƒÙ„ Ù…Ù† Ù‡ÙˆØ§Ø¦ÙŠ Ø§Ù„Ø±ÙØ¹ ÙˆØµÙˆØ±Ø© Ø§Ù„Ù‡ÙˆØ§Ø¦ÙŠ ØŸ\n\nğŸ¤– 3 epochs Generated Questions:\n Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ØªØ¶Ø§Ø±ÙŠØ³ Ø§Ù„Ø³Ø·Ø­ ØŸ\n\nğŸ¤– 10 epochs Generated Questions:\n Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„ØµØ§ÙÙŠØ© Ù„Ø§Ù†Ø¹ÙƒØ§Ø³ Ø§Ù„Ø£Ø±Ø¶ ØŸ\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Pick a test example\nsample = test_dataset[65]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text, model, tokenizer)\ngenerated_question2 = generate_question_from_input(input_text, model2, tokenizer2)\n\n# Show results\nprint(\"ğŸ“¥ Input to the model:\\n\", input_text)\nprint(\"\\nâœ… Dataset Question:\\n\", real_question)\nprint(\"\\nğŸ¤– 3 epochs Generated Questions:\\n\", generated_question)\nprint(\"\\nğŸ¤– 10 epochs Generated Questions:\\n\", generated_question2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:15:18.921374Z","iopub.execute_input":"2025-05-05T00:15:18.922054Z","iopub.status.idle":"2025-05-05T00:15:22.846817Z","shell.execute_reply.started":"2025-05-05T00:15:18.922031Z","shell.execute_reply":"2025-05-05T00:15:22.846023Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Input to the model:\n ÙˆÙÙŠ Ø£Ø¹Ù‚Ø§Ø¨ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„ØªÙŠ ÙˆÙ‚Ø¹Øª ÙÙŠ Ø£ÙˆÙ„Ù…Ø¨ÙŠØ§ ØŒ ÙˆØ±Ø¯Øª ØªÙ‚Ø§Ø±ÙŠØ± ØªÙÙŠØ¯ Ø¨Ø£Ù† Ø§Ù„ØµÙŠÙ† Ø·Ù„Ø¨Øª Ø§Ù„Ø¥Ø°Ù† Ø¨Ù†Ø´Ø± Ø£ÙØ±Ø§Ø¯ Ù…Ù† Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ø§Ù„ØµÙŠÙ†ÙŠ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø·Ø±ÙŠÙ‚ Ø§Ù„ØªØªØ§Ø¨Ø¹ Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø´Ø¹Ù„Ø© ÙÙŠ ÙƒØ§Ù†Ø¨ÙŠØ±Ø§ . ÙˆØ°ÙƒØ±Øª Ø§Ù„Ø³Ù„Ø·Ø§Øª Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠØ© Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø·Ù„Ø¨ ØŒ Ø¥Ø°Ø§ Ù…Ø§ Ù‚Ø¯Ù… ØŒ Ø³ÙŠØ±ÙØ¶ . ÙˆÙˆØµÙ Ù…Ø³Ø¤ÙˆÙ„ÙˆÙ† ØµÙŠÙ†ÙŠÙˆÙ† Ø§Ù„Ø£Ù…Ø± Ø¨Ø£Ù†Ù‡ Ø´Ø§Ø¦Ø¹Ø© . Ù…Ù†Ø­Øª Ø§Ù„Ø´Ø±Ø·Ø© Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠØ© ØµÙ„Ø§Ø­ÙŠØ§Øª ØªÙØªÙŠØ´ Ø§Ù„Ù…ØªÙØ±Ø¬ÙŠÙ† ÙÙŠ Ø§Ù„ØªØªØ§Ø¨Ø¹ ØŒ Ø¨Ø¹Ø¯ Ø¯Ø¹ÙˆØ© Ø£Ø·Ù„Ù‚ØªÙ‡Ø§ Ø±Ø§Ø¨Ø·Ø© Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØ§Ù„Ø¹Ù„Ù…Ø§Ø¡ Ø§Ù„ØµÙŠÙ†ÙŠÙŠÙ† Ù„Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„ØµÙŠÙ†ÙŠÙŠÙ† Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠÙŠÙ† Ø¥Ù„Ù‰ \" Ø§Ù„Ø¯ÙØ§Ø¹ Ø¹Ù† Ø´Ø¹Ù„ØªÙ†Ø§ Ø§Ù„Ù…Ù‚Ø¯Ø³Ø© \" Ø¶Ø¯ \" Ø­Ø«Ø§Ù„Ø© Ø¹Ø±Ù‚ÙŠØ© Ù…Ù†Ø­Ø·Ø© ÙˆØ§Ù†ÙØµØ§Ù„ÙŠÙŠÙ† Ù…Ù†Ø§Ù‡Ø¶ÙŠÙ† Ù„Ù„ØµÙŠÙ† \" . ÙˆÙ‚Ø§Ù„ ØªÙˆÙ†ÙŠ Ø¬ÙˆÙ‡ ØŒ Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠ Ù„Ù„Ù…Ù†Ø¸Ù…Ø§Øª Ø§Ù„ØµÙŠÙ†ÙŠØ© ØŒ Ø¥Ù† Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ø³ØªØ£Ø®Ø° \" Ø§Ù„Ø¢Ù„Ø§Ù \" Ù…Ù† Ø§Ù„Ù…ØªØ¸Ø§Ù‡Ø±ÙŠÙ† Ø§Ù„Ù…Ø¤ÙŠØ¯ÙŠÙ† Ù„Ø¨ÙƒÙŠÙ† Ø¥Ù„Ù‰ ÙƒØ§Ù†Ø¨ÙŠØ±Ø§ Ø¨Ø§Ù„Ø­Ø§ÙÙ„Ø© ØŒ Ù„Ø¯Ø¹Ù… ØªØªØ§Ø¨Ø¹ Ø§Ù„Ø´Ø¹Ù„Ø© . ÙˆÙ‚Ø§Ù„ ØªØ´Ø§Ù†Øº Ø±ÙˆÙ†ØºØ§Ù† ØŒ ÙˆÙ‡Ùˆ Ø·Ø§Ù„Ø¨ Ø£Ø³ØªØ±Ø§Ù„ÙŠ ØµÙŠÙ†ÙŠ ÙŠÙ†Ø¸Ù… Ù…Ø¸Ø§Ù‡Ø±Ø§Øª Ù…Ø¤ÙŠØ¯Ø© Ù„Ø¨ÙƒÙŠÙ† ØŒ Ù„Ù„ØµØ­Ø§ÙØ© Ø¥Ù† Ø¯Ø¨Ù„ÙˆÙ…Ø§Ø³ÙŠÙŠÙ† ØµÙŠÙ†ÙŠÙŠÙ† ÙŠØ³Ø§Ø¹Ø¯ÙˆÙ† ÙÙŠ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø­Ø§ÙÙ„Ø§Øª ÙˆØ§Ù„ÙˆØ¬Ø¨Ø§Øª ÙˆØ§Ù„Ø¥Ù‚Ø§Ù…Ø© Ù„Ù„Ù…ØªØ¸Ø§Ù‡Ø±ÙŠÙ† Ø§Ù„Ù…Ø¤ÙŠØ¯ÙŠÙ† Ù„Ø¨ÙƒÙŠÙ† ØŒ ÙˆÙŠØ³Ø§Ø¹Ø¯ÙˆÙ†Ù‡Ù… Ø¹Ù„Ù‰ ØªÙ†Ø¸ÙŠÙ… \" Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø³Ù„Ù…ÙŠ Ù„Ù„Ù‚ÙˆØ© \" . ÙˆÙ‚Ø§Ù„ ÙˆØ²ÙŠØ± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø³ØªÙŠÙÙ† Ø³Ù…ÙŠØ« Ø¥Ù† Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠÙ† Ø§Ù„ØµÙŠÙ†ÙŠÙŠÙ† ÙŠØ­Ø«ÙˆÙ† Ø£Ù†ØµØ§Ø±Ù‡Ù… Ø¹Ù„Ù‰ \" Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ·Ø±Ø­ ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± \" Ù„ÙƒÙ†Ù‡ Ù„ÙŠØ³ Ù„Ø¯ÙŠÙ‡ Ø§Ø¹ØªØ±Ø§Ø¶ Ø¹Ù„Ù‰ Ø°Ù„Ùƒ Ø·Ø§Ù„Ù…Ø§ Ø¸Ù„ÙˆØ§ Ø³Ù„Ù…ÙŠÙŠÙ† .\n\nâœ… Dataset Question:\n Ù…Ù† Ù‡Ùˆ ÙˆØ²ÙŠØ± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø§Ù„Ø°ÙŠ Ù‚Ø§Ù„ Ø¥Ù†Ù‡ Ù…ÙˆØ§ÙÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø­ØªØ¬Ø§Ø¬Ø§Øª Ø·Ø§Ù„Ù…Ø§ ÙƒØ§Ù†Øª Ø³Ù„Ù…ÙŠØ© ØŸ\n\nğŸ¤– 3 epochs Generated Questions:\n Ù…Ù† Ø§Ù„Ø°ÙŠ Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø°Ù† Ø¨Ù†Ø´Ø± Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ø§Ù„ØµÙŠÙ†ÙŠ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø·Ø±ÙŠÙ‚ Ø§Ù„ØªØªØ§Ø¨Ø¹ ØŸ\n\nğŸ¤– 10 epochs Generated Questions:\n Ù…Ù† Ù‡Ùˆ Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠ Ù„Ù„Ù…Ù†Ø¸Ù…Ø§Øª Ø§Ù„ØµÙŠÙ†ÙŠØ© ØŸ\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Pick a test example\nsample = data[65]\ninput_text = sample[\"context\"]\nreal_question = sample[\"question\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text, model, tokenizer)\ngenerated_question2 = generate_question_from_input(input_text, model2, tokenizer2)\n\n# Show results\nprint(\"ğŸ“¥ Input to the model:\\n\", input_text)\nprint(\"\\nâœ… Dataset Question:\\n\", real_question)\nprint(\"\\nğŸ¤– 3 epochs Generated Questions:\\n\", generated_question)\nprint(\"\\nğŸ¤– 10 epochs Generated Questions:\\n\", generated_question2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:18:15.748637Z","iopub.execute_input":"2025-05-05T00:18:15.749110Z","iopub.status.idle":"2025-05-05T00:18:20.705595Z","shell.execute_reply.started":"2025-05-05T00:18:15.749086Z","shell.execute_reply":"2025-05-05T00:18:20.704842Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Input to the model:\n ÙŠØ­ÙƒÙ‰ Ø£Ù† Ø¨Ù„Ø¯Ø§ ÙŠØ­ÙƒÙ…Ù‡ Ù…Ù„Ùƒ Ù„Ø§ ÙŠØ­Ø¨ ÙÙŠ Ø§Ù„Ø¯Ù†ÙŠØ§ Ø´ÙŠØ¡ ÙƒÙ…Ø§ ÙŠØ­Ø¨ Ø§Ù„Ù…Ù„Ø§Ø¨Ø³ ÙˆØ§Ù„Ø§Ø¹ØªÙ†Ø§Ø¡ Ø¨Ù…Ø¸Ù‡Ø±Ù‡, ÙÙƒØ§Ù† ÙŠÙ‚Ø¶ÙŠ Ø§Ù„Ø³Ø§Ø¹Ø§Øª ÙÙŠ Ø´Ø±Ø§Ø¡ ÙˆØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ù„Ø§Ø¨Ø³ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø¨Ù…Ø´Ø§ØºÙ„ Ø´Ø¹Ø¨Ù‡, ÙˆÙƒØ§Ù† ÙŠØ¨Ø°Ù„ Ø§Ù„Ù…Ø§Ù„ Ø§Ù„ÙƒØ«ÙŠØ± Ù„Ù„Ø®ÙŠØ§Ø·ÙŠÙ† ÙÙŠ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø«ÙŠØ§Ø¨ Ø¬Ø¯ÙŠØ¯Ø© ÙˆÙ…Ù…ÙŠØ²Ø©, ÙˆÙÙŠ ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… Ù‚Ø¯Ù… Ø®ÙŠØ§Ø· Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ùƒ ÙŠØ¯Ø¹ÙŠ Ø£Ù†Ù‡ ÙŠØ³ØªØ·ÙŠØ¹ Ø®ÙŠØ§Ø·Ø© Ø«ÙŠØ§Ø¨ Ø³Ø­Ø±ÙŠØ©, Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒ ÙŠØ§ Ø³ÙŠØ¯ÙŠØŒ Ø£Ù†Ø§ Ø®ÙŠØ§Ø· Ù…ØªØ¬ÙˆÙ„ Ù…Ø®ØªØµ ÙÙŠ Ø®ÙŠØ§Ø·Ø© Ø§Ù„Ø«ÙŠØ§Ø¨ Ø§Ù„Ø³Ø­Ø±ÙŠØ© ÙÙ‚Ø§Ù„ Ø§Ù„Ù…Ù„Ùƒ Ù…ØªØ¹Ø¬Ø¨Ø§: ÙˆÙ…Ø§ Ø§Ù„Ø³Ø­Ø± Ø§Ù„Ø°ÙŠ ÙŠÙ…ÙŠØ² Ø«ÙŠØ§Ø¨Ùƒ Ø¹Ù† Ø¨Ù‚ÙŠØ© Ø§Ù„Ø«ÙŠØ§Ø¨ØŸ Ù…Ù„Ø§Ø¨Ø³ÙŠ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø±Ø¤ÙŠØªÙ‡Ø§ ÙˆØ§Ù„ØªÙ…ØªØ¹ Ø¨Ø¬Ù…Ø§Ù„Ù‡Ø§ Ø¥Ù„Ø§ Ù…Ù† Ø·Ø±Ù Ø§Ù„Ø£Ø°ÙƒÙŠØ§Ø¡ØŒ Ø£Ù…Ø§ Ø§Ù„Ø£ØºØ¨ÙŠØ§Ø¡ ÙÙ„Ø§ ÙŠÙ…ÙƒÙ†Ù‡Ù… Ù…Ø´Ø§Ù‡Ø¯ØªÙ‡Ø§ ÙˆÙ…Ø§ Ø§Ù„Ø°ÙŠ ØªØ­ØªØ§Ø¬ Ø£Ù„ÙŠÙ‡ Ù„ØªØµÙ†Ø¹ Ù„Ù†Ø§ Ù‡ÙƒØ°Ø§ Ø«ÙˆØ¨Ø§ØŸ Ø£Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø°Ù‡Ø¨ Ù„Ø£ØµÙ†Ø¹ Ù…Ù†Ù‡ Ø§Ù„Ø®ÙŠÙˆØ· Ø§Ù„ØªÙŠ Ø³Ø£Ø³ØªØ¹Ù…Ù„Ù‡Ø§ ÙÙŠ Ù†Ø³ÙŠØ¬ Ø§Ù„Ù‚Ù…Ø§Ø´ ÙˆØ®ÙŠØ§Ø·Ø© Ø§Ù„Ø«ÙŠØ§Ø¨, ÙØ£Ù…Ø± Ù„Ù‡ Ø§Ù„Ù…Ù„Ùƒ Ø¨ØºØ±ÙØ© ÙÙŠ Ø§Ù„Ù‚ØµØ± ÙˆØªÙˆÙÙŠØ± ÙƒÙ„ Ù…Ø§ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„ÙŠÙ‡ Ù…Ù† Ø°Ù‡Ø¨, ÙˆØ¨Ø¹Ø¯ Ø£ÙŠØ§Ù…ØŒ Ù‚Ø¯Ù… Ø§Ù„Ø®ÙŠØ§Ø· Ø¨Ø§Ù„Ø«ÙˆØ¨ Ø­ØªÙ‰ ÙŠÙ‚ÙŠØ³Ù‡ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ùƒ Ø§Ù„Ø°ÙŠ Ù„Ù… ÙŠØ³ØªØ·Ø¹ Ø±Ø¤ÙŠØ© Ø§Ù„Ø«ÙˆØ¨ Ø¹Ù„Ù‰ Ø¨Ø¯Ù†Ù‡ Ø¹Ù†Ø¯Ù…Ø§ Ù†Ø¸Ø± ÙÙŠ Ø§Ù„Ù…Ø±Ø¢Ø© ÙÙ„Ù… ÙŠÙ‚Ù„ Ø´ÙŠØ¡ Ø­ØªÙ‰ Ù„Ø§ ÙŠÙ‚Ø§Ù„ Ø¥Ù†Ù‡ ØºØ¨ÙŠ ÙˆÙƒØ°Ù„Ùƒ ÙØ¹Ù„ Ø­Ø§Ø´ÙŠØªÙ‡ Ø§Ù„Ø°ÙŠÙ† ØªØ¸Ø§Ù‡Ø±ÙˆØ§ Ø¨Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø¨ Ø¨Ø§Ù„Ø«ÙˆØ¨ ÙˆÙ‚Ø±Ø± Ø§Ù„Ù…Ù„Ùƒ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø¬ÙˆÙ„Ø© ÙÙŠ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ù…Ø±ØªØ¯ÙŠØ§ Ø§Ù„Ø«ÙˆØ¨ Ø§Ù„Ø³Ø­Ø±ÙŠ Ø­ØªÙ‰ ÙŠØªØ¨Ø§Ù‡Ù‰ Ø¨Ù‡ Ø£Ù…Ø§Ù… Ø´Ø¹Ø¨Ù‡. ÙˆÙÙŠ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ù…ÙˆØ¹ÙˆØ¯ Ø®Ø±Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø§Ø³ Ø§Ù„Ø°ÙŠÙ† Ù„Ù… ÙŠØ±Ùˆ Ø§Ù„Ø§ Ù…Ù„ÙƒØ§ Ø¹Ø§Ø±ÙŠØ§ ÙŠÙ…Ø´ÙŠ ÙÙŠ ØºØ±ÙˆØ± ÙˆØ³Ø· Ø­Ø§Ø´ÙŠØªÙ‡ ÙˆÙ„ÙƒÙ† Ø§Ù„Ø¬Ù…ÙŠØ¹ ØªØ¸Ø§Ù‡Ø± Ø¨Ø±Ø¤ÙŠØ© Ø§Ù„Ø«ÙˆØ¨ Ø­ØªÙ‰ Ù„Ø§ ÙŠÙ‚Ø§Ù„ Ø§Ù†Ù‡Ù… Ø§ØºØ¨ÙŠØ§Ø¡ Ø¥Ù„Ø§Ù‘ Ø·ÙÙ„Ø§ Ø¨Ø±ÙŠØ¦Ø§ ØµØ§Ø­ ÙˆØ³Ø· Ø§Ù„Ø¬Ù…ÙŠØ¹ Ù‚Ø§Ø¦Ù„Ø§ Ø¥Ù† Ø§Ù„Ù…Ù„Ùƒ Ø¹Ø§Ø± Ù„Ø§ ÙŠØ±ØªØ¯ÙŠ Ø£ÙŠ Ø«ÙŠØ§Ø¨, ÙØ£Ø®Ø° Ø§Ù„Ø¬Ù…ÙŠØ¹ ÙŠÙ‚ÙˆÙ„ ÙˆÙ‡Ù… ÙŠØ¶Ø­ÙƒÙˆÙ† Ù†Ø¹Ù… Ø¥Ù† Ø§Ù„Ù…Ù„Ùƒ Ù„Ø§ ÙŠØ±ØªØ¯ÙŠ Ø¥Ù„Ø§ Ù…Ù„Ø§Ø¨Ø³Ù‡ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©, ÙˆÙ‡ÙƒØ°Ø§ Ø¹Ø§Ø¯ Ø§Ù„Ù…Ù„Ùƒ Ø¥Ù„Ù‰ Ù‚ØµØ±Ù‡ Ø¨Ø³Ø±Ø¹Ø© Ù…Ø­Ø±Ø¬Ø§ Ø®Ø¬Ù„Ø§ Ù…Ù† Ù†ÙØ³Ù‡ Ø¨Ø¹Ø¯ Ø£Ù† Ø£ØµØ¨Ø­ Ø§Ø¶Ø­ÙˆÙƒØ© Ø¨ÙŠÙ† Ø§Ù„Ù†Ø§Ø³, ÙˆØªØ¹Ù„Ù… Ø£Ù† ÙŠÙ‚Ù„Ù„ Ù…Ù† Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø¹Ù„Ù‰ Ø§Ù„Ø«ÙŠØ§Ø¨ ÙˆØ§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø¨Ù…Ø¸Ù‡Ø±Ù‡ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨ÙˆØ§Ø¬Ø¨Ø§ØªÙ‡.\n\nâœ… Dataset Question:\n Ù…Ø§Ø°Ø§ Ø­Ø¯Ø« Ù„Ù„Ù…Ù„Ùƒ Ù„Ù…Ø§ Ù‚Ø±Ø± Ø§Ù† ÙŠØªØ¨Ø§Ù‡Ù‰ Ø§Ù…Ø§Ù… Ø´Ø¹Ø¨Ù‡ØŸ\n\nğŸ¤– 3 epochs Generated Questions:\n ÙÙŠ Ø£ÙŠ ÙŠÙˆÙ… Ø®Ø±Ø¬ Ø§Ù„Ù…Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø§Ø³ Ù…Ø±ØªØ¯ÙŠØ§ Ø§Ù„Ø«ÙˆØ¨ Ø§Ù„Ø³Ø­Ø±ÙŠ Ø­ØªÙ‰ ÙŠØªØ¨Ø§Ù‡Ù‰ Ø¨Ù‡ Ø£Ù…Ø§Ù… Ø´Ø¹Ø¨Ù‡ ØŸ\n\nğŸ¤– 10 epochs Generated Questions:\n Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ùƒ ÙŠØ­Ø§ÙˆÙ„ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø¨Ù…Ø´Ø§ØºÙ„ Ø´Ø¹Ø¨Ù‡ ØŸ\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\n\n# Load XML\ntree = ET.parse('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml')  \nroot = tree.getroot()\n\n# Print tag names of the first few elements\nfor child in root.iter():\n    print(child.tag)\n    break  # remove this break to see more tags if needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:16:14.419278Z","iopub.execute_input":"2025-05-05T00:16:14.419578Z","iopub.status.idle":"2025-05-05T00:16:14.585000Z","shell.execute_reply.started":"2025-05-05T00:16:14.419558Z","shell.execute_reply":"2025-05-05T00:16:14.584252Z"}},"outputs":[{"name":"stdout","text":"corpus\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"with open('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml', 'r', encoding='utf-8') as f:\n    for _ in range(20):\n        print(f.readline().strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:16:19.284835Z","iopub.execute_input":"2025-05-05T00:16:19.285443Z","iopub.status.idle":"2025-05-05T00:16:19.290023Z","shell.execute_reply.started":"2025-05-05T00:16:19.285420Z","shell.execute_reply":"2025-05-05T00:16:19.289412Z"}},"outputs":[{"name":"stdout","text":"<?xml version='1.0' encoding='utf-8'?>\n<corpus><texte id=\"0\"><titre>Ø§Ù„Ø£Ø³Ø¯ ÙˆØ§Ù„ÙØ£Ø±\n</titre><body>\nÙˆØ³Ø· ØºØ§Ø¨Ø© ÙƒØ¨ÙŠØ±Ø© ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ\nØ§Ù„Ø§Ø³Ø¯ Ù…Ù„Ùƒ Ø§Ù„ØºØ§Ø¨Ø© Ù†Ø§Ø¦Ù…Ø§ ØªØ­Øª\nØ¸Ù„ Ø´Ø¬Ø±Ø© ÙˆÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙØ£Ø±\nØµØºÙŠØ± ÙŠÙ„Ø¹Ø¨ ÙÙŠ Ø§Ù„Ø¬ÙˆØ§Ø±Ø«Ù… Ù„Ø§Ø­Ø¸\nØ£Ù† Ø§Ù„Ù…Ù„Ùƒ Ù†Ø§Ø¦Ù… Ù„Ø°Ù„Ùƒ Ù‚Ø±Ø± Ø£Ù† ÙŠÙ„Ø¹Ø¨ Ù‚Ù„ÙŠÙ„Ø§ ØµØ¹Ø¯ Ø¹Ù„Ù‰ Ø¸Ù‡Ø±Ù‡\nÙˆØ¨Ø¯Ø£ ÙŠØªØ²Ø­Ù„Ù‚ Ø¹Ø¨Ø± Ø°ÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø³ÙÙ„ Ø£Ø¹Ø§Ø¯Ù‡Ø§ Ù…Ø±Ø© ÙˆØ§Ø«Ù†ØªØ§Ù† ÙˆØ«Ù„Ø§Ø« Ø§Ø³ØªÙ…ØªØ¹ Ø§Ù„ÙØ£Ø± Ø¨Ø§Ù„Ø£Ù…Ø±ØŒ Ø§Ù†Ø²Ø¹Ø¬ Ø§Ù„Ø£Ø³Ø¯ ÙˆØ§Ø³ØªÙŠÙ‚Ø¸ Ø«Ù…\nØ£Ù…Ø³Ùƒ Ø¨Ø§Ù„ÙØ£Ø± Ø§Ù„ØµØºÙŠØ±Ø£Ø±Ø§Ø¯ Ø£ÙƒÙ„Ù‡ Ø§Ø³ØªÙˆÙ‚ÙÙ‡ Ø§Ù„ÙØ£Ø± Ø§Ù„ØµØºÙŠØ± Ø¨Ø§ÙƒÙŠØ§ ÙŠØªØ±Ø¬Ø§Ù‡ Ù„ÙƒÙŠ Ù„Ø§ÙŠÙƒÙˆÙ†\nÙˆØ¬Ø¨Ø© Ø®ÙÙŠÙØ© Ù„Ù‡ ØªØ±Ø¬Ø§Ù‡ Ø§Ù„ÙØ£Ø± ÙˆÙˆØ¹Ø¯Ù‡ Ø¨Ø£Ù† Ù„Ø§ÙŠØ²Ø¹Ø¬Ù‡ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰\nØ¨Ù„ Ù„Ø±Ø¨Ù…Ø§ ÙŠØ­ØªØ§Ø¬Ù‡ ÙÙŠ ÙˆÙ‚Øª Ù…Ù† Ø§Ù„Ø£ÙˆÙ‚Ø§Øª ØªØ£Ø«Ø± Ø§Ù„Ø£Ø³Ø¯ Ø¨Ù…Ø§ Ø³Ù…Ø¹Ù‡ Ø«Ù… ØªØ±Ùƒ Ø§Ù„ÙØ£Ø± ÙŠØ±Ø­Ù„ ÙˆØ¨Ø¹Ø¯ Ø¨Ø¶Ø¹Ø© Ø£ÙŠØ§Ù… ÙˆÙƒÙƒÙ„ ÙŠÙˆÙ…\nÙ…Ù„Ùƒ Ø§Ù„ØºØ§Ø¨Ø© ÙŠØ£Ø®Ø° Ù‚ÙŠÙ„ÙˆÙ„ØªÙ‡ Ø¥Ø° Ø¨Ø§Ù„ØµÙŠØ§Ø¯ÙŠ ÙŠÙ„Ù‚ÙŠ Ø´Ø¨ÙƒØªÙ‡ Ø¹Ù„ÙŠÙ‡ Ù„ÙŠÙ…Ø³Ùƒ Ø¨Ù‡ ÙØ¹Ù„Ø§ Ù‚Ø¯ ÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„ÙØ®\nØ¨Ø¯Ø£ Ø§Ù„Ø£Ø³Ø¯ Ø¨Ø§Ù„Ø²Ø¦ÙŠØ± Ù„ÙŠØ³Ù…Ø¹Ù‡ ÙƒÙ„ Ù…Ù† ÙÙŠ Ø§Ù„ØºØ§Ø¨Ø© Ø­ØªÙ‰ Ø§Ù„ÙØ£Ø± Ø§Ù„ØµØºÙŠØ± Ø³Ù…Ø¹ Ø²Ø¦ÙŠØ±Ù‡ Ù„ÙŠØªØ°ÙƒØ± Ø£Ù†Ù‡\nÙ…Ø¯ÙŠÙ† Ù„Ù„Ø£Ø³Ø¯ ÙˆØ¹Ù„ÙŠÙ‡ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©ÙˆØ£Ù† ÙŠØ±Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙˆÙ Ø¨Ù…Ø«Ù„Ù‡ Ù„Ù… ÙŠØªØ±Ø¯Ø¯ ØµØ¯ÙŠÙ‚Ù†Ø§\nÙˆØ°Ù‡Ø¨ Ù…Ø³Ø±Ø¹Ø§ Ù„ÙŠØ±Ù‰ Ù…Ø§Ø­ØµÙ„ ÙˆØ¹Ù†Ø¯Ù…Ø§ ÙˆØµÙ„ ÙˆØ¬Ø¯ Ø§Ù„Ø£Ø³Ø¯ ØªØ­Øª Ø§Ù„Ø´Ø¨Ø§Ùƒ\nØªØ³Ù„Ù‚Ù‡Ø§ Ø§Ù„ÙØ£Ø± ÙˆØ¨Ø¯Ø£ Ø¨ØªÙ…Ø²ÙŠÙ‚Ù‡Ø§ Ø¨Ø£Ø³Ù†Ø§Ù†Ù‡ Ø§Ù„Ø­Ø§Ø¯Ø©\nØ­ØªÙ‰ Ù…Ø²Ù‚Ù‡Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ£Ø®ÙŠØ±Ø§ Ø£Ù†Ù‚Ø° Ø§Ù„Ø£Ø³Ø¯ Ù…Ù† Ø§Ù„ÙØ® ÙˆØ±Ø¯ Ù„Ù‡ ØµÙ†ÙŠØ¹Ù‡ ÙˆÙ…Ù† Ø°Ù„Ùƒ Ø§Ù„Ø­ÙŠÙ† ÙˆØ§Ù„Ø£Ø³Ø¯ ØµØ¯ÙŠÙ‚ Ø§Ù„ÙØ£Ø±.\nÙ‡Ù†Ø§Ùƒ Ø£ØµØ¯Ù‚Ø§Ø¡ ÙŠØ¹Ø±ÙÙˆÙ† Ø¹Ù†Ø¯ Ø§Ù„Ø´Ø¯Ø§Ø¦Ø¯ ÙÙ„Ù†ØªÙ…Ø³Ùƒ Ø¨Ù‡Ù….\n</body><questions>\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimport re\n\ndef parse_custom_xml(file_path):\n    tree = ET.parse(file_path)\n    root = tree.getroot()\n\n    data = []\n    for texte in root.findall(\"texte\"):\n        raw_context = texte.find(\"body\").text or \"\"\n        context = re.sub(r'\\s+', ' ', raw_context).strip()\n        questions_block = texte.find(\"questions\").text\n\n        # Check and split questions using dash\n        if questions_block:\n            questions = [q.strip() for q in questions_block.strip().split(\"-\") if q.strip()]\n            for question in questions:\n                data.append({\"context\": context, \"question\": question})\n\n    return data\ndata = parse_custom_xml(\"/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml\")\nprint(f\"Total examples extracted: {len(data)}\")\nprint(data[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:16:21.930608Z","iopub.execute_input":"2025-05-05T00:16:21.931152Z","iopub.status.idle":"2025-05-05T00:16:22.106729Z","shell.execute_reply.started":"2025-05-05T00:16:21.931132Z","shell.execute_reply":"2025-05-05T00:16:22.105929Z"}},"outputs":[{"name":"stdout","text":"Total examples extracted: 1506\n{'context': 'ÙÙŠ ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… ÙˆÙÙŠ Ø£Ø­Ø¯ ØºØ§Ø¨Ø§Øª Ø¥ÙØ±ÙŠÙ‚ÙŠØ§ØŒ Ø¨ÙŠÙ†Ù…Ø§ ÙƒØ§Ù† Ø£Ø­Ø¯ Ø§Ù„ÙÙ‡ÙˆØ¯ ÙŠØªØ¬ÙˆÙ„ Ù‚Ø±Ø¨ Ø¶ÙØ© Ø§Ù„Ù†Ù‡Ø± Ø¨Ø§Ø­Ø«Ø§ Ø¹Ù† ÙØ±ÙŠØ³Ø© ÙŠØ³Ø¯ Ø¨Ù‡Ø§ Ø±Ù…Ù‚Ù‡ØŒ Ù„Ù…Ø­ Ù‚Ø·ÙŠØ¹Ø§ Ù…Ù† Ø§Ù„ØºØ²Ù„Ø§Ù† ÙŠØ±Ø¹Ù‰ Ø§Ù„Ø¹Ø´Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¶ÙØ© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©. ÙÙ‚Ø§Ù„ ÙÙŠ Ù†ÙØ³Ù‡ ÙˆÙ‡Ùˆ ÙŠÙ†Ø¸Ø± Ø¥Ù„ÙŠÙ‡Ø§: \"Ù„ÙŠØªÙ†ÙŠ Ø£Ø¹Ø±Ù Ø§Ù„Ø³Ø¨Ø§Ø­Ø©ØŒ ÙØ£Ø¹Ø¨Ø± Ø§Ù„Ù†Ù‡Ø± ÙˆØ£ÙØªØ±Ø³ ØºØ²Ø§Ù„Ø§ Ø£Ù…Ù„Ø¦ Ø¨Ù‡ Ù…Ø¹Ø¯ØªÙŠ Ø§Ù„Ø®Ø§ÙˆÙŠØ©.\" Ø§Ù„ØªÙØª Ø§Ù„ÙÙ‡Ø¯ ÙŠÙ…Ù†Ø©Ù‹ ÙˆÙŠØ³Ø±Ø©Ù‹ Ø¨Ø§Ø­Ø«Ø§Ù‹ Ø¹Ù† Ø´ÙŠØ¡ ÙŠÙ…ÙƒÙ†Ù‘Ù‡ Ù…Ù† Ø§Ù„Ø¹Ø¨ÙˆØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¶ÙÙ‘Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©ØŒ ÙˆÙ„ÙƒÙ† Ø¯ÙˆÙ† Ø¬Ø¯ÙˆÙ‰ . Ø«Ù… Ù†Ø¸Ø± ÙˆØ³Ø· Ø§Ù„Ù†Ù‡Ø± ÙØ±Ø£Ù‰ ÙØ±Ø³ Ù†Ù‡Ø± ÙŠØ³Ø¨Ø­ ÙÙŠ Ø§Ù„Ù…Ø§Ø¡ ÙˆÙŠØ£ÙƒÙ„ Ù…Ù† Ø§Ù„Ø£Ø¹Ø´Ø§Ø¨ Ø§Ù„ØªÙŠ Ù†Ù…Øª ÙÙŠ Ù‚Ø§Ø¹Ù‡. ÙÙƒØ± Ø§Ù„ÙÙ‡Ø¯ Ù‚Ù„ÙŠÙ„Ø§ Ø«Ù… ØªÙˆØ¬Ù‡ Ø¥Ù„Ù‰ Ø¶ÙØ© Ø§Ù„Ù†Ù‡Ø± ÙˆØ®Ø§Ø·Ø¨ Ø§Ù„ÙØ±Ø³ Ù‚Ø§Ø¦Ù„Ø§: \" Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒ ÙŠØ§ Ø§Ø¨Ù† Ø¹Ù…ÙŠ \" ÙØ£Ø¬Ø§Ø¨ ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙˆÙ‚Ø¯ Ø¨Ø¯Øª Ø¹Ù„ÙŠÙ‡ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¹Ø¬Ø¨: \"ÙˆØ¹Ù„ÙŠÙƒ Ø§Ù„Ø³Ù„Ø§Ù…. ÙƒÙŠÙ ØªÙƒÙˆÙ† Ø§Ø¨Ù† Ø¹Ù…ÙŠ ÙˆØ£Ù†Øª Ù„Ø³Øª Ù…Ù† ÙØµÙŠÙ„ØªÙŠØŸ ÙØ£Ù†Øª ØªÙ…Ù„Ùƒ Ø¬Ø³Ù…Ø§ Ø±Ø´ÙŠÙ‚Ø§ ÙˆÙ…Ø±Ù‚Ø·Ø§ Ø¨ÙŠÙ†Ù…Ø§ Ø¬Ø³Ù…ÙŠ Ù…Ù…ØªÙ„Ø¦ ÙˆØ®Ø§Ù„ Ù…Ù† Ø§Ù„Ø¨Ù‚Ø¹\" ÙØ£Ø¬Ø§Ø¨ Ø§Ù„ÙÙ‡Ø¯ ÙÙŠ Ø®Ø¨Ø«: \" Ø£Ù†Ø§ Ù…Ù† Ø¨Ù„Ø¯ Ø¨Ø¹ÙŠØ¯ Ø­ÙŠØ« ØªÙƒÙˆÙ† Ø£ÙØ±Ø§Ø³ Ø§Ù„Ù†Ù‡Ø± Ù…Ø±Ù‚Ø·Ø© ÙˆÙ†Ø­ÙŠÙ„Ø©.\" ØªØ¸Ø§Ù‡Ø± ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± Ø¨ØªØµØ¯ÙŠÙ‚ ÙƒÙ„Ø§Ù… Ø§Ù„ÙÙ‡Ø¯ Ø«Ù… Ù‚Ø§Ù„: \"Ø­Ø³Ù† ÙŠØ§ Ø§Ø¨Ù† Ø¹Ù…ÙŠ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø®Ø¯Ù…ØªÙƒØŸ\" ÙÙ‚Ø§Ù„ Ø§Ù„ÙÙ‡Ø¯: \"Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø³Ø§Ø¹Ø¯ØªÙŠ ÙˆÙ†Ù‚Ù„ÙŠ Ø¹Ù„Ù‰ Ø¸Ù‡Ø±Ùƒ Ø§Ù„Ù‰ Ø§Ù„Ø¶ÙØ© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‡Ø±ØŸ\" ÙÙƒØ± ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± Ù‚Ù„ÙŠÙ„Ø§ Ø«Ù… ÙˆØ§ÙÙ‚ ÙˆØ­Ù…Ù„ Ø§Ù„ÙÙ‡Ø¯ Ø¹Ù„Ù‰ Ø¶Ù‡Ø±Ù‡ Ù„ÙŠØ¹Ø¨Ø± Ø¨Ù‡ Ø§Ù„Ù†Ù‡Ø±. ÙˆÙÙŠ Ù…Ù†ØªØµÙ Ø§Ù„Ø·Ø±ÙŠÙ‚ ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„Ø³Ø¨Ø§Ø­Ø© Ø«Ù… Ù‚Ø§Ù„: \"Ø¨Ù…Ø§ Ø£Ù†Ùƒ ÙØ±Ø³ Ù†Ù‡Ø± ÙØ¨Ø¥Ù…ÙƒØ§Ù†Ùƒ Ø§Ù„Ø³Ø¨Ø§Ø­Ø© ÙˆØ§Ù„ØºØ·Ø³ Ù…Ø«Ù„ÙŠ. Ø£Ù„ÙŠØ³ ÙƒØ°Ù„ÙƒØŸ\" ÙØ£Ø¬Ø§Ø¨ Ø§Ù„ÙÙ‡Ø¯ Ù…Ø±ØªØ¨ÙƒØ§ : \"Ø¥Ù… Ù… Ù… ... Ø¨Ø§Ù„Ø·Ø¨Ø¹ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø³Ø¨Ø§Ø­Ø©.\" ÙˆØ¨ÙŠÙ†Ù…Ø§ ÙƒØ§Ù† Ø§Ù„ÙÙ‡Ø¯ ÙŠÙ‡Ù…Ù‡Ù… ÙˆÙŠØ¨Ø­Ø« ÙÙŠ Ø±Ø£Ø³Ù‡ Ø¹Ù† ÙƒÙ„Ø§Ù… Ù…Ù‚Ù†Ø¹ØŒ Ø§Ø° Ø¨ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙŠØºØ·Ø³ Ø¨Ù‡ Ø§Ù„Ù‰ Ø§Ø¹Ù…Ø§Ù‚ Ø§Ù„Ù†Ù‡Ø±. ÙÙƒØ§Ù†Øª ØªÙ„Ùƒ Ø§Ù„ØºØ·Ø³Ø© Ø¯Ø±Ø³Ø§ Ù‚Ø§Ø³ÙŠØ§ Ù„Ù„ÙÙ‡Ø¯ Ø§Ù„Ø°ÙŠ Ù†Ø¬Ø§ Ø¨Ø£Ø¹Ø¬ÙˆØ¨Ø© Ù…Ù† Ø§Ù„ØºØ±Ù‚. ÙˆÙ‡ÙƒØ°Ø§ Ù†Ø§Ù„ Ø§Ù„ÙÙ‡Ø¯ Ø§Ù„Ø®Ø¨ÙŠØ« Ø¬Ø²Ø§Ø¡ Ø®Ø¯Ø§Ø¹Ù‡ Ù„ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙˆØ§Ø³ØªØ®ÙØ§ÙÙ‡ Ø¨Ø°ÙƒØ§Ø¦Ù‡.', 'question': 'Ù‡Ù„ Ø§Ù†Ø®Ø¯Ø¹ ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± Ø¨ÙƒØ°Ø¨Ø© Ø§Ù„ÙÙ‡Ø¯ØŸ'}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}