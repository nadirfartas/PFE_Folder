{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11662247,"sourceType":"datasetVersion","datasetId":7318913}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:16:59.957688Z","iopub.execute_input":"2025-05-04T03:16:59.958030Z","iopub.status.idle":"2025-05-04T03:17:00.297046Z","shell.execute_reply.started":"2025-05-04T03:16:59.958002Z","shell.execute_reply":"2025-05-04T03:17:00.296259Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:17:00.298267Z","iopub.execute_input":"2025-05-04T03:17:00.298659Z","iopub.status.idle":"2025-05-04T03:17:10.204569Z","shell.execute_reply.started":"2025-05-04T03:17:00.298635Z","shell.execute_reply":"2025-05-04T03:17:10.203840Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1.1\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!pip install \\\n    datasets \\\n    evaluate \\\n    rouge_score\\\n    loralib \\\n    evaluate \\\n    accelerate \\\n    bitsandbytes \\\n    trl \\\n    peft \\\n    -U --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:17:10.205402Z","iopub.execute_input":"2025-05-04T03:17:10.205588Z","iopub.status.idle":"2025-05-04T03:18:40.006827Z","shell.execute_reply.started":"2025-05-04T03:17:10.205568Z","shell.execute_reply":"2025-05-04T03:18:40.006147Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [bitsandbytes][0m [bitsandbytes]er-cu12]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"def format_squad_dataset(dataset_split):\n    \"\"\"\n    Format a SQuAD-style dataset split into a list of dictionaries \n    with context, questions, and answers.\n\n    Args:\n        dataset_split: a split of the SQuAD-style dataset, e.g., ds[\"train\"] or ds[\"validation\"]\n\n    Returns:\\\n    \n        A list of formatted entries: [{\"context\": ..., \"questions\": [...]}]\n    \"\"\"\n    formatted = []\n\n    for article in dataset_split:\n        for paragraph in article[\"data\"]:\n            for p in paragraph[\"paragraphs\"]:\n                context = p[\"context\"]\n                questions = []\n\n                for qa in p[\"qas\"]:\n\n                    question = qa[\"question\"]\n\n                    questions.append(question)\n\n                if questions:\n                    formatted.append({\n                        \"context\": context,\n                        \"questions\": questions,\n                    })\n                    \n    return formatted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:07:11.070845Z","iopub.execute_input":"2025-05-05T00:07:11.071332Z","iopub.status.idle":"2025-05-05T00:07:11.075858Z","shell.execute_reply.started":"2025-05-05T00:07:11.071298Z","shell.execute_reply":"2025-05-05T00:07:11.075209Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\n\n# Load dataset\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")\nformatted_train_dataset = format_squad_dataset(ds[\"train\"])\nformatted_val_dataset = format_squad_dataset(ds[\"validation\"])\n\nprint(f\"✅ Done. Formatted {len(formatted_train_dataset)} training context blocks.\")\nprint(f\"✅ Done. Formatted {len(formatted_val_dataset)} validation context blocks.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:18:40.015313Z","iopub.execute_input":"2025-05-04T03:18:40.015527Z","iopub.status.idle":"2025-05-04T03:18:49.933034Z","shell.execute_reply.started":"2025-05-04T03:18:40.015513Z","shell.execute_reply":"2025-05-04T03:18:49.932266Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d38619f7cdf8407086df0dd6d5e385d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14dbb1fe2574083b3dc3c653c4ae0a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebbd9ea7f3fd4c6ca27d88a55db47e24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bef115618bbd49479bd1bb6b397f802a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df157078eaf24f90b1267c596b8a1373"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5ac9f773a54204b924e30cbbf2b0b2"}},"metadata":{}},{"name":"stdout","text":"✅ Done. Formatted 18117 training context blocks.\n✅ Done. Formatted 7290 validation context blocks.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"def flatten_context_qa_pairs(formatted_data):\n    \"\"\"\n    Convert formatted context-question-answer data into a flat list of\n    input-target training pairs for seq2seq modeling.\n\n    Args:\n        formatted_data: List of dicts with 'context', 'questions'\n\n    Returns:\n        A list of dicts with 'input' and 'target' fields\n    \"\"\"\n    flat_data = []\n\n    for item in formatted_data:\n        context = item[\"context\"]\n        for question in item[\"questions\"]:\n            input_text = context\n            target_text = question\n            flat_data.append({\"input\": input_text, \"target\": target_text})\n\n    return flat_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:07:07.808902Z","iopub.execute_input":"2025-05-05T00:07:07.809168Z","iopub.status.idle":"2025-05-05T00:07:07.813236Z","shell.execute_reply.started":"2025-05-05T00:07:07.809149Z","shell.execute_reply":"2025-05-05T00:07:07.812677Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_dataset = flatten_context_qa_pairs(formatted_train_dataset)\nval_dataset = flatten_context_qa_pairs(formatted_val_dataset)\nprint(f\"Total training pairs: {len(train_dataset)}\")\nprint(f\"Total validation pairs: {len(val_dataset)}\")\nprint(train_dataset[1])\nprint(val_dataset[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:18:49.939840Z","iopub.execute_input":"2025-05-04T03:18:49.940086Z","iopub.status.idle":"2025-05-04T03:18:50.629450Z","shell.execute_reply.started":"2025-05-04T03:18:49.940071Z","shell.execute_reply":"2025-05-04T03:18:50.628732Z"}},"outputs":[{"name":"stdout","text":"Total training pairs: 76840\nTotal validation pairs: 9605\n{'input': '( لم يكن زلزال Ms 6 . 1 في 30 أغسطس 2008 في جنوب سيتشوان جزءا من هذه السلسلة لأنه كان ناجما عن صدع مختلف . انظر زلزال بانتشيهوا 2008 للحصول على التفاصيل . )', 'target': 'أين يجب أن تبحث عن مزيد من التفاصيل ؟'}\n{'input': 'غادر فريق الإغاثة الطارئة من الزلازل المكون من 184 شخصا ( يتألف من 12 شخصا من مكتب الدولة لرصد الزلازل و 150 من قيادة منطقة بكين العسكرية و 22 من مستشفى الشرطة العامة المسلحة ) بكين من مطار نانيوان في أواخر 12 مايو في طائرتي نقل عسكريتين للسفر إلى مقاطعة ونتشوان .', 'target': 'كم عدد الأشخاص الذين شكلوا فريق الإغاثة ؟'}\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from transformers import T5Tokenizer, AutoModelForSeq2SeqLM\nfrom datasets import Dataset\n\n# Load tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\", legacy=False)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\")\n# Convert list to Hugging Face Dataset\nhf_train_dataset = Dataset.from_list(train_dataset)\nhf_val_dataset = Dataset.from_list(val_dataset)\n\n# Tokenize function\ndef tokenize(example):\n    model_input = tokenizer(\n        example[\"input\"], \n        max_length=512, \n        padding=\"max_length\", \n        truncation=True\n    )\n    labels = tokenizer(\n        example[\"target\"], \n        max_length=64, \n        padding=\"max_length\", \n        truncation=True\n    )\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\n# Apply tokenizer\ntokenized_train_dataset = hf_train_dataset.map(tokenize, batched=False)\ntokenized_val_dataset = hf_val_dataset.map(tokenize, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:18:50.630131Z","iopub.execute_input":"2025-05-04T03:18:50.630314Z","iopub.status.idle":"2025-05-04T03:22:08.297308Z","shell.execute_reply.started":"2025-05-04T03:18:50.630300Z","shell.execute_reply":"2025-05-04T03:22:08.296385Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88f27c54397344379535dcd9578d54e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"004f99820f7141f1a2ed3e32bb8608d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e4f2bd568b84410984865d2a9dc2bda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/8.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d98eda1680a142f997df606e8153c3bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c60ad62243e74223ad35a73e0b85bd3a"}},"metadata":{}},{"name":"stderr","text":"2025-05-04 03:19:14.304570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746328754.760556      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746328754.903838      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20dda1c408084c4094bf28e8c20da1ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45749d43c0604698a9d0c7b34a22a337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b15cbf8af94d7190eff842bfd473bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/76840 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3efa86c4d3454ba9edbcb4836a207c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9605 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9db55239baba45ab8777c31e94b964c6"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nsecret_label = \"HF Hub\"\nsecret_value = UserSecretsClient().get_secret(secret_label)\nlogin(token=secret_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:22:08.298409Z","iopub.execute_input":"2025-05-04T03:22:08.298687Z","iopub.status.idle":"2025-05-04T03:22:08.981168Z","shell.execute_reply.started":"2025-05-04T03:22:08.298669Z","shell.execute_reply":"2025-05-04T03:22:08.980227Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:22:08.984852Z","iopub.execute_input":"2025-05-04T03:22:08.985383Z","iopub.status.idle":"2025-05-04T03:22:09.744141Z","shell.execute_reply.started":"2025-05-04T03:22:08.985357Z","shell.execute_reply":"2025-05-04T03:22:09.743271Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nDevice: cuda\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./araT5-qg\",\n    run_name=\"araT5-qg-run-1\",\n    learning_rate=2e-5,                           # standard LR for T5 fine-tuning\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    save_total_limit=1,                           # keep only 2 latest checkpoints\n    eval_strategy=\"epoch\",           # use eval_strategy (not evaluation_strategy)\n    save_strategy=\"epoch\",\n    fp16=True, \n    metric_for_best_model=\"loss\",\n    greater_is_better=False,\n    load_best_model_at_end=False,\n    report_to=\"none\",                             # no wandb/huggingface reporting\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n)\n\n# Start training\ntrainer.train()\n\n# Save final model and tokenizer\nmodel.save_pretrained(\"./araT5-qg-final\")\ntokenizer.save_pretrained(\"./araT5-qg-final\")\n\nprint(\"✅ Training complete! Model and tokenizer saved to './araT5-qg-final'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T03:22:09.745123Z","iopub.execute_input":"2025-05-04T03:22:09.745385Z","iopub.status.idle":"2025-05-04T10:51:06.183453Z","shell.execute_reply.started":"2025-05-04T03:22:09.745368Z","shell.execute_reply":"2025-05-04T10:51:06.182531Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2099068984.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='14409' max='14409' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [14409/14409 7:28:46, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.561800</td>\n      <td>0.458341</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.526300</td>\n      <td>0.445013</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.499700</td>\n      <td>0.441425</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ Training complete! Model and tokenizer saved to './araT5-qg-final'\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"%cd /kaggle/working/araT5-qg-final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:09:59.964970Z","iopub.execute_input":"2025-05-04T11:09:59.965834Z","iopub.status.idle":"2025-05-04T11:09:59.971108Z","shell.execute_reply.started":"2025-05-04T11:09:59.965804Z","shell.execute_reply":"2025-05-04T11:09:59.970259Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/araT5-qg-final\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"!git init","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:17.651518Z","iopub.execute_input":"2025-05-04T11:05:17.652159Z","iopub.status.idle":"2025-05-04T11:05:17.856600Z","shell.execute_reply.started":"2025-05-04T11:05:17.652136Z","shell.execute_reply":"2025-05-04T11:05:17.855816Z"}},"outputs":[{"name":"stdout","text":"Reinitialized existing Git repository in /kaggle/working/araT5-qg-final/.git/\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"!git remote add origin https://huggingface.co/NadirFartas/NadirFartas/AraT5-V2-QG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:20.005847Z","iopub.execute_input":"2025-05-04T11:05:20.006627Z","iopub.status.idle":"2025-05-04T11:05:20.209809Z","shell.execute_reply.started":"2025-05-04T11:05:20.006586Z","shell.execute_reply":"2025-05-04T11:05:20.208884Z"}},"outputs":[{"name":"stdout","text":"error: remote origin already exists.\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"!git remote set-url origin https://NadirFartas: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@huggingface.co/NadirFartas/AraT5-V2-QG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:26.767710Z","iopub.execute_input":"2025-05-04T11:05:26.768537Z","iopub.status.idle":"2025-05-04T11:05:26.969847Z","shell.execute_reply.started":"2025-05-04T11:05:26.768506Z","shell.execute_reply":"2025-05-04T11:05:26.968798Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Configure your identity\n!git config user.email \"fartasnadir2003@gmail.com\"\n!git config user.name \"NadirFartas\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:28.843551Z","iopub.execute_input":"2025-05-04T11:05:28.843836Z","iopub.status.idle":"2025-05-04T11:05:29.239653Z","shell.execute_reply.started":"2025-05-04T11:05:28.843813Z","shell.execute_reply":"2025-05-04T11:05:29.238570Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Add and commit files\n!git add .\n!git commit -m \"Initial commit of AraT5 version 2 fine-tuned model\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:31.134529Z","iopub.execute_input":"2025-05-04T11:05:31.135080Z","iopub.status.idle":"2025-05-04T11:05:31.532876Z","shell.execute_reply.started":"2025-05-04T11:05:31.135049Z","shell.execute_reply":"2025-05-04T11:05:31.532146Z"}},"outputs":[{"name":"stdout","text":"On branch main\nnothing to commit, working tree clean\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"!git branch -M main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:05:34.038330Z","iopub.execute_input":"2025-05-04T11:05:34.039046Z","iopub.status.idle":"2025-05-04T11:05:34.241921Z","shell.execute_reply.started":"2025-05-04T11:05:34.039019Z","shell.execute_reply":"2025-05-04T11:05:34.241079Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"!git fetch origin\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:07:29.615811Z","iopub.execute_input":"2025-05-04T11:07:29.616770Z","iopub.status.idle":"2025-05-04T11:07:30.157723Z","shell.execute_reply.started":"2025-05-04T11:07:29.616738Z","shell.execute_reply":"2025-05-04T11:07:30.156729Z"}},"outputs":[{"name":"stdout","text":"warning: no common commits\nremote: Enumerating objects: 4, done.\u001b[K\nremote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\nUnpacking objects: 100% (4/4), 1.13 KiB | 386.00 KiB/s, done.\nFrom https://huggingface.co/NadirFartas/AraT5-V2-QG\n * [new branch]      main       -> origin/main\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi(token=os.getenv(\"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\"))\napi.upload_folder(\n    folder_path=\"/kaggle/working/araT5-qg-final\",\n    repo_id=\"NadirFartas/AraT5-V2-QG\",\n    repo_type=\"model\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:12:01.526852Z","iopub.execute_input":"2025-05-04T11:12:01.527229Z","iopub.status.idle":"2025-05-04T11:12:39.784028Z","shell.execute_reply.started":"2025-05-04T11:12:01.527204Z","shell.execute_reply":"2025-05-04T11:12:39.783128Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4432dbea3f8b494ab26ee6d2f07c9749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e927e17c9a7a4ab7a9d12d0ff6b443c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c32cb9df91b4469bd5b20a20988916c"}},"metadata":{}},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/NadirFartas/AraT5-V2-QG/commit/9f71d604950d675857ac06365780e4cd7ece72e0', commit_message='Upload folder using huggingface_hub', commit_description='', oid='9f71d604950d675857ac06365780e4cd7ece72e0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NadirFartas/AraT5-V2-QG', endpoint='https://huggingface.co', repo_type='model', repo_id='NadirFartas/AraT5-V2-QG'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"!git push origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:09:52.056753Z","iopub.execute_input":"2025-05-04T11:09:52.057518Z","iopub.status.idle":"2025-05-04T11:09:52.476115Z","shell.execute_reply.started":"2025-05-04T11:09:52.057487Z","shell.execute_reply":"2025-05-04T11:09:52.475134Z"}},"outputs":[{"name":"stdout","text":"To https://huggingface.co/NadirFartas/AraT5-V2-QG\n \u001b[31m! [rejected]       \u001b[m main -> main (non-fast-forward)\n\u001b[31merror: failed to push some refs to 'https://huggingface.co/NadirFartas/AraT5-V2-QG'\n\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"print(ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:14:53.583005Z","iopub.execute_input":"2025-05-04T11:14:53.583382Z","iopub.status.idle":"2025-05-04T11:14:53.588200Z","shell.execute_reply.started":"2025-05-04T11:14:53.583357Z","shell.execute_reply":"2025-05-04T11:14:53.587313Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['version', 'data'],\n        num_rows: 1\n    })\n    validation: Dataset({\n        features: ['version', 'data'],\n        num_rows: 1\n    })\n    test: Dataset({\n        features: ['version', 'data'],\n        num_rows: 1\n    })\n})\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"# Testing the Model with both 3 epochs and 10 epochs","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom datasets import load_dataset\nimport json\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"NadirFartas/AraT5-V2-QG\")\ntokenizer = AutoTokenizer.from_pretrained(\"NadirFartas/AraT5-V2-QG\")\nmodel2 = AutoModelForSeq2SeqLM.from_pretrained(\"NadirFartas/AraT5_V2_10epoch\")\ntokenizer2 = AutoTokenizer.from_pretrained(\"NadirFartas/AraT5_V2_10epoch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:04:24.148342Z","iopub.execute_input":"2025-05-05T00:04:24.148602Z","iopub.status.idle":"2025-05-05T00:05:55.502478Z","shell.execute_reply.started":"2025-05-05T00:04:24.148584Z","shell.execute_reply":"2025-05-05T00:05:55.501585Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd3879b01a14d44ac3208b85618f7f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2560126ec24c0592fc3dd9e6b6d78a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2dff5797216412baf317745e587041e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12dd268b2f594fabab66128cd2691c9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f08e6e058c784f6a89d0af4640c57d6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3c9543bd8a41c4b3f7dcc28aed09db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea89ef5c75454a21b12e665bad34e9bf"}},"metadata":{}},{"name":"stderr","text":"2025-05-05 00:04:46.927477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746403487.213894      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746403487.286946      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c727ef83fb94be8999f81db877aee1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1bbc5ecc064f62b7f6c8b300c201da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3111395f5d964be5821792c17bf246b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05560cfd94fd4e449d57bd1591de8057"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"726450131ea84d0ebd3fe58d02124d48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f72d756a6794bf0a56d9af625ec2cd4"}},"metadata":{}},{"name":"stderr","text":"You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e360e141aa4346288c336b0ca270d3c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52991b3e813645799115f6c2233c2edd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d4c50725304791bf79d868888ed474"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac3241f36fc0428c8fd4b22b45d8fb6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e6e1f6c7dfb4fafa00bee45f31a73ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1592253547e54524b16fb9aa3e9b37e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ecd99f83244bb2bd4c188ffa39dfe4"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"formatted_test_dataset = format_squad_dataset(ds[\"test\"])\ntest_dataset = flatten_context_qa_pairs(formatted_test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:07:26.826477Z","iopub.execute_input":"2025-05-05T00:07:26.827157Z","iopub.status.idle":"2025-05-05T00:07:27.123388Z","shell.execute_reply.started":"2025-05-05T00:07:26.827131Z","shell.execute_reply":"2025-05-05T00:07:27.122641Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(f\"Total test pairs: {len(test_dataset)}\")\nprint(test_dataset[4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:07:30.029272Z","iopub.execute_input":"2025-05-05T00:07:30.029596Z","iopub.status.idle":"2025-05-05T00:07:30.033915Z","shell.execute_reply.started":"2025-05-05T00:07:30.029574Z","shell.execute_reply":"2025-05-05T00:07:30.033306Z"}},"outputs":[{"name":"stdout","text":"Total test pairs: 9606\n{'input': 'بحلول 15 مايو ، أمر رئيس مجلس الدولة ون جياباو بنشر 90 طائرة هليكوبتر إضافية ، منها 60 طائرة مقدمة من قبل جيش التحرير الشعبي الصيني ، و 30 طائرة من المقرر أن توفرها صناعة الطيران المدني ، ليصل إجمالي عدد الطائرات التي تم نشرها في عمليات الإغاثة من قبل القوات الجوية والجيش والطيران المدني إلى أكثر من 150 ، مما أدى إلى أكبر عملية نقل جوي غير قتالية في تاريخ جيش التحرير الشعبي .', 'target': 'ماذا طلب رئيس الوزراء ون جياباو ؟'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"**Exemple 1**","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef generate_question_from_input(input_text, modelS, tokenizerS, max_length=64):\n    inputs = tokenizerS.encode(input_text, return_tensors=\"pt\", truncation=True).to(modelS.device)\n    outputs = modelS.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)\n    question = tokenizerS.decode(outputs[0], skip_special_tokens=True)\n    return question\n\n# Pick a test example\nsample = test_dataset[3]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text, model, tokenizer)\ngenerated_question2 = generate_question_from_input(input_text, model2, tokenizer2)\n\n# Show results\nprint(\"📥 Input to the model:\\n\", input_text)\nprint(\"\\n✅ Dataset Question:\\n\", real_question)\nprint(\"\\n🤖 3 epochs Generated Questions:\\n\", generated_question)\nprint(\"\\n🤖 10 epochs Generated Questions:\\n\", generated_question2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:11:53.511156Z","iopub.execute_input":"2025-05-05T00:11:53.511484Z","iopub.status.idle":"2025-05-05T00:11:56.494189Z","shell.execute_reply.started":"2025-05-05T00:11:53.511461Z","shell.execute_reply":"2025-05-05T00:11:56.493495Z"}},"outputs":[{"name":"stdout","text":"📥 Input to the model:\n بحلول 15 مايو ، أمر رئيس مجلس الدولة ون جياباو بنشر 90 طائرة هليكوبتر إضافية ، منها 60 طائرة مقدمة من قبل جيش التحرير الشعبي الصيني ، و 30 طائرة من المقرر أن توفرها صناعة الطيران المدني ، ليصل إجمالي عدد الطائرات التي تم نشرها في عمليات الإغاثة من قبل القوات الجوية والجيش والطيران المدني إلى أكثر من 150 ، مما أدى إلى أكبر عملية نقل جوي غير قتالية في تاريخ جيش التحرير الشعبي .\n\n✅ Dataset Question:\n كم عدد الطائرات التي كانت موجودة في المجموع ؟\n\n🤖 3 epochs Generated Questions:\n كم عدد الطائرات التي تم نشرها في عمليات الإغاثة ؟\n\n🤖 10 epochs Generated Questions:\n كم عدد طائرات الهليكوبتر التي تم نشرها في عمليات الإغاثة ؟\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"**Exemple 2**","metadata":{}},{"cell_type":"code","source":"# Pick a test example\nsample = test_dataset[333]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text, model, tokenizer)\ngenerated_question2 = generate_question_from_input(input_text, model2, tokenizer2)\n\n# Show results\nprint(\"📥 Input to the model:\\n\", input_text)\nprint(\"\\n✅ Dataset Question:\\n\", real_question)\nprint(\"\\n🤖 3 epochs Generated Questions:\\n\", generated_question)\nprint(\"\\n🤖 10 epochs Generated Questions:\\n\", generated_question2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:14:29.619412Z","iopub.execute_input":"2025-05-05T00:14:29.619701Z","iopub.status.idle":"2025-05-05T00:14:31.965843Z","shell.execute_reply.started":"2025-05-05T00:14:29.619680Z","shell.execute_reply":"2025-05-05T00:14:31.965044Z"}},"outputs":[{"name":"stdout","text":"📥 Input to the model:\n تعتمد الجودة الصافية لانعكاس الأرض على تضاريس السطح . عندما تكون مخالفات السطح أصغر بكثير من الطول الموجي ، فنحن في نظام الانعكاس المنظاري ، ويرى المستقبل كلا من الهوائي الحقيقي وصورة للهوائي تحت الأرض بسبب الانعكاس . ولكن إذا كانت الأرض بها مخالفات ليست صغيرة مقارنة بالطول الموجي ، فلن تكون الانعكاسات متماسكة ولكنها ستتحول عن طريق مراحل عشوائية . مع الأطوال الموجية الأقصر ( الترددات الأعلى ) ، هذا هو الحال بشكل عام .\n\n✅ Dataset Question:\n ما هو سبب رؤية المستقبل لكل من هوائي الرفع وصورة الهوائي ؟\n\n🤖 3 epochs Generated Questions:\n ما الذي يعتمد على تضاريس السطح ؟\n\n🤖 10 epochs Generated Questions:\n ما هي الجودة الصافية لانعكاس الأرض ؟\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Pick a test example\nsample = test_dataset[65]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text, model, tokenizer)\ngenerated_question2 = generate_question_from_input(input_text, model2, tokenizer2)\n\n# Show results\nprint(\"📥 Input to the model:\\n\", input_text)\nprint(\"\\n✅ Dataset Question:\\n\", real_question)\nprint(\"\\n🤖 3 epochs Generated Questions:\\n\", generated_question)\nprint(\"\\n🤖 10 epochs Generated Questions:\\n\", generated_question2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:15:18.921374Z","iopub.execute_input":"2025-05-05T00:15:18.922054Z","iopub.status.idle":"2025-05-05T00:15:22.846817Z","shell.execute_reply.started":"2025-05-05T00:15:18.922031Z","shell.execute_reply":"2025-05-05T00:15:22.846023Z"}},"outputs":[{"name":"stdout","text":"📥 Input to the model:\n وفي أعقاب الأحداث التي وقعت في أولمبيا ، وردت تقارير تفيد بأن الصين طلبت الإذن بنشر أفراد من جيش التحرير الشعبي الصيني على طول طريق التتابع لحماية الشعلة في كانبيرا . وذكرت السلطات الأسترالية أن هذا الطلب ، إذا ما قدم ، سيرفض . ووصف مسؤولون صينيون الأمر بأنه شائعة . منحت الشرطة الأسترالية صلاحيات تفتيش المتفرجين في التتابع ، بعد دعوة أطلقتها رابطة الطلاب والعلماء الصينيين للطلاب الصينيين الأستراليين إلى \" الدفاع عن شعلتنا المقدسة \" ضد \" حثالة عرقية منحطة وانفصاليين مناهضين للصين \" . وقال توني جوه ، رئيس المجلس الأسترالي للمنظمات الصينية ، إن المنظمة ستأخذ \" الآلاف \" من المتظاهرين المؤيدين لبكين إلى كانبيرا بالحافلة ، لدعم تتابع الشعلة . وقال تشانغ رونغان ، وهو طالب أسترالي صيني ينظم مظاهرات مؤيدة لبكين ، للصحافة إن دبلوماسيين صينيين يساعدون في تنظيم الحافلات والوجبات والإقامة للمتظاهرين المؤيدين لبكين ، ويساعدونهم على تنظيم \" استعراض سلمي للقوة \" . وقال وزير الخارجية ستيفن سميث إن المسؤولين الصينيين يحثون أنصارهم على \" الحضور وطرح وجهة نظر \" لكنه ليس لديه اعتراض على ذلك طالما ظلوا سلميين .\n\n✅ Dataset Question:\n من هو وزير الخارجية الذي قال إنه موافق على الاحتجاجات طالما كانت سلمية ؟\n\n🤖 3 epochs Generated Questions:\n من الذي طلب الإذن بنشر جيش التحرير الشعبي الصيني على طول طريق التتابع ؟\n\n🤖 10 epochs Generated Questions:\n من هو رئيس المجلس الأسترالي للمنظمات الصينية ؟\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Pick a test example\nsample = data[65]\ninput_text = sample[\"context\"]\nreal_question = sample[\"question\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text, model, tokenizer)\ngenerated_question2 = generate_question_from_input(input_text, model2, tokenizer2)\n\n# Show results\nprint(\"📥 Input to the model:\\n\", input_text)\nprint(\"\\n✅ Dataset Question:\\n\", real_question)\nprint(\"\\n🤖 3 epochs Generated Questions:\\n\", generated_question)\nprint(\"\\n🤖 10 epochs Generated Questions:\\n\", generated_question2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:18:15.748637Z","iopub.execute_input":"2025-05-05T00:18:15.749110Z","iopub.status.idle":"2025-05-05T00:18:20.705595Z","shell.execute_reply.started":"2025-05-05T00:18:15.749086Z","shell.execute_reply":"2025-05-05T00:18:20.704842Z"}},"outputs":[{"name":"stdout","text":"📥 Input to the model:\n يحكى أن بلدا يحكمه ملك لا يحب في الدنيا شيء كما يحب الملابس والاعتناء بمظهره, فكان يقضي الساعات في شراء وتجربة الملابس الجديدة على حساب الاهتمام بمشاغل شعبه, وكان يبذل المال الكثير للخياطين في سبيل الحصول على ثياب جديدة ومميزة, وفي يوم من الأيام قدم خياط إلى الملك يدعي أنه يستطيع خياطة ثياب سحرية, السلام عليك يا سيدي، أنا خياط متجول مختص في خياطة الثياب السحرية فقال الملك متعجبا: وما السحر الذي يميز ثيابك عن بقية الثياب؟ ملابسي لا يمكن رؤيتها والتمتع بجمالها إلا من طرف الأذكياء، أما الأغبياء فلا يمكنهم مشاهدتها وما الذي تحتاج أليه لتصنع لنا هكذا ثوبا؟ أحتاج إلى الكثير من الذهب لأصنع منه الخيوط التي سأستعملها في نسيج القماش وخياطة الثياب, فأمر له الملك بغرفة في القصر وتوفير كل ما يحتاج إليه من ذهب, وبعد أيام، قدم الخياط بالثوب حتى يقيسه على الملك الذي لم يستطع رؤية الثوب على بدنه عندما نظر في المرآة فلم يقل شيء حتى لا يقال إنه غبي وكذلك فعل حاشيته الذين تظاهروا بالإعجاب بالثوب وقرر الملك القيام بجولة في المدينة مرتديا الثوب السحري حتى يتباهى به أمام شعبه. وفي اليوم الموعود خرج على الناس الذين لم يرو الا ملكا عاريا يمشي في غرور وسط حاشيته ولكن الجميع تظاهر برؤية الثوب حتى لا يقال انهم اغبياء إلاّ طفلا بريئا صاح وسط الجميع قائلا إن الملك عار لا يرتدي أي ثياب, فأخذ الجميع يقول وهم يضحكون نعم إن الملك لا يرتدي إلا ملابسه الداخلية, وهكذا عاد الملك إلى قصره بسرعة محرجا خجلا من نفسه بعد أن أصبح اضحوكة بين الناس, وتعلم أن يقلل من الإنفاق على الثياب والاهتمام بمظهره على حساب القيام بواجباته.\n\n✅ Dataset Question:\n ماذا حدث للملك لما قرر ان يتباهى امام شعبه؟\n\n🤖 3 epochs Generated Questions:\n في أي يوم خرج الملك على الناس مرتديا الثوب السحري حتى يتباهى به أمام شعبه ؟\n\n🤖 10 epochs Generated Questions:\n ما الذي كان الملك يحاول القيام به على حساب الاهتمام بمشاغل شعبه ؟\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\n\n# Load XML\ntree = ET.parse('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml')  \nroot = tree.getroot()\n\n# Print tag names of the first few elements\nfor child in root.iter():\n    print(child.tag)\n    break  # remove this break to see more tags if needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:16:14.419278Z","iopub.execute_input":"2025-05-05T00:16:14.419578Z","iopub.status.idle":"2025-05-05T00:16:14.585000Z","shell.execute_reply.started":"2025-05-05T00:16:14.419558Z","shell.execute_reply":"2025-05-05T00:16:14.584252Z"}},"outputs":[{"name":"stdout","text":"corpus\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"with open('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml', 'r', encoding='utf-8') as f:\n    for _ in range(20):\n        print(f.readline().strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:16:19.284835Z","iopub.execute_input":"2025-05-05T00:16:19.285443Z","iopub.status.idle":"2025-05-05T00:16:19.290023Z","shell.execute_reply.started":"2025-05-05T00:16:19.285420Z","shell.execute_reply":"2025-05-05T00:16:19.289412Z"}},"outputs":[{"name":"stdout","text":"<?xml version='1.0' encoding='utf-8'?>\n<corpus><texte id=\"0\"><titre>الأسد والفأر\n</titre><body>\nوسط غابة كبيرة كان هناك\nالاسد ملك الغابة نائما تحت\nظل شجرة وكان هناك فأر\nصغير يلعب في الجوارثم لاحظ\nأن الملك نائم لذلك قرر أن يلعب قليلا صعد على ظهره\nوبدأ يتزحلق عبر ذيله إلى الأسفل أعادها مرة واثنتان وثلاث استمتع الفأر بالأمر، انزعج الأسد واستيقظ ثم\nأمسك بالفأر الصغيرأراد أكله استوقفه الفأر الصغير باكيا يترجاه لكي لايكون\nوجبة خفيفة له ترجاه الفأر ووعده بأن لايزعجه مرة أخرى\nبل لربما يحتاجه في وقت من الأوقات تأثر الأسد بما سمعه ثم ترك الفأر يرحل وبعد بضعة أيام وككل يوم\nملك الغابة يأخذ قيلولته إذ بالصيادي يلقي شبكته عليه ليمسك به فعلا قد وقع في الفخ\nبدأ الأسد بالزئير ليسمعه كل من في الغابة حتى الفأر الصغير سمع زئيره ليتذكر أنه\nمدين للأسد وعليه المساعدةوأن يرد المعروف بمثله لم يتردد صديقنا\nوذهب مسرعا ليرى ماحصل وعندما وصل وجد الأسد تحت الشباك\nتسلقها الفأر وبدأ بتمزيقها بأسنانه الحادة\nحتى مزقها بالكامل وأخيرا أنقذ الأسد من الفخ ورد له صنيعه ومن ذلك الحين والأسد صديق الفأر.\nهناك أصدقاء يعرفون عند الشدائد فلنتمسك بهم.\n</body><questions>\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimport re\n\ndef parse_custom_xml(file_path):\n    tree = ET.parse(file_path)\n    root = tree.getroot()\n\n    data = []\n    for texte in root.findall(\"texte\"):\n        raw_context = texte.find(\"body\").text or \"\"\n        context = re.sub(r'\\s+', ' ', raw_context).strip()\n        questions_block = texte.find(\"questions\").text\n\n        # Check and split questions using dash\n        if questions_block:\n            questions = [q.strip() for q in questions_block.strip().split(\"-\") if q.strip()]\n            for question in questions:\n                data.append({\"context\": context, \"question\": question})\n\n    return data\ndata = parse_custom_xml(\"/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml\")\nprint(f\"Total examples extracted: {len(data)}\")\nprint(data[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T00:16:21.930608Z","iopub.execute_input":"2025-05-05T00:16:21.931152Z","iopub.status.idle":"2025-05-05T00:16:22.106729Z","shell.execute_reply.started":"2025-05-05T00:16:21.931132Z","shell.execute_reply":"2025-05-05T00:16:22.105929Z"}},"outputs":[{"name":"stdout","text":"Total examples extracted: 1506\n{'context': 'في يوم من الأيام وفي أحد غابات إفريقيا، بينما كان أحد الفهود يتجول قرب ضفة النهر باحثا عن فريسة يسد بها رمقه، لمح قطيعا من الغزلان يرعى العشب على الضفة المقابلة. فقال في نفسه وهو ينظر إليها: \"ليتني أعرف السباحة، فأعبر النهر وأفترس غزالا أملئ به معدتي الخاوية.\" التفت الفهد يمنةً ويسرةً باحثاً عن شيء يمكنّه من العبور إلى الضفّة المقابلة، ولكن دون جدوى . ثم نظر وسط النهر فرأى فرس نهر يسبح في الماء ويأكل من الأعشاب التي نمت في قاعه. فكر الفهد قليلا ثم توجه إلى ضفة النهر وخاطب الفرس قائلا: \" السلام عليك يا ابن عمي \" فأجاب فرس النهر وقد بدت عليه علامات التعجب: \"وعليك السلام. كيف تكون ابن عمي وأنت لست من فصيلتي؟ فأنت تملك جسما رشيقا ومرقطا بينما جسمي ممتلئ وخال من البقع\" فأجاب الفهد في خبث: \" أنا من بلد بعيد حيث تكون أفراس النهر مرقطة ونحيلة.\" تظاهر فرس النهر بتصديق كلام الفهد ثم قال: \"حسن يا ابن عمي كيف يمكنني خدمتك؟\" فقال الفهد: \"هل يمكنك مساعدتي ونقلي على ظهرك الى الضفة المقابلة للنهر؟\" فكر فرس النهر قليلا ثم وافق وحمل الفهد على ضهره ليعبر به النهر. وفي منتصف الطريق توقف عن السباحة ثم قال: \"بما أنك فرس نهر فبإمكانك السباحة والغطس مثلي. أليس كذلك؟\" فأجاب الفهد مرتبكا : \"إم م م ... بالطبع يمكنني السباحة.\" وبينما كان الفهد يهمهم ويبحث في رأسه عن كلام مقنع، اذ بفرس النهر يغطس به الى اعماق النهر. فكانت تلك الغطسة درسا قاسيا للفهد الذي نجا بأعجوبة من الغرق. وهكذا نال الفهد الخبيث جزاء خداعه لفرس النهر واستخفافه بذكائه.', 'question': 'هل انخدع فرس النهر بكذبة الفهد؟'}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}