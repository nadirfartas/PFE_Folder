{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/nadirfartas/pfenotebook?scriptVersionId=236321355\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:55:59.385133Z","iopub.execute_input":"2025-05-02T10:55:59.385682Z","iopub.status.idle":"2025-05-02T10:55:59.390129Z","shell.execute_reply.started":"2025-05-02T10:55:59.385660Z","shell.execute_reply":"2025-05-02T10:55:59.389284Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nsecret_label = \"HF Hub\"\nsecret_value = UserSecretsClient().get_secret(secret_label)\nlogin(token=secret_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:06:37.599301Z","iopub.execute_input":"2025-05-02T11:06:37.599729Z","iopub.status.idle":"2025-05-02T11:06:37.817105Z","shell.execute_reply.started":"2025-05-02T11:06:37.599705Z","shell.execute_reply":"2025-05-02T11:06:37.816585Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:06:41.059865Z","iopub.execute_input":"2025-05-02T11:06:41.060405Z","iopub.status.idle":"2025-05-02T11:06:47.832566Z","shell.execute_reply.started":"2025-05-02T11:06:41.060379Z","shell.execute_reply":"2025-05-02T11:06:47.831617Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install \\\n    datasets \\\n    evaluate \\\n    rouge_score\\\n    loralib \\\n    evaluate \\\n    accelerate \\\n    bitsandbytes \\\n    trl \\\n    peft \\\n    -U --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:51:34.750579Z","iopub.execute_input":"2025-05-03T13:51:34.751117Z","iopub.status.idle":"2025-05-03T13:53:03.662727Z","shell.execute_reply.started":"2025-05-03T13:51:34.751091Z","shell.execute_reply":"2025-05-03T13:53:03.661819Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:18:00.409499Z","iopub.execute_input":"2025-05-02T11:18:00.409793Z","iopub.status.idle":"2025-05-02T11:18:04.252339Z","shell.execute_reply.started":"2025-05-02T11:18:00.409766Z","shell.execute_reply":"2025-05-02T11:18:04.251776Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# 1. Preparing and loading Train and val dataset","metadata":{}},{"cell_type":"code","source":"def format_squad_dataset(dataset_split):\n    \"\"\"\n    Format a SQuAD-style dataset split into a list of dictionaries \n    with context, questions, and answers.\n\n    Args:\n        dataset_split: a split of the SQuAD-style dataset, e.g., ds[\"train\"] or ds[\"validation\"]\n\n    Returns:\n        A list of formatted entries: [{\"context\": ..., \"questions\": [...], \"answers\": [...]}]\n    \"\"\"\n    formatted = []\n\n    for article in dataset_split:\n        for paragraph in article[\"data\"]:\n            for p in paragraph[\"paragraphs\"]:\n                context = p[\"context\"]\n                questions = []\n                answers = []\n\n                for qa in p[\"qas\"]:\n                    if qa[\"is_impossible\"]:\n                        continue\n\n                    if not qa.get(\"answers\") or not qa[\"answers\"][0].get(\"text\"):\n                        continue\n\n                    question = qa[\"question\"]\n                    answer = qa[\"answers\"][0][\"text\"]\n\n                    questions.append(question)\n                    answers.append(answer)\n\n                if questions and answers:\n                    formatted.append({\n                        \"context\": context,\n                        \"questions\": questions,\n                        \"answers\": answers\n                    })\n\n    return formatted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:59:16.453724Z","iopub.execute_input":"2025-05-03T13:59:16.455101Z","iopub.status.idle":"2025-05-03T13:59:16.460723Z","shell.execute_reply.started":"2025-05-03T13:59:16.455065Z","shell.execute_reply":"2025-05-03T13:59:16.459968Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\n\n# Load dataset\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")\nformatted_train_dataset = format_squad_dataset(ds[\"train\"])\nformatted_val_dataset = format_squad_dataset(ds[\"validation\"])\n\nprint(f\"✅ Done. Formatted {len(formatted_train_dataset)} training context blocks.\")\nprint(f\"✅ Done. Formatted {len(formatted_val_dataset)} validation context blocks.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:18:04.260997Z","iopub.execute_input":"2025-05-02T11:18:04.261183Z","iopub.status.idle":"2025-05-02T11:18:14.953551Z","shell.execute_reply.started":"2025-05-02T11:18:04.261168Z","shell.execute_reply":"2025-05-02T11:18:14.952826Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d56093e552541759193672c0db94f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e409aab3ce64d2195892053b113e3ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c662b8a291dd4f9daece6e5bb4c77b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b148e4848dea4bf689bf9e0355cb2048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bc7a5b6bd044f66a6034eafc5d0c28d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f808f446d4f4451384553c69deb03847"}},"metadata":{}},{"name":"stdout","text":"✅ Done. Formatted 17180 training context blocks.\n✅ Done. Formatted 4639 validation context blocks.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def flatten_context_qa_pairs(formatted_data):\n    \"\"\"\n    Convert formatted context-question-answer data into a flat list of\n    input-target training pairs for seq2seq modeling.\n\n    Args:\n        formatted_data: List of dicts with 'context', 'questions', and 'answers'\n\n    Returns:\n        A list of dicts with 'input' and 'target' fields\n    \"\"\"\n    flat_data = []\n\n    for item in formatted_data:\n        context = item[\"context\"]\n        for question, answer in zip(item[\"questions\"], item[\"answers\"]):\n            input_text = f\"context: {context} answer: {answer}\"\n            target_text = question\n            flat_data.append({\"input\": input_text, \"target\": target_text})\n\n    return flat_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:59:20.643647Z","iopub.execute_input":"2025-05-03T13:59:20.643943Z","iopub.status.idle":"2025-05-03T13:59:20.648990Z","shell.execute_reply.started":"2025-05-03T13:59:20.643920Z","shell.execute_reply":"2025-05-03T13:59:20.648258Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_dataset = flatten_context_qa_pairs(formatted_train_dataset)\nval_dataset = flatten_context_qa_pairs(formatted_val_dataset)\nprint(f\"Total training pairs: {len(train_dataset)}\")\nprint(f\"Total validation pairs: {len(val_dataset)}\")\nprint(train_dataset[1])\nprint(val_dataset[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:18:14.960313Z","iopub.execute_input":"2025-05-02T11:18:14.960553Z","iopub.status.idle":"2025-05-02T11:18:15.478915Z","shell.execute_reply.started":"2025-05-02T11:18:14.960538Z","shell.execute_reply":"2025-05-02T11:18:15.478126Z"}},"outputs":[{"name":"stdout","text":"Total training pairs: 42033\nTotal validation pairs: 5254\n{'input': 'context: ( لم يكن زلزال Ms 6 . 1 في 30 أغسطس 2008 في جنوب سيتشوان جزءا من هذه السلسلة لأنه كان ناجما عن صدع مختلف . انظر زلزال بانتشيهوا 2008 للحصول على التفاصيل . ) answer: زلزال بانتشيهوا 2008', 'target': 'أين يجب أن تبحث عن مزيد من التفاصيل ؟'}\n{'input': 'context: غادر فريق الإغاثة الطارئة من الزلازل المكون من 184 شخصا ( يتألف من 12 شخصا من مكتب الدولة لرصد الزلازل و 150 من قيادة منطقة بكين العسكرية و 22 من مستشفى الشرطة العامة المسلحة ) بكين من مطار نانيوان في أواخر 12 مايو في طائرتي نقل عسكريتين للسفر إلى مقاطعة ونتشوان . answer: 184', 'target': 'كم عدد الأشخاص الذين شكلوا فريق الإغاثة ؟'}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from transformers import T5Tokenizer, AutoModelForSeq2SeqLM\nfrom datasets import Dataset\n\n# Load tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\", legacy=False)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\")\n# Convert list to Hugging Face Dataset\nhf_train_dataset = Dataset.from_list(train_dataset)\nhf_val_dataset = Dataset.from_list(val_dataset)\n\n# Tokenize function\ndef tokenize(example):\n    model_input = tokenizer(\n        example[\"input\"], \n        max_length=512, \n        padding=\"max_length\", \n        truncation=True\n    )\n    labels = tokenizer(\n        example[\"target\"], \n        max_length=64, \n        padding=\"max_length\", \n        truncation=True\n    )\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\n# Apply tokenizer\ntokenized_train_dataset = hf_train_dataset.map(tokenize, batched=False)\ntokenized_val_dataset = hf_val_dataset.map(tokenize, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:19:29.772013Z","iopub.execute_input":"2025-05-02T11:19:29.772687Z","iopub.status.idle":"2025-05-02T11:20:56.780295Z","shell.execute_reply.started":"2025-05-02T11:19:29.772663Z","shell.execute_reply":"2025-05-02T11:20:56.779598Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/42033 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"057a65c5d0734d24888ae3f0b316542b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5254 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09fea35bd1a9447a96cc5dabce501f2d"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:22:18.448549Z","iopub.execute_input":"2025-05-02T11:22:18.448891Z","iopub.status.idle":"2025-05-02T11:22:19.116484Z","shell.execute_reply.started":"2025-05-02T11:22:18.448859Z","shell.execute_reply":"2025-05-02T11:22:19.115655Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nDevice: cuda\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# 2. Training the model","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./araT5-qg\",\n    run_name=\"araT5-qg-run-1\",\n    learning_rate=2e-5,                           # standard LR for T5 fine-tuning\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    save_total_limit=1,                           # keep only 2 latest checkpoints\n    eval_strategy=\"epoch\",           # use eval_strategy (not evaluation_strategy)\n    save_strategy=\"epoch\",\n    fp16=True, \n    metric_for_best_model=\"loss\",\n    greater_is_better=False,\n    load_best_model_at_end=False,\n    report_to=\"none\",                             # no wandb/huggingface reporting\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n)\n\n# Start training\ntrainer.train()\n\n# Save final model and tokenizer\nmodel.save_pretrained(\"./araT5-qg-final\")\ntokenizer.save_pretrained(\"./araT5-qg-final\")\n\nprint(\"✅ Training complete! Model and tokenizer saved to './araT5-qg-final'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:22:26.799862Z","iopub.execute_input":"2025-05-02T11:22:26.800148Z","iopub.status.idle":"2025-05-02T15:12:41.399851Z","shell.execute_reply.started":"2025-05-02T11:22:26.800126Z","shell.execute_reply":"2025-05-02T15:12:41.398989Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2099068984.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7884' max='7884' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7884/7884 3:50:06, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.486000</td>\n      <td>0.391099</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.453800</td>\n      <td>0.377061</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.445300</td>\n      <td>0.373185</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ Training complete! Model and tokenizer saved to './araT5-qg-final'\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:16:22.851495Z","iopub.execute_input":"2025-05-02T15:16:22.852219Z","iopub.status.idle":"2025-05-02T15:16:25.227444Z","shell.execute_reply.started":"2025-05-02T15:16:22.852196Z","shell.execute_reply":"2025-05-02T15:16:25.226448Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# 3. Hosting the Model in HuggingFace Hub","metadata":{}},{"cell_type":"code","source":"# Go to the saved model directory\n%cd /kaggle/working/araT5-qg-final\n\n# Initialize Git repo (if not already a repo)\n!git init\n\n# Configure your identity\n!git config user.email \"fartasnadir2003@gmail.com\"\n!git config user.name \"NadirFartas\"\n\n# Link to your Hugging Face repo\n!git remote add origin https://huggingface.co/NadirFartas/araT5-qg-final\n\n# Add and commit files\n!git add .\n!git commit -m \"Initial commit of AraT5 fine-tuned model\"\n\n# Set the branch to main\n!git branch -M main\n\n# Push to Hugging Face\n!git push origin main\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:51:59.609988Z","iopub.execute_input":"2025-05-02T15:51:59.610294Z","iopub.status.idle":"2025-05-02T15:52:11.176094Z","shell.execute_reply.started":"2025-05-02T15:51:59.610270Z","shell.execute_reply":"2025-05-02T15:52:11.175060Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nReinitialized existing Git repository in /kaggle/working/araT5-qg-final/.git/\nerror: remote origin already exists.\nOn branch main\nnothing to commit, working tree clean\nUsername for 'https://huggingface.co': ^C\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Go to the saved model directory\n%cd /kaggle/working/araT5-qg-final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:43:23.397591Z","iopub.execute_input":"2025-05-02T15:43:23.397951Z","iopub.status.idle":"2025-05-02T15:43:23.403264Z","shell.execute_reply.started":"2025-05-02T15:43:23.397920Z","shell.execute_reply":"2025-05-02T15:43:23.402459Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Initialize Git repo (if not already a repo)\n!git init","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:43:33.119502Z","iopub.execute_input":"2025-05-02T15:43:33.119969Z","iopub.status.idle":"2025-05-02T15:43:33.344388Z","shell.execute_reply.started":"2025-05-02T15:43:33.119944Z","shell.execute_reply":"2025-05-02T15:43:33.343606Z"}},"outputs":[{"name":"stdout","text":"Reinitialized existing Git repository in /kaggle/working/araT5-qg-final/.git/\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"!git config user.email \"fartasnadir2003@gmail.com\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:43:47.821547Z","iopub.execute_input":"2025-05-02T15:43:47.822222Z","iopub.status.idle":"2025-05-02T15:43:48.049607Z","shell.execute_reply.started":"2025-05-02T15:43:47.822194Z","shell.execute_reply":"2025-05-02T15:43:48.048535Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"!git config user.name \"NadirFartas\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:44:00.975924Z","iopub.execute_input":"2025-05-02T15:44:00.976215Z","iopub.status.idle":"2025-05-02T15:44:01.201142Z","shell.execute_reply.started":"2025-05-02T15:44:00.976192Z","shell.execute_reply":"2025-05-02T15:44:01.200188Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Add and commit files\n!git add .\n!git commit -m \"Initial commit of AraT5 fine-tuned model\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:09:34.977890Z","iopub.execute_input":"2025-05-02T16:09:34.978569Z","iopub.status.idle":"2025-05-02T16:09:35.434595Z","shell.execute_reply.started":"2025-05-02T16:09:34.978539Z","shell.execute_reply":"2025-05-02T16:09:35.433850Z"}},"outputs":[{"name":"stdout","text":"On branch main\nnothing to commit, working tree clean\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:48:21.870599Z","iopub.execute_input":"2025-05-02T15:48:21.870938Z","iopub.status.idle":"2025-05-02T15:48:22.106783Z","shell.execute_reply.started":"2025-05-02T15:48:21.870907Z","shell.execute_reply":"2025-05-02T15:48:22.105767Z"}},"outputs":[{"name":"stdout","text":"added_tokens.json\tmodel.safetensors\t spiece.model\nconfig.json\t\tREADME.md\t\t tokenizer_config.json\ngeneration_config.json\tspecial_tokens_map.json\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"!git branch -M main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:09:44.515535Z","iopub.execute_input":"2025-05-02T16:09:44.516193Z","iopub.status.idle":"2025-05-02T16:09:44.741636Z","shell.execute_reply.started":"2025-05-02T16:09:44.516167Z","shell.execute_reply":"2025-05-02T16:09:44.740781Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"!git remote set-url origin https://NadirFartas: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@huggingface.co/NadirFartas/araT5-qg-final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:08:57.600136Z","iopub.execute_input":"2025-05-02T16:08:57.600644Z","iopub.status.idle":"2025-05-02T16:08:57.829709Z","shell.execute_reply.started":"2025-05-02T16:08:57.600620Z","shell.execute_reply":"2025-05-02T16:08:57.828648Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"!git push origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:10:04.230279Z","iopub.execute_input":"2025-05-02T16:10:04.231028Z","iopub.status.idle":"2025-05-02T16:10:20.381245Z","shell.execute_reply.started":"2025-05-02T16:10:04.230982Z","shell.execute_reply":"2025-05-02T16:10:20.380133Z"}},"outputs":[{"name":"stdout","text":"Uploading LFS objects: 100% (2/2), 1.5 GB | 102 MB/s, done.                     \nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 4 threads\nCompressing objects: 100% (9/9), done.\nWriting objects: 100% (9/9), 3.22 KiB | 1.61 MiB/s, done.\nTotal 9 (delta 0), reused 0 (delta 0), pack-reused 0\nTo https://huggingface.co/NadirFartas/araT5-qg-final\n   10f9fa8..3995e3f  main -> main\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"# 4. Loading the model and Dataset for test","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom datasets import load_dataset\nimport json\n\n# Load dataset\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"NadirFartas/araT5-qg-final\")\ntokenizer = AutoTokenizer.from_pretrained(\"NadirFartas/araT5-qg-final\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:57:42.493605Z","iopub.execute_input":"2025-05-03T13:57:42.493895Z","iopub.status.idle":"2025-05-03T13:58:37.065129Z","shell.execute_reply.started":"2025-05-03T13:57:42.493872Z","shell.execute_reply":"2025-05-03T13:58:37.064284Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b0b1ec98b4450ea72aa19f294a809e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5209e2dfdcb4443fbc0b86f0632bf973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764a9267afb844a0a36478711c81c782"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"004f51ac8dda4a7dae91186e5058fdcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eee8edd4f1644213a20dd465c0581dac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a548ae9aa2c4140bec170c284b7015c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec9e39f3fb3447b8401c7e451a508f6"}},"metadata":{}},{"name":"stderr","text":"2025-05-03 13:58:10.719137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746280691.137737      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746280691.247581      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b7840044c649d6a885bf88383e6d3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fa7d0265cca4ea2addc8f96359c19a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a3d9b9df50e43fa9b306f454a9b3e55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abae1dfc3fd24bdfbfa5361d2d384a4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a95dded99d5f411c9fd21fb236dc907a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50630a1dcc9447db81630d0916612a7f"}},"metadata":{}},{"name":"stderr","text":"You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 5. Preparing the Test Dataset","metadata":{}},{"cell_type":"code","source":"formatted_test_dataset = format_squad_dataset(ds[\"test\"])\ntest_dataset = flatten_context_qa_pairs(formatted_test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:59:34.523416Z","iopub.execute_input":"2025-05-03T13:59:34.524142Z","iopub.status.idle":"2025-05-03T13:59:34.871695Z","shell.execute_reply.started":"2025-05-03T13:59:34.524110Z","shell.execute_reply":"2025-05-03T13:59:34.870942Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(f\"Total test pairs: {len(test_dataset)}\")\nprint(test_dataset[4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:59:45.404189Z","iopub.execute_input":"2025-05-03T13:59:45.405042Z","iopub.status.idle":"2025-05-03T13:59:45.409568Z","shell.execute_reply.started":"2025-05-03T13:59:45.405009Z","shell.execute_reply":"2025-05-03T13:59:45.408763Z"}},"outputs":[{"name":"stdout","text":"Total test pairs: 5254\n{'input': 'context: بحلول 15 مايو ، أمر رئيس مجلس الدولة ون جياباو بنشر 90 طائرة هليكوبتر إضافية ، منها 60 طائرة مقدمة من قبل جيش التحرير الشعبي الصيني ، و 30 طائرة من المقرر أن توفرها صناعة الطيران المدني ، ليصل إجمالي عدد الطائرات التي تم نشرها في عمليات الإغاثة من قبل القوات الجوية والجيش والطيران المدني إلى أكثر من 150 ، مما أدى إلى أكبر عملية نقل جوي غير قتالية في تاريخ جيش التحرير الشعبي . answer: نشر 90 طائرة هليكوبتر إضافية', 'target': 'ماذا طلب رئيس الوزراء ون جياباو ؟'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# 6. Testing the Model","metadata":{}},{"cell_type":"markdown","source":"**Exemple 1:**","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef generate_question_from_input(input_text, max_length=64):\n    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n    outputs = model.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)\n    question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return question\n\n# Pick a test example\nsample = test_dataset[3]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text)\n\n# Show results\nprint(\"📥 Input to the model:\\n\", input_text)\nprint(\"\\n✅ Dataset Question:\\n\", real_question)\nprint(\"\\n🤖 Generated Questions:\\n\", generated_question)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:10:52.535151Z","iopub.execute_input":"2025-05-03T17:10:52.535707Z","iopub.status.idle":"2025-05-03T17:10:54.000123Z","shell.execute_reply.started":"2025-05-03T17:10:52.535685Z","shell.execute_reply":"2025-05-03T17:10:53.999298Z"}},"outputs":[{"name":"stdout","text":"📥 Input to the model:\n context: بحلول 15 مايو ، أمر رئيس مجلس الدولة ون جياباو بنشر 90 طائرة هليكوبتر إضافية ، منها 60 طائرة مقدمة من قبل جيش التحرير الشعبي الصيني ، و 30 طائرة من المقرر أن توفرها صناعة الطيران المدني ، ليصل إجمالي عدد الطائرات التي تم نشرها في عمليات الإغاثة من قبل القوات الجوية والجيش والطيران المدني إلى أكثر من 150 ، مما أدى إلى أكبر عملية نقل جوي غير قتالية في تاريخ جيش التحرير الشعبي . answer: أكثر من 150\n\n✅ Dataset Question:\n كم عدد الطائرات التي كانت موجودة في المجموع ؟\n\n🤖 Generated Questions:\n كم عدد الطائرات التي تم نشرها في عمليات الإغاثة ؟\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"**Exemple 2:**","metadata":{}},{"cell_type":"code","source":"# Pick a test example\nsample = test_dataset[8]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text)\n\n# Show results\nprint(\"📥 Input to the model:\\n\", input_text)\nprint(\"\\n✅ Dataset Question:\\n\", real_question)\nprint(\"\\n🤖 Generated Questions:\\n\", generated_question)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:10:58.099067Z","iopub.execute_input":"2025-05-03T17:10:58.099540Z","iopub.status.idle":"2025-05-03T17:10:59.792120Z","shell.execute_reply.started":"2025-05-03T17:10:58.099516Z","shell.execute_reply":"2025-05-03T17:10:59.790738Z"}},"outputs":[{"name":"stdout","text":"📥 Input to the model:\n context: في يوم الطفل ، 1 يونيو - حزيران 2008 ، ذهب العديد من الآباء إلى أنقاض المدارس للحداد على أطفالهم . وقام الأطفال الناجون ، الذين كان معظمهم يعيشون في مراكز الإغاثة ، بمراسم الاحتفال باليوم الخاص ، لكنهم اعترفوا أيضا بالزلزال . answer: يوم الطفل\n\n✅ Dataset Question:\n ماذا كان يسمى 1 يونيو 2008 ؟\n\n🤖 Generated Questions:\n في أي يوم ذهب العديد من الآباء إلى أنقاض المدارس للحداد على أطفالهم ؟\n","output_type":"stream"}],"execution_count":82},{"cell_type":"markdown","source":"**Exemple 3:**","metadata":{}},{"cell_type":"code","source":"# Pick a test example\nsample = test_dataset[65]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text)\n\n# Show results\nprint(\"📥 Input to the model:\\n\", input_text)\nprint(\"\\n✅ Dataset Question:\\n\", real_question)\nprint(\"\\n🤖 Generated Questions:\\n\", generated_question)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:11:02.183240Z","iopub.execute_input":"2025-05-03T17:11:02.183907Z","iopub.status.idle":"2025-05-03T17:11:04.521184Z","shell.execute_reply.started":"2025-05-03T17:11:02.183882Z","shell.execute_reply":"2025-05-03T17:11:04.520333Z"}},"outputs":[{"name":"stdout","text":"📥 Input to the model:\n context: وفي أعقاب الأحداث التي وقعت في أولمبيا ، وردت تقارير تفيد بأن الصين طلبت الإذن بنشر أفراد من جيش التحرير الشعبي الصيني على طول طريق التتابع لحماية الشعلة في كانبيرا . وذكرت السلطات الأسترالية أن هذا الطلب ، إذا ما قدم ، سيرفض . ووصف مسؤولون صينيون الأمر بأنه شائعة . منحت الشرطة الأسترالية صلاحيات تفتيش المتفرجين في التتابع ، بعد دعوة أطلقتها رابطة الطلاب والعلماء الصينيين للطلاب الصينيين الأستراليين إلى \" الدفاع عن شعلتنا المقدسة \" ضد \" حثالة عرقية منحطة وانفصاليين مناهضين للصين \" . وقال توني جوه ، رئيس المجلس الأسترالي للمنظمات الصينية ، إن المنظمة ستأخذ \" الآلاف \" من المتظاهرين المؤيدين لبكين إلى كانبيرا بالحافلة ، لدعم تتابع الشعلة . وقال تشانغ رونغان ، وهو طالب أسترالي صيني ينظم مظاهرات مؤيدة لبكين ، للصحافة إن دبلوماسيين صينيين يساعدون في تنظيم الحافلات والوجبات والإقامة للمتظاهرين المؤيدين لبكين ، ويساعدونهم على تنظيم \" استعراض سلمي للقوة \" . وقال وزير الخارجية ستيفن سميث إن المسؤولين الصينيين يحثون أنصارهم على \" الحضور وطرح وجهة نظر \" لكنه ليس لديه اعتراض على ذلك طالما ظلوا سلميين . answer: ستيفن سميث\n\n✅ Dataset Question:\n من هو وزير الخارجية الذي قال إنه موافق على الاحتجاجات طالما كانت سلمية ؟\n\n🤖 Generated Questions:\n من قال إن المسؤولين الصينيين يحثون أنصارهم على الحضور وطرح وجهة نظر ؟\n","output_type":"stream"}],"execution_count":83},{"cell_type":"markdown","source":"# 7. Evaluating the Model","metadata":{}},{"cell_type":"code","source":"import evaluate\n\nrouge = evaluate.load(\"rouge\")\nbleu = evaluate.load(\"bleu\")\npredictions = []\nreferences = []\n\nfor sample in test_dataset[:500]:  # evaluate on a subset to be faster\n    input_text = sample[\"input\"]\n    reference = sample[\"target\"]\n    \n    # Generate question\n    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n    outputs = model.generate(inputs, max_length=64, num_beams=4)\n    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    predictions.append(generated)\n    references.append(reference)\n\n# ROUGE expects dict with lists\nrouge_result = rouge.compute(predictions=predictions, references=references)\nprint(\"🔍 ROUGE scores:\")\nprint(rouge_result)\n\n# BLEU expects references as list of lists\nbleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\nprint(\"\\n🔍 BLEU score:\")\nprint(bleu_result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T17:07:21.542043Z","iopub.execute_input":"2025-05-02T17:07:21.542300Z","iopub.status.idle":"2025-05-02T17:21:28.317893Z","shell.execute_reply.started":"2025-05-02T17:07:21.542284Z","shell.execute_reply":"2025-05-02T17:21:28.317108Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"000dce57b6ad43dca2df0137fa856765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a58b06f455104dfaad04705c1abcfac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfe45baa49dd4674b26553715801b27c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f86a14f1fab04f53b2b75cb1d6d579b0"}},"metadata":{}},{"name":"stdout","text":"🔍 ROUGE scores:\n{'rouge1': 0.08273333333333334, 'rouge2': 0.018166666666666664, 'rougeL': 0.08276666666666666, 'rougeLsum': 0.08233333333333331}\n\n🔍 BLEU score:\n{'bleu': 0.17064651710073242, 'precisions': [0.4323908443931525, 0.20429878697595233, 0.12502976899261728, 0.07677750743444174], 'brevity_penalty': 1.0, 'length_ratio': 1.0186128526645768, 'translation_length': 5199, 'reference_length': 5104}\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"# 8. Corpus XML preparation","metadata":{}},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\n\n# Load XML\ntree = ET.parse('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml')  \nroot = tree.getroot()\n\n# Print tag names of the first few elements\nfor child in root.iter():\n    print(child.tag)\n    break  # remove this break to see more tags if needed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T14:33:23.884533Z","iopub.execute_input":"2025-05-03T14:33:23.884826Z","iopub.status.idle":"2025-05-03T14:33:23.941105Z","shell.execute_reply.started":"2025-05-03T14:33:23.884804Z","shell.execute_reply":"2025-05-03T14:33:23.940416Z"}},"outputs":[{"name":"stdout","text":"corpus\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"with open('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml', 'r', encoding='utf-8') as f:\n    for _ in range(20):\n        print(f.readline().strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T14:34:07.873831Z","iopub.execute_input":"2025-05-03T14:34:07.874131Z","iopub.status.idle":"2025-05-03T14:34:07.881667Z","shell.execute_reply.started":"2025-05-03T14:34:07.874110Z","shell.execute_reply":"2025-05-03T14:34:07.880715Z"}},"outputs":[{"name":"stdout","text":"<?xml version='1.0' encoding='utf-8'?>\n<corpus><texte id=\"0\"><titre>الأسد والفأر\n</titre><body>\nوسط غابة كبيرة كان هناك\nالاسد ملك الغابة نائما تحت\nظل شجرة وكان هناك فأر\nصغير يلعب في الجوارثم لاحظ\nأن الملك نائم لذلك قرر أن يلعب قليلا صعد على ظهره\nوبدأ يتزحلق عبر ذيله إلى الأسفل أعادها مرة واثنتان وثلاث استمتع الفأر بالأمر، انزعج الأسد واستيقظ ثم\nأمسك بالفأر الصغيرأراد أكله استوقفه الفأر الصغير باكيا يترجاه لكي لايكون\nوجبة خفيفة له ترجاه الفأر ووعده بأن لايزعجه مرة أخرى\nبل لربما يحتاجه في وقت من الأوقات تأثر الأسد بما سمعه ثم ترك الفأر يرحل وبعد بضعة أيام وككل يوم\nملك الغابة يأخذ قيلولته إذ بالصيادي يلقي شبكته عليه ليمسك به فعلا قد وقع في الفخ\nبدأ الأسد بالزئير ليسمعه كل من في الغابة حتى الفأر الصغير سمع زئيره ليتذكر أنه\nمدين للأسد وعليه المساعدةوأن يرد المعروف بمثله لم يتردد صديقنا\nوذهب مسرعا ليرى ماحصل وعندما وصل وجد الأسد تحت الشباك\nتسلقها الفأر وبدأ بتمزيقها بأسنانه الحادة\nحتى مزقها بالكامل وأخيرا أنقذ الأسد من الفخ ورد له صنيعه ومن ذلك الحين والأسد صديق الفأر.\nهناك أصدقاء يعرفون عند الشدائد فلنتمسك بهم.\n</body><questions>\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimport re\n\ndef parse_custom_xml(file_path):\n    tree = ET.parse(file_path)\n    root = tree.getroot()\n\n    data = []\n    for texte in root.findall(\"texte\"):\n        raw_context = texte.find(\"body\").text or \"\"\n        context = re.sub(r'\\s+', ' ', raw_context).strip()\n        questions_block = texte.find(\"questions\").text\n\n        # Check and split questions using dash\n        if questions_block:\n            questions = [q.strip() for q in questions_block.strip().split(\"-\") if q.strip()]\n            for question in questions:\n                data.append({\"context\": context, \"question\": question})\n\n    return data\ndata = parse_custom_xml(\"/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml\")\nprint(f\"Total examples extracted: {len(data)}\")\nprint(data[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T15:33:18.964276Z","iopub.execute_input":"2025-05-03T15:33:18.964865Z","iopub.status.idle":"2025-05-03T15:33:19.140137Z","shell.execute_reply.started":"2025-05-03T15:33:18.964842Z","shell.execute_reply":"2025-05-03T15:33:19.139417Z"}},"outputs":[{"name":"stdout","text":"Total examples extracted: 1506\n{'context': 'في يوم من الأيام وفي أحد غابات إفريقيا، بينما كان أحد الفهود يتجول قرب ضفة النهر باحثا عن فريسة يسد بها رمقه، لمح قطيعا من الغزلان يرعى العشب على الضفة المقابلة. فقال في نفسه وهو ينظر إليها: \"ليتني أعرف السباحة، فأعبر النهر وأفترس غزالا أملئ به معدتي الخاوية.\" التفت الفهد يمنةً ويسرةً باحثاً عن شيء يمكنّه من العبور إلى الضفّة المقابلة، ولكن دون جدوى . ثم نظر وسط النهر فرأى فرس نهر يسبح في الماء ويأكل من الأعشاب التي نمت في قاعه. فكر الفهد قليلا ثم توجه إلى ضفة النهر وخاطب الفرس قائلا: \" السلام عليك يا ابن عمي \" فأجاب فرس النهر وقد بدت عليه علامات التعجب: \"وعليك السلام. كيف تكون ابن عمي وأنت لست من فصيلتي؟ فأنت تملك جسما رشيقا ومرقطا بينما جسمي ممتلئ وخال من البقع\" فأجاب الفهد في خبث: \" أنا من بلد بعيد حيث تكون أفراس النهر مرقطة ونحيلة.\" تظاهر فرس النهر بتصديق كلام الفهد ثم قال: \"حسن يا ابن عمي كيف يمكنني خدمتك؟\" فقال الفهد: \"هل يمكنك مساعدتي ونقلي على ظهرك الى الضفة المقابلة للنهر؟\" فكر فرس النهر قليلا ثم وافق وحمل الفهد على ضهره ليعبر به النهر. وفي منتصف الطريق توقف عن السباحة ثم قال: \"بما أنك فرس نهر فبإمكانك السباحة والغطس مثلي. أليس كذلك؟\" فأجاب الفهد مرتبكا : \"إم م م ... بالطبع يمكنني السباحة.\" وبينما كان الفهد يهمهم ويبحث في رأسه عن كلام مقنع، اذ بفرس النهر يغطس به الى اعماق النهر. فكانت تلك الغطسة درسا قاسيا للفهد الذي نجا بأعجوبة من الغرق. وهكذا نال الفهد الخبيث جزاء خداعه لفرس النهر واستخفافه بذكائه.', 'question': 'هل انخدع فرس النهر بكذبة الفهد؟'}\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"# Idea: Segmenting the context into phrases ","metadata":{}},{"cell_type":"code","source":"import re\n\ndef split_into_phrases(context):\n    # Split on common Arabic sentence-ending punctuation\n    phrases = re.split(r'[؟.!؟]', context)\n    # Remove empty and strip whitespace\n    phrases = [phrase.strip() for phrase in phrases if phrase.strip()]\n    return phrases\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T16:06:48.106074Z","iopub.execute_input":"2025-05-03T16:06:48.106362Z","iopub.status.idle":"2025-05-03T16:06:48.110696Z","shell.execute_reply.started":"2025-05-03T16:06:48.106341Z","shell.execute_reply":"2025-05-03T16:06:48.110092Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"context = data[10]['context']\n\nphrases = split_into_phrases(context)\nprint(phrases)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T16:07:27.866707Z","iopub.execute_input":"2025-05-03T16:07:27.867542Z","iopub.status.idle":"2025-05-03T16:07:27.872318Z","shell.execute_reply.started":"2025-05-03T16:07:27.867508Z","shell.execute_reply":"2025-05-03T16:07:27.871598Z"}},"outputs":[{"name":"stdout","text":"['في يوم من الأيام وفي أحد غابات إفريقيا، بينما كان أحد الفهود يتجول قرب ضفة النهر باحثا عن فريسة يسد بها رمقه، لمح قطيعا من الغزلان يرعى العشب على الضفة المقابلة', 'فقال في نفسه وهو ينظر إليها: \"ليتني أعرف السباحة، فأعبر النهر وأفترس غزالا أملئ به معدتي الخاوية', '\" التفت الفهد يمنةً ويسرةً باحثاً عن شيء يمكنّه من العبور إلى الضفّة المقابلة، ولكن دون جدوى', 'ثم نظر وسط النهر فرأى فرس نهر يسبح في الماء ويأكل من الأعشاب التي نمت في قاعه', 'فكر الفهد قليلا ثم توجه إلى ضفة النهر وخاطب الفرس قائلا: \" السلام عليك يا ابن عمي \" فأجاب فرس النهر وقد بدت عليه علامات التعجب: \"وعليك السلام', 'كيف تكون ابن عمي وأنت لست من فصيلتي', 'فأنت تملك جسما رشيقا ومرقطا بينما جسمي ممتلئ وخال من البقع\" فأجاب الفهد في خبث: \" أنا من بلد بعيد حيث تكون أفراس النهر مرقطة ونحيلة', '\" تظاهر فرس النهر بتصديق كلام الفهد ثم قال: \"حسن يا ابن عمي كيف يمكنني خدمتك', '\" فقال الفهد: \"هل يمكنك مساعدتي ونقلي على ظهرك الى الضفة المقابلة للنهر', '\" فكر فرس النهر قليلا ثم وافق وحمل الفهد على ضهره ليعبر به النهر', 'وفي منتصف الطريق توقف عن السباحة ثم قال: \"بما أنك فرس نهر فبإمكانك السباحة والغطس مثلي', 'أليس كذلك', '\" فأجاب الفهد مرتبكا : \"إم م م', 'بالطبع يمكنني السباحة', '\" وبينما كان الفهد يهمهم ويبحث في رأسه عن كلام مقنع، اذ بفرس النهر يغطس به الى اعماق النهر', 'فكانت تلك الغطسة درسا قاسيا للفهد الذي نجا بأعجوبة من الغرق', 'وهكذا نال الفهد الخبيث جزاء خداعه لفرس النهر واستخفافه بذكائه']\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"print(phrases[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:14:20.456189Z","iopub.execute_input":"2025-05-03T17:14:20.456717Z","iopub.status.idle":"2025-05-03T17:14:20.460603Z","shell.execute_reply.started":"2025-05-03T17:14:20.456692Z","shell.execute_reply":"2025-05-03T17:14:20.459788Z"}},"outputs":[{"name":"stdout","text":"في يوم من الأيام وفي أحد غابات إفريقيا، بينما كان أحد الفهود يتجول قرب ضفة النهر باحثا عن فريسة يسد بها رمقه، لمح قطيعا من الغزلان يرعى العشب على الضفة المقابلة\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}