{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/nadirfartas/pfenotebook?scriptVersionId=236321355\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:55:59.385133Z","iopub.execute_input":"2025-05-02T10:55:59.385682Z","iopub.status.idle":"2025-05-02T10:55:59.390129Z","shell.execute_reply.started":"2025-05-02T10:55:59.385660Z","shell.execute_reply":"2025-05-02T10:55:59.389284Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nsecret_label = \"HF Hub\"\nsecret_value = UserSecretsClient().get_secret(secret_label)\nlogin(token=secret_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:06:37.599301Z","iopub.execute_input":"2025-05-02T11:06:37.599729Z","iopub.status.idle":"2025-05-02T11:06:37.817105Z","shell.execute_reply.started":"2025-05-02T11:06:37.599705Z","shell.execute_reply":"2025-05-02T11:06:37.816585Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:06:41.059865Z","iopub.execute_input":"2025-05-02T11:06:41.060405Z","iopub.status.idle":"2025-05-02T11:06:47.832566Z","shell.execute_reply.started":"2025-05-02T11:06:41.060379Z","shell.execute_reply":"2025-05-02T11:06:47.831617Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install \\\n    datasets \\\n    evaluate \\\n    rouge_score\\\n    loralib \\\n    evaluate \\\n    accelerate \\\n    bitsandbytes \\\n    trl \\\n    peft \\\n    -U --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:51:34.750579Z","iopub.execute_input":"2025-05-03T13:51:34.751117Z","iopub.status.idle":"2025-05-03T13:53:03.662727Z","shell.execute_reply.started":"2025-05-03T13:51:34.751091Z","shell.execute_reply":"2025-05-03T13:53:03.661819Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:18:00.409499Z","iopub.execute_input":"2025-05-02T11:18:00.409793Z","iopub.status.idle":"2025-05-02T11:18:04.252339Z","shell.execute_reply.started":"2025-05-02T11:18:00.409766Z","shell.execute_reply":"2025-05-02T11:18:04.251776Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# 1. Preparing and loading Train and val dataset","metadata":{}},{"cell_type":"code","source":"def format_squad_dataset(dataset_split):\n    \"\"\"\n    Format a SQuAD-style dataset split into a list of dictionaries \n    with context, questions, and answers.\n\n    Args:\n        dataset_split: a split of the SQuAD-style dataset, e.g., ds[\"train\"] or ds[\"validation\"]\n\n    Returns:\n        A list of formatted entries: [{\"context\": ..., \"questions\": [...], \"answers\": [...]}]\n    \"\"\"\n    formatted = []\n\n    for article in dataset_split:\n        for paragraph in article[\"data\"]:\n            for p in paragraph[\"paragraphs\"]:\n                context = p[\"context\"]\n                questions = []\n                answers = []\n\n                for qa in p[\"qas\"]:\n                    if qa[\"is_impossible\"]:\n                        continue\n\n                    if not qa.get(\"answers\") or not qa[\"answers\"][0].get(\"text\"):\n                        continue\n\n                    question = qa[\"question\"]\n                    answer = qa[\"answers\"][0][\"text\"]\n\n                    questions.append(question)\n                    answers.append(answer)\n\n                if questions and answers:\n                    formatted.append({\n                        \"context\": context,\n                        \"questions\": questions,\n                        \"answers\": answers\n                    })\n\n    return formatted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:59:16.453724Z","iopub.execute_input":"2025-05-03T13:59:16.455101Z","iopub.status.idle":"2025-05-03T13:59:16.460723Z","shell.execute_reply.started":"2025-05-03T13:59:16.455065Z","shell.execute_reply":"2025-05-03T13:59:16.459968Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\n\n# Load dataset\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")\nformatted_train_dataset = format_squad_dataset(ds[\"train\"])\nformatted_val_dataset = format_squad_dataset(ds[\"validation\"])\n\nprint(f\"âœ… Done. Formatted {len(formatted_train_dataset)} training context blocks.\")\nprint(f\"âœ… Done. Formatted {len(formatted_val_dataset)} validation context blocks.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:18:04.260997Z","iopub.execute_input":"2025-05-02T11:18:04.261183Z","iopub.status.idle":"2025-05-02T11:18:14.953551Z","shell.execute_reply.started":"2025-05-02T11:18:04.261168Z","shell.execute_reply":"2025-05-02T11:18:14.952826Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d56093e552541759193672c0db94f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e409aab3ce64d2195892053b113e3ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c662b8a291dd4f9daece6e5bb4c77b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b148e4848dea4bf689bf9e0355cb2048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bc7a5b6bd044f66a6034eafc5d0c28d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f808f446d4f4451384553c69deb03847"}},"metadata":{}},{"name":"stdout","text":"âœ… Done. Formatted 17180 training context blocks.\nâœ… Done. Formatted 4639 validation context blocks.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def flatten_context_qa_pairs(formatted_data):\n    \"\"\"\n    Convert formatted context-question-answer data into a flat list of\n    input-target training pairs for seq2seq modeling.\n\n    Args:\n        formatted_data: List of dicts with 'context', 'questions', and 'answers'\n\n    Returns:\n        A list of dicts with 'input' and 'target' fields\n    \"\"\"\n    flat_data = []\n\n    for item in formatted_data:\n        context = item[\"context\"]\n        for question, answer in zip(item[\"questions\"], item[\"answers\"]):\n            input_text = f\"context: {context} answer: {answer}\"\n            target_text = question\n            flat_data.append({\"input\": input_text, \"target\": target_text})\n\n    return flat_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:59:20.643647Z","iopub.execute_input":"2025-05-03T13:59:20.643943Z","iopub.status.idle":"2025-05-03T13:59:20.648990Z","shell.execute_reply.started":"2025-05-03T13:59:20.643920Z","shell.execute_reply":"2025-05-03T13:59:20.648258Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_dataset = flatten_context_qa_pairs(formatted_train_dataset)\nval_dataset = flatten_context_qa_pairs(formatted_val_dataset)\nprint(f\"Total training pairs: {len(train_dataset)}\")\nprint(f\"Total validation pairs: {len(val_dataset)}\")\nprint(train_dataset[1])\nprint(val_dataset[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:18:14.960313Z","iopub.execute_input":"2025-05-02T11:18:14.960553Z","iopub.status.idle":"2025-05-02T11:18:15.478915Z","shell.execute_reply.started":"2025-05-02T11:18:14.960538Z","shell.execute_reply":"2025-05-02T11:18:15.478126Z"}},"outputs":[{"name":"stdout","text":"Total training pairs: 42033\nTotal validation pairs: 5254\n{'input': 'context: ( Ù„Ù… ÙŠÙƒÙ† Ø²Ù„Ø²Ø§Ù„ Ms 6 . 1 ÙÙŠ 30 Ø£ØºØ³Ø·Ø³ 2008 ÙÙŠ Ø¬Ù†ÙˆØ¨ Ø³ÙŠØªØ´ÙˆØ§Ù† Ø¬Ø²Ø¡Ø§ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù„Ø£Ù†Ù‡ ÙƒØ§Ù† Ù†Ø§Ø¬Ù…Ø§ Ø¹Ù† ØµØ¯Ø¹ Ù…Ø®ØªÙ„Ù . Ø§Ù†Ø¸Ø± Ø²Ù„Ø²Ø§Ù„ Ø¨Ø§Ù†ØªØ´ÙŠÙ‡ÙˆØ§ 2008 Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ . ) answer: Ø²Ù„Ø²Ø§Ù„ Ø¨Ø§Ù†ØªØ´ÙŠÙ‡ÙˆØ§ 2008', 'target': 'Ø£ÙŠÙ† ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ø­Ø« Ø¹Ù† Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ ØŸ'}\n{'input': 'context: ØºØ§Ø¯Ø± ÙØ±ÙŠÙ‚ Ø§Ù„Ø¥ØºØ§Ø«Ø© Ø§Ù„Ø·Ø§Ø±Ø¦Ø© Ù…Ù† Ø§Ù„Ø²Ù„Ø§Ø²Ù„ Ø§Ù„Ù…ÙƒÙˆÙ† Ù…Ù† 184 Ø´Ø®ØµØ§ ( ÙŠØªØ£Ù„Ù Ù…Ù† 12 Ø´Ø®ØµØ§ Ù…Ù† Ù…ÙƒØªØ¨ Ø§Ù„Ø¯ÙˆÙ„Ø© Ù„Ø±ØµØ¯ Ø§Ù„Ø²Ù„Ø§Ø²Ù„ Ùˆ 150 Ù…Ù† Ù‚ÙŠØ§Ø¯Ø© Ù…Ù†Ø·Ù‚Ø© Ø¨ÙƒÙŠÙ† Ø§Ù„Ø¹Ø³ÙƒØ±ÙŠØ© Ùˆ 22 Ù…Ù† Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø´Ø±Ø·Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ø§Ù„Ù…Ø³Ù„Ø­Ø© ) Ø¨ÙƒÙŠÙ† Ù…Ù† Ù…Ø·Ø§Ø± Ù†Ø§Ù†ÙŠÙˆØ§Ù† ÙÙŠ Ø£ÙˆØ§Ø®Ø± 12 Ù…Ø§ÙŠÙˆ ÙÙŠ Ø·Ø§Ø¦Ø±ØªÙŠ Ù†Ù‚Ù„ Ø¹Ø³ÙƒØ±ÙŠØªÙŠÙ† Ù„Ù„Ø³ÙØ± Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹Ø© ÙˆÙ†ØªØ´ÙˆØ§Ù† . answer: 184', 'target': 'ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø®Ø§Øµ Ø§Ù„Ø°ÙŠÙ† Ø´ÙƒÙ„ÙˆØ§ ÙØ±ÙŠÙ‚ Ø§Ù„Ø¥ØºØ§Ø«Ø© ØŸ'}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from transformers import T5Tokenizer, AutoModelForSeq2SeqLM\nfrom datasets import Dataset\n\n# Load tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\", legacy=False)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\")\n# Convert list to Hugging Face Dataset\nhf_train_dataset = Dataset.from_list(train_dataset)\nhf_val_dataset = Dataset.from_list(val_dataset)\n\n# Tokenize function\ndef tokenize(example):\n    model_input = tokenizer(\n        example[\"input\"], \n        max_length=512, \n        padding=\"max_length\", \n        truncation=True\n    )\n    labels = tokenizer(\n        example[\"target\"], \n        max_length=64, \n        padding=\"max_length\", \n        truncation=True\n    )\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\n# Apply tokenizer\ntokenized_train_dataset = hf_train_dataset.map(tokenize, batched=False)\ntokenized_val_dataset = hf_val_dataset.map(tokenize, batched=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:19:29.772013Z","iopub.execute_input":"2025-05-02T11:19:29.772687Z","iopub.status.idle":"2025-05-02T11:20:56.780295Z","shell.execute_reply.started":"2025-05-02T11:19:29.772663Z","shell.execute_reply":"2025-05-02T11:20:56.779598Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/42033 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"057a65c5d0734d24888ae3f0b316542b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5254 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09fea35bd1a9447a96cc5dabce501f2d"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:22:18.448549Z","iopub.execute_input":"2025-05-02T11:22:18.448891Z","iopub.status.idle":"2025-05-02T11:22:19.116484Z","shell.execute_reply.started":"2025-05-02T11:22:18.448859Z","shell.execute_reply":"2025-05-02T11:22:19.115655Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nDevice: cuda\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# 2. Training the model","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./araT5-qg\",\n    run_name=\"araT5-qg-run-1\",\n    learning_rate=2e-5,                           # standard LR for T5 fine-tuning\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    save_total_limit=1,                           # keep only 2 latest checkpoints\n    eval_strategy=\"epoch\",           # use eval_strategy (not evaluation_strategy)\n    save_strategy=\"epoch\",\n    fp16=True, \n    metric_for_best_model=\"loss\",\n    greater_is_better=False,\n    load_best_model_at_end=False,\n    report_to=\"none\",                             # no wandb/huggingface reporting\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n)\n\n# Start training\ntrainer.train()\n\n# Save final model and tokenizer\nmodel.save_pretrained(\"./araT5-qg-final\")\ntokenizer.save_pretrained(\"./araT5-qg-final\")\n\nprint(\"âœ… Training complete! Model and tokenizer saved to './araT5-qg-final'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T11:22:26.799862Z","iopub.execute_input":"2025-05-02T11:22:26.800148Z","iopub.status.idle":"2025-05-02T15:12:41.399851Z","shell.execute_reply.started":"2025-05-02T11:22:26.800126Z","shell.execute_reply":"2025-05-02T15:12:41.398989Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2099068984.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7884' max='7884' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7884/7884 3:50:06, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.486000</td>\n      <td>0.391099</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.453800</td>\n      <td>0.377061</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.445300</td>\n      <td>0.373185</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"âœ… Training complete! Model and tokenizer saved to './araT5-qg-final'\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:16:22.851495Z","iopub.execute_input":"2025-05-02T15:16:22.852219Z","iopub.status.idle":"2025-05-02T15:16:25.227444Z","shell.execute_reply.started":"2025-05-02T15:16:22.852196Z","shell.execute_reply":"2025-05-02T15:16:25.226448Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# 3. Hosting the Model in HuggingFace Hub","metadata":{}},{"cell_type":"code","source":"# Go to the saved model directory\n%cd /kaggle/working/araT5-qg-final\n\n# Initialize Git repo (if not already a repo)\n!git init\n\n# Configure your identity\n!git config user.email \"fartasnadir2003@gmail.com\"\n!git config user.name \"NadirFartas\"\n\n# Link to your Hugging Face repo\n!git remote add origin https://huggingface.co/NadirFartas/araT5-qg-final\n\n# Add and commit files\n!git add .\n!git commit -m \"Initial commit of AraT5 fine-tuned model\"\n\n# Set the branch to main\n!git branch -M main\n\n# Push to Hugging Face\n!git push origin main\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:51:59.609988Z","iopub.execute_input":"2025-05-02T15:51:59.610294Z","iopub.status.idle":"2025-05-02T15:52:11.176094Z","shell.execute_reply.started":"2025-05-02T15:51:59.610270Z","shell.execute_reply":"2025-05-02T15:52:11.175060Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nReinitialized existing Git repository in /kaggle/working/araT5-qg-final/.git/\nerror: remote origin already exists.\nOn branch main\nnothing to commit, working tree clean\nUsername for 'https://huggingface.co': ^C\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Go to the saved model directory\n%cd /kaggle/working/araT5-qg-final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:43:23.397591Z","iopub.execute_input":"2025-05-02T15:43:23.397951Z","iopub.status.idle":"2025-05-02T15:43:23.403264Z","shell.execute_reply.started":"2025-05-02T15:43:23.397920Z","shell.execute_reply":"2025-05-02T15:43:23.402459Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Initialize Git repo (if not already a repo)\n!git init","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:43:33.119502Z","iopub.execute_input":"2025-05-02T15:43:33.119969Z","iopub.status.idle":"2025-05-02T15:43:33.344388Z","shell.execute_reply.started":"2025-05-02T15:43:33.119944Z","shell.execute_reply":"2025-05-02T15:43:33.343606Z"}},"outputs":[{"name":"stdout","text":"Reinitialized existing Git repository in /kaggle/working/araT5-qg-final/.git/\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"!git config user.email \"fartasnadir2003@gmail.com\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:43:47.821547Z","iopub.execute_input":"2025-05-02T15:43:47.822222Z","iopub.status.idle":"2025-05-02T15:43:48.049607Z","shell.execute_reply.started":"2025-05-02T15:43:47.822194Z","shell.execute_reply":"2025-05-02T15:43:48.048535Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"!git config user.name \"NadirFartas\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:44:00.975924Z","iopub.execute_input":"2025-05-02T15:44:00.976215Z","iopub.status.idle":"2025-05-02T15:44:01.201142Z","shell.execute_reply.started":"2025-05-02T15:44:00.976192Z","shell.execute_reply":"2025-05-02T15:44:01.200188Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Add and commit files\n!git add .\n!git commit -m \"Initial commit of AraT5 fine-tuned model\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:09:34.977890Z","iopub.execute_input":"2025-05-02T16:09:34.978569Z","iopub.status.idle":"2025-05-02T16:09:35.434595Z","shell.execute_reply.started":"2025-05-02T16:09:34.978539Z","shell.execute_reply":"2025-05-02T16:09:35.433850Z"}},"outputs":[{"name":"stdout","text":"On branch main\nnothing to commit, working tree clean\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:48:21.870599Z","iopub.execute_input":"2025-05-02T15:48:21.870938Z","iopub.status.idle":"2025-05-02T15:48:22.106783Z","shell.execute_reply.started":"2025-05-02T15:48:21.870907Z","shell.execute_reply":"2025-05-02T15:48:22.105767Z"}},"outputs":[{"name":"stdout","text":"added_tokens.json\tmodel.safetensors\t spiece.model\nconfig.json\t\tREADME.md\t\t tokenizer_config.json\ngeneration_config.json\tspecial_tokens_map.json\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"!git branch -M main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:09:44.515535Z","iopub.execute_input":"2025-05-02T16:09:44.516193Z","iopub.status.idle":"2025-05-02T16:09:44.741636Z","shell.execute_reply.started":"2025-05-02T16:09:44.516167Z","shell.execute_reply":"2025-05-02T16:09:44.740781Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"!git remote set-url origin https://NadirFartas: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@huggingface.co/NadirFartas/araT5-qg-final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:08:57.600136Z","iopub.execute_input":"2025-05-02T16:08:57.600644Z","iopub.status.idle":"2025-05-02T16:08:57.829709Z","shell.execute_reply.started":"2025-05-02T16:08:57.600620Z","shell.execute_reply":"2025-05-02T16:08:57.828648Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"!git push origin main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:10:04.230279Z","iopub.execute_input":"2025-05-02T16:10:04.231028Z","iopub.status.idle":"2025-05-02T16:10:20.381245Z","shell.execute_reply.started":"2025-05-02T16:10:04.230982Z","shell.execute_reply":"2025-05-02T16:10:20.380133Z"}},"outputs":[{"name":"stdout","text":"Uploading LFS objects: 100% (2/2), 1.5 GB | 102 MB/s, done.                     \nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 4 threads\nCompressing objects: 100% (9/9), done.\nWriting objects: 100% (9/9), 3.22 KiB | 1.61 MiB/s, done.\nTotal 9 (delta 0), reused 0 (delta 0), pack-reused 0\nTo https://huggingface.co/NadirFartas/araT5-qg-final\n   10f9fa8..3995e3f  main -> main\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"# 4. Loading the model and Dataset for test","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom datasets import load_dataset\nimport json\n\n# Load dataset\nds = load_dataset(\"ZeyadAhmed/Arabic-SQuADv2.0\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"NadirFartas/araT5-qg-final\")\ntokenizer = AutoTokenizer.from_pretrained(\"NadirFartas/araT5-qg-final\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:57:42.493605Z","iopub.execute_input":"2025-05-03T13:57:42.493895Z","iopub.status.idle":"2025-05-03T13:58:37.065129Z","shell.execute_reply.started":"2025-05-03T13:57:42.493872Z","shell.execute_reply":"2025-05-03T13:58:37.064284Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"asquadv2-train.json:   0%|          | 0.00/91.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b0b1ec98b4450ea72aa19f294a809e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-val.json:   0%|          | 0.00/27.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5209e2dfdcb4443fbc0b86f0632bf973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"asquadv2-test.json:   0%|          | 0.00/27.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764a9267afb844a0a36478711c81c782"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"004f51ac8dda4a7dae91186e5058fdcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eee8edd4f1644213a20dd465c0581dac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a548ae9aa2c4140bec170c284b7015c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec9e39f3fb3447b8401c7e451a508f6"}},"metadata":{}},{"name":"stderr","text":"2025-05-03 13:58:10.719137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746280691.137737      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746280691.247581      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b7840044c649d6a885bf88383e6d3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fa7d0265cca4ea2addc8f96359c19a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a3d9b9df50e43fa9b306f454a9b3e55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abae1dfc3fd24bdfbfa5361d2d384a4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a95dded99d5f411c9fd21fb236dc907a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50630a1dcc9447db81630d0916612a7f"}},"metadata":{}},{"name":"stderr","text":"You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# 5. Preparing the Test Dataset","metadata":{}},{"cell_type":"code","source":"formatted_test_dataset = format_squad_dataset(ds[\"test\"])\ntest_dataset = flatten_context_qa_pairs(formatted_test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:59:34.523416Z","iopub.execute_input":"2025-05-03T13:59:34.524142Z","iopub.status.idle":"2025-05-03T13:59:34.871695Z","shell.execute_reply.started":"2025-05-03T13:59:34.524110Z","shell.execute_reply":"2025-05-03T13:59:34.870942Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(f\"Total test pairs: {len(test_dataset)}\")\nprint(test_dataset[4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:59:45.404189Z","iopub.execute_input":"2025-05-03T13:59:45.405042Z","iopub.status.idle":"2025-05-03T13:59:45.409568Z","shell.execute_reply.started":"2025-05-03T13:59:45.405009Z","shell.execute_reply":"2025-05-03T13:59:45.408763Z"}},"outputs":[{"name":"stdout","text":"Total test pairs: 5254\n{'input': 'context: Ø¨Ø­Ù„ÙˆÙ„ 15 Ù…Ø§ÙŠÙˆ ØŒ Ø£Ù…Ø± Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¯ÙˆÙ„Ø© ÙˆÙ† Ø¬ÙŠØ§Ø¨Ø§Ùˆ Ø¨Ù†Ø´Ø± 90 Ø·Ø§Ø¦Ø±Ø© Ù‡Ù„ÙŠÙƒÙˆØ¨ØªØ± Ø¥Ø¶Ø§ÙÙŠØ© ØŒ Ù…Ù†Ù‡Ø§ 60 Ø·Ø§Ø¦Ø±Ø© Ù…Ù‚Ø¯Ù…Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ø§Ù„ØµÙŠÙ†ÙŠ ØŒ Ùˆ 30 Ø·Ø§Ø¦Ø±Ø© Ù…Ù† Ø§Ù„Ù…Ù‚Ø±Ø± Ø£Ù† ØªÙˆÙØ±Ù‡Ø§ ØµÙ†Ø§Ø¹Ø© Ø§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„Ù…Ø¯Ù†ÙŠ ØŒ Ù„ÙŠØµÙ„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ù†Ø´Ø±Ù‡Ø§ ÙÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥ØºØ§Ø«Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø¬ÙˆÙŠØ© ÙˆØ§Ù„Ø¬ÙŠØ´ ÙˆØ§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„Ù…Ø¯Ù†ÙŠ Ø¥Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† 150 ØŒ Ù…Ù…Ø§ Ø£Ø¯Ù‰ Ø¥Ù„Ù‰ Ø£ÙƒØ¨Ø± Ø¹Ù…Ù„ÙŠØ© Ù†Ù‚Ù„ Ø¬ÙˆÙŠ ØºÙŠØ± Ù‚ØªØ§Ù„ÙŠØ© ÙÙŠ ØªØ§Ø±ÙŠØ® Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ . answer: Ù†Ø´Ø± 90 Ø·Ø§Ø¦Ø±Ø© Ù‡Ù„ÙŠÙƒÙˆØ¨ØªØ± Ø¥Ø¶Ø§ÙÙŠØ©', 'target': 'Ù…Ø§Ø°Ø§ Ø·Ù„Ø¨ Ø±Ø¦ÙŠØ³ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ ÙˆÙ† Ø¬ÙŠØ§Ø¨Ø§Ùˆ ØŸ'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# 6. Testing the Model","metadata":{}},{"cell_type":"markdown","source":"**Exemple 1:**","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef generate_question_from_input(input_text, max_length=64):\n    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n    outputs = model.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)\n    question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return question\n\n# Pick a test example\nsample = test_dataset[3]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text)\n\n# Show results\nprint(\"ğŸ“¥ Input to the model:\\n\", input_text)\nprint(\"\\nâœ… Dataset Question:\\n\", real_question)\nprint(\"\\nğŸ¤– Generated Questions:\\n\", generated_question)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:10:52.535151Z","iopub.execute_input":"2025-05-03T17:10:52.535707Z","iopub.status.idle":"2025-05-03T17:10:54.000123Z","shell.execute_reply.started":"2025-05-03T17:10:52.535685Z","shell.execute_reply":"2025-05-03T17:10:53.999298Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Input to the model:\n context: Ø¨Ø­Ù„ÙˆÙ„ 15 Ù…Ø§ÙŠÙˆ ØŒ Ø£Ù…Ø± Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¯ÙˆÙ„Ø© ÙˆÙ† Ø¬ÙŠØ§Ø¨Ø§Ùˆ Ø¨Ù†Ø´Ø± 90 Ø·Ø§Ø¦Ø±Ø© Ù‡Ù„ÙŠÙƒÙˆØ¨ØªØ± Ø¥Ø¶Ø§ÙÙŠØ© ØŒ Ù…Ù†Ù‡Ø§ 60 Ø·Ø§Ø¦Ø±Ø© Ù…Ù‚Ø¯Ù…Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ø§Ù„ØµÙŠÙ†ÙŠ ØŒ Ùˆ 30 Ø·Ø§Ø¦Ø±Ø© Ù…Ù† Ø§Ù„Ù…Ù‚Ø±Ø± Ø£Ù† ØªÙˆÙØ±Ù‡Ø§ ØµÙ†Ø§Ø¹Ø© Ø§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„Ù…Ø¯Ù†ÙŠ ØŒ Ù„ÙŠØµÙ„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ù†Ø´Ø±Ù‡Ø§ ÙÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥ØºØ§Ø«Ø© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø¬ÙˆÙŠØ© ÙˆØ§Ù„Ø¬ÙŠØ´ ÙˆØ§Ù„Ø·ÙŠØ±Ø§Ù† Ø§Ù„Ù…Ø¯Ù†ÙŠ Ø¥Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† 150 ØŒ Ù…Ù…Ø§ Ø£Ø¯Ù‰ Ø¥Ù„Ù‰ Ø£ÙƒØ¨Ø± Ø¹Ù…Ù„ÙŠØ© Ù†Ù‚Ù„ Ø¬ÙˆÙŠ ØºÙŠØ± Ù‚ØªØ§Ù„ÙŠØ© ÙÙŠ ØªØ§Ø±ÙŠØ® Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ . answer: Ø£ÙƒØ«Ø± Ù…Ù† 150\n\nâœ… Dataset Question:\n ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªÙŠ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ ØŸ\n\nğŸ¤– Generated Questions:\n ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ù†Ø´Ø±Ù‡Ø§ ÙÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥ØºØ§Ø«Ø© ØŸ\n","output_type":"stream"}],"execution_count":81},{"cell_type":"markdown","source":"**Exemple 2:**","metadata":{}},{"cell_type":"code","source":"# Pick a test example\nsample = test_dataset[8]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text)\n\n# Show results\nprint(\"ğŸ“¥ Input to the model:\\n\", input_text)\nprint(\"\\nâœ… Dataset Question:\\n\", real_question)\nprint(\"\\nğŸ¤– Generated Questions:\\n\", generated_question)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:10:58.099067Z","iopub.execute_input":"2025-05-03T17:10:58.099540Z","iopub.status.idle":"2025-05-03T17:10:59.792120Z","shell.execute_reply.started":"2025-05-03T17:10:58.099516Z","shell.execute_reply":"2025-05-03T17:10:59.790738Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Input to the model:\n context: ÙÙŠ ÙŠÙˆÙ… Ø§Ù„Ø·ÙÙ„ ØŒ 1 ÙŠÙˆÙ†ÙŠÙˆ - Ø­Ø²ÙŠØ±Ø§Ù† 2008 ØŒ Ø°Ù‡Ø¨ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¢Ø¨Ø§Ø¡ Ø¥Ù„Ù‰ Ø£Ù†Ù‚Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ù„Ù„Ø­Ø¯Ø§Ø¯ Ø¹Ù„Ù‰ Ø£Ø·ÙØ§Ù„Ù‡Ù… . ÙˆÙ‚Ø§Ù… Ø§Ù„Ø£Ø·ÙØ§Ù„ Ø§Ù„Ù†Ø§Ø¬ÙˆÙ† ØŒ Ø§Ù„Ø°ÙŠÙ† ÙƒØ§Ù† Ù…Ø¹Ø¸Ù…Ù‡Ù… ÙŠØ¹ÙŠØ´ÙˆÙ† ÙÙŠ Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ø¥ØºØ§Ø«Ø© ØŒ Ø¨Ù…Ø±Ø§Ø³Ù… Ø§Ù„Ø§Ø­ØªÙØ§Ù„ Ø¨Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø®Ø§Øµ ØŒ Ù„ÙƒÙ†Ù‡Ù… Ø§Ø¹ØªØ±ÙÙˆØ§ Ø£ÙŠØ¶Ø§ Ø¨Ø§Ù„Ø²Ù„Ø²Ø§Ù„ . answer: ÙŠÙˆÙ… Ø§Ù„Ø·ÙÙ„\n\nâœ… Dataset Question:\n Ù…Ø§Ø°Ø§ ÙƒØ§Ù† ÙŠØ³Ù…Ù‰ 1 ÙŠÙˆÙ†ÙŠÙˆ 2008 ØŸ\n\nğŸ¤– Generated Questions:\n ÙÙŠ Ø£ÙŠ ÙŠÙˆÙ… Ø°Ù‡Ø¨ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¢Ø¨Ø§Ø¡ Ø¥Ù„Ù‰ Ø£Ù†Ù‚Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ù„Ù„Ø­Ø¯Ø§Ø¯ Ø¹Ù„Ù‰ Ø£Ø·ÙØ§Ù„Ù‡Ù… ØŸ\n","output_type":"stream"}],"execution_count":82},{"cell_type":"markdown","source":"**Exemple 3:**","metadata":{}},{"cell_type":"code","source":"# Pick a test example\nsample = test_dataset[65]\ninput_text = sample[\"input\"]\nreal_question = sample[\"target\"]\n\n# Generate question\ngenerated_question = generate_question_from_input(input_text)\n\n# Show results\nprint(\"ğŸ“¥ Input to the model:\\n\", input_text)\nprint(\"\\nâœ… Dataset Question:\\n\", real_question)\nprint(\"\\nğŸ¤– Generated Questions:\\n\", generated_question)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:11:02.183240Z","iopub.execute_input":"2025-05-03T17:11:02.183907Z","iopub.status.idle":"2025-05-03T17:11:04.521184Z","shell.execute_reply.started":"2025-05-03T17:11:02.183882Z","shell.execute_reply":"2025-05-03T17:11:04.520333Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Input to the model:\n context: ÙˆÙÙŠ Ø£Ø¹Ù‚Ø§Ø¨ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„ØªÙŠ ÙˆÙ‚Ø¹Øª ÙÙŠ Ø£ÙˆÙ„Ù…Ø¨ÙŠØ§ ØŒ ÙˆØ±Ø¯Øª ØªÙ‚Ø§Ø±ÙŠØ± ØªÙÙŠØ¯ Ø¨Ø£Ù† Ø§Ù„ØµÙŠÙ† Ø·Ù„Ø¨Øª Ø§Ù„Ø¥Ø°Ù† Ø¨Ù†Ø´Ø± Ø£ÙØ±Ø§Ø¯ Ù…Ù† Ø¬ÙŠØ´ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ø§Ù„ØµÙŠÙ†ÙŠ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø·Ø±ÙŠÙ‚ Ø§Ù„ØªØªØ§Ø¨Ø¹ Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø´Ø¹Ù„Ø© ÙÙŠ ÙƒØ§Ù†Ø¨ÙŠØ±Ø§ . ÙˆØ°ÙƒØ±Øª Ø§Ù„Ø³Ù„Ø·Ø§Øª Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠØ© Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø·Ù„Ø¨ ØŒ Ø¥Ø°Ø§ Ù…Ø§ Ù‚Ø¯Ù… ØŒ Ø³ÙŠØ±ÙØ¶ . ÙˆÙˆØµÙ Ù…Ø³Ø¤ÙˆÙ„ÙˆÙ† ØµÙŠÙ†ÙŠÙˆÙ† Ø§Ù„Ø£Ù…Ø± Ø¨Ø£Ù†Ù‡ Ø´Ø§Ø¦Ø¹Ø© . Ù…Ù†Ø­Øª Ø§Ù„Ø´Ø±Ø·Ø© Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠØ© ØµÙ„Ø§Ø­ÙŠØ§Øª ØªÙØªÙŠØ´ Ø§Ù„Ù…ØªÙØ±Ø¬ÙŠÙ† ÙÙŠ Ø§Ù„ØªØªØ§Ø¨Ø¹ ØŒ Ø¨Ø¹Ø¯ Ø¯Ø¹ÙˆØ© Ø£Ø·Ù„Ù‚ØªÙ‡Ø§ Ø±Ø§Ø¨Ø·Ø© Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØ§Ù„Ø¹Ù„Ù…Ø§Ø¡ Ø§Ù„ØµÙŠÙ†ÙŠÙŠÙ† Ù„Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„ØµÙŠÙ†ÙŠÙŠÙ† Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠÙŠÙ† Ø¥Ù„Ù‰ \" Ø§Ù„Ø¯ÙØ§Ø¹ Ø¹Ù† Ø´Ø¹Ù„ØªÙ†Ø§ Ø§Ù„Ù…Ù‚Ø¯Ø³Ø© \" Ø¶Ø¯ \" Ø­Ø«Ø§Ù„Ø© Ø¹Ø±Ù‚ÙŠØ© Ù…Ù†Ø­Ø·Ø© ÙˆØ§Ù†ÙØµØ§Ù„ÙŠÙŠÙ† Ù…Ù†Ø§Ù‡Ø¶ÙŠÙ† Ù„Ù„ØµÙŠÙ† \" . ÙˆÙ‚Ø§Ù„ ØªÙˆÙ†ÙŠ Ø¬ÙˆÙ‡ ØŒ Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠ Ù„Ù„Ù…Ù†Ø¸Ù…Ø§Øª Ø§Ù„ØµÙŠÙ†ÙŠØ© ØŒ Ø¥Ù† Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ø³ØªØ£Ø®Ø° \" Ø§Ù„Ø¢Ù„Ø§Ù \" Ù…Ù† Ø§Ù„Ù…ØªØ¸Ø§Ù‡Ø±ÙŠÙ† Ø§Ù„Ù…Ø¤ÙŠØ¯ÙŠÙ† Ù„Ø¨ÙƒÙŠÙ† Ø¥Ù„Ù‰ ÙƒØ§Ù†Ø¨ÙŠØ±Ø§ Ø¨Ø§Ù„Ø­Ø§ÙÙ„Ø© ØŒ Ù„Ø¯Ø¹Ù… ØªØªØ§Ø¨Ø¹ Ø§Ù„Ø´Ø¹Ù„Ø© . ÙˆÙ‚Ø§Ù„ ØªØ´Ø§Ù†Øº Ø±ÙˆÙ†ØºØ§Ù† ØŒ ÙˆÙ‡Ùˆ Ø·Ø§Ù„Ø¨ Ø£Ø³ØªØ±Ø§Ù„ÙŠ ØµÙŠÙ†ÙŠ ÙŠÙ†Ø¸Ù… Ù…Ø¸Ø§Ù‡Ø±Ø§Øª Ù…Ø¤ÙŠØ¯Ø© Ù„Ø¨ÙƒÙŠÙ† ØŒ Ù„Ù„ØµØ­Ø§ÙØ© Ø¥Ù† Ø¯Ø¨Ù„ÙˆÙ…Ø§Ø³ÙŠÙŠÙ† ØµÙŠÙ†ÙŠÙŠÙ† ÙŠØ³Ø§Ø¹Ø¯ÙˆÙ† ÙÙŠ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø­Ø§ÙÙ„Ø§Øª ÙˆØ§Ù„ÙˆØ¬Ø¨Ø§Øª ÙˆØ§Ù„Ø¥Ù‚Ø§Ù…Ø© Ù„Ù„Ù…ØªØ¸Ø§Ù‡Ø±ÙŠÙ† Ø§Ù„Ù…Ø¤ÙŠØ¯ÙŠÙ† Ù„Ø¨ÙƒÙŠÙ† ØŒ ÙˆÙŠØ³Ø§Ø¹Ø¯ÙˆÙ†Ù‡Ù… Ø¹Ù„Ù‰ ØªÙ†Ø¸ÙŠÙ… \" Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø³Ù„Ù…ÙŠ Ù„Ù„Ù‚ÙˆØ© \" . ÙˆÙ‚Ø§Ù„ ÙˆØ²ÙŠØ± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø³ØªÙŠÙÙ† Ø³Ù…ÙŠØ« Ø¥Ù† Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠÙ† Ø§Ù„ØµÙŠÙ†ÙŠÙŠÙ† ÙŠØ­Ø«ÙˆÙ† Ø£Ù†ØµØ§Ø±Ù‡Ù… Ø¹Ù„Ù‰ \" Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ·Ø±Ø­ ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± \" Ù„ÙƒÙ†Ù‡ Ù„ÙŠØ³ Ù„Ø¯ÙŠÙ‡ Ø§Ø¹ØªØ±Ø§Ø¶ Ø¹Ù„Ù‰ Ø°Ù„Ùƒ Ø·Ø§Ù„Ù…Ø§ Ø¸Ù„ÙˆØ§ Ø³Ù„Ù…ÙŠÙŠÙ† . answer: Ø³ØªÙŠÙÙ† Ø³Ù…ÙŠØ«\n\nâœ… Dataset Question:\n Ù…Ù† Ù‡Ùˆ ÙˆØ²ÙŠØ± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø§Ù„Ø°ÙŠ Ù‚Ø§Ù„ Ø¥Ù†Ù‡ Ù…ÙˆØ§ÙÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø­ØªØ¬Ø§Ø¬Ø§Øª Ø·Ø§Ù„Ù…Ø§ ÙƒØ§Ù†Øª Ø³Ù„Ù…ÙŠØ© ØŸ\n\nğŸ¤– Generated Questions:\n Ù…Ù† Ù‚Ø§Ù„ Ø¥Ù† Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠÙ† Ø§Ù„ØµÙŠÙ†ÙŠÙŠÙ† ÙŠØ­Ø«ÙˆÙ† Ø£Ù†ØµØ§Ø±Ù‡Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ·Ø±Ø­ ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± ØŸ\n","output_type":"stream"}],"execution_count":83},{"cell_type":"markdown","source":"# 7. Evaluating the Model","metadata":{}},{"cell_type":"code","source":"import evaluate\n\nrouge = evaluate.load(\"rouge\")\nbleu = evaluate.load(\"bleu\")\npredictions = []\nreferences = []\n\nfor sample in test_dataset[:500]:  # evaluate on a subset to be faster\n    input_text = sample[\"input\"]\n    reference = sample[\"target\"]\n    \n    # Generate question\n    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n    outputs = model.generate(inputs, max_length=64, num_beams=4)\n    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    predictions.append(generated)\n    references.append(reference)\n\n# ROUGE expects dict with lists\nrouge_result = rouge.compute(predictions=predictions, references=references)\nprint(\"ğŸ” ROUGE scores:\")\nprint(rouge_result)\n\n# BLEU expects references as list of lists\nbleu_result = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\nprint(\"\\nğŸ” BLEU score:\")\nprint(bleu_result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T17:07:21.542043Z","iopub.execute_input":"2025-05-02T17:07:21.542300Z","iopub.status.idle":"2025-05-02T17:21:28.317893Z","shell.execute_reply.started":"2025-05-02T17:07:21.542284Z","shell.execute_reply":"2025-05-02T17:21:28.317108Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"000dce57b6ad43dca2df0137fa856765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a58b06f455104dfaad04705c1abcfac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfe45baa49dd4674b26553715801b27c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f86a14f1fab04f53b2b75cb1d6d579b0"}},"metadata":{}},{"name":"stdout","text":"ğŸ” ROUGE scores:\n{'rouge1': 0.08273333333333334, 'rouge2': 0.018166666666666664, 'rougeL': 0.08276666666666666, 'rougeLsum': 0.08233333333333331}\n\nğŸ” BLEU score:\n{'bleu': 0.17064651710073242, 'precisions': [0.4323908443931525, 0.20429878697595233, 0.12502976899261728, 0.07677750743444174], 'brevity_penalty': 1.0, 'length_ratio': 1.0186128526645768, 'translation_length': 5199, 'reference_length': 5104}\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"# 8. Corpus XML preparation","metadata":{}},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\n\n# Load XML\ntree = ET.parse('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml')  \nroot = tree.getroot()\n\n# Print tag names of the first few elements\nfor child in root.iter():\n    print(child.tag)\n    break  # remove this break to see more tags if needed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T14:33:23.884533Z","iopub.execute_input":"2025-05-03T14:33:23.884826Z","iopub.status.idle":"2025-05-03T14:33:23.941105Z","shell.execute_reply.started":"2025-05-03T14:33:23.884804Z","shell.execute_reply":"2025-05-03T14:33:23.940416Z"}},"outputs":[{"name":"stdout","text":"corpus\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"with open('/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml', 'r', encoding='utf-8') as f:\n    for _ in range(20):\n        print(f.readline().strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T14:34:07.873831Z","iopub.execute_input":"2025-05-03T14:34:07.874131Z","iopub.status.idle":"2025-05-03T14:34:07.881667Z","shell.execute_reply.started":"2025-05-03T14:34:07.874110Z","shell.execute_reply":"2025-05-03T14:34:07.880715Z"}},"outputs":[{"name":"stdout","text":"<?xml version='1.0' encoding='utf-8'?>\n<corpus><texte id=\"0\"><titre>Ø§Ù„Ø£Ø³Ø¯ ÙˆØ§Ù„ÙØ£Ø±\n</titre><body>\nÙˆØ³Ø· ØºØ§Ø¨Ø© ÙƒØ¨ÙŠØ±Ø© ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ\nØ§Ù„Ø§Ø³Ø¯ Ù…Ù„Ùƒ Ø§Ù„ØºØ§Ø¨Ø© Ù†Ø§Ø¦Ù…Ø§ ØªØ­Øª\nØ¸Ù„ Ø´Ø¬Ø±Ø© ÙˆÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙØ£Ø±\nØµØºÙŠØ± ÙŠÙ„Ø¹Ø¨ ÙÙŠ Ø§Ù„Ø¬ÙˆØ§Ø±Ø«Ù… Ù„Ø§Ø­Ø¸\nØ£Ù† Ø§Ù„Ù…Ù„Ùƒ Ù†Ø§Ø¦Ù… Ù„Ø°Ù„Ùƒ Ù‚Ø±Ø± Ø£Ù† ÙŠÙ„Ø¹Ø¨ Ù‚Ù„ÙŠÙ„Ø§ ØµØ¹Ø¯ Ø¹Ù„Ù‰ Ø¸Ù‡Ø±Ù‡\nÙˆØ¨Ø¯Ø£ ÙŠØªØ²Ø­Ù„Ù‚ Ø¹Ø¨Ø± Ø°ÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø³ÙÙ„ Ø£Ø¹Ø§Ø¯Ù‡Ø§ Ù…Ø±Ø© ÙˆØ§Ø«Ù†ØªØ§Ù† ÙˆØ«Ù„Ø§Ø« Ø§Ø³ØªÙ…ØªØ¹ Ø§Ù„ÙØ£Ø± Ø¨Ø§Ù„Ø£Ù…Ø±ØŒ Ø§Ù†Ø²Ø¹Ø¬ Ø§Ù„Ø£Ø³Ø¯ ÙˆØ§Ø³ØªÙŠÙ‚Ø¸ Ø«Ù…\nØ£Ù…Ø³Ùƒ Ø¨Ø§Ù„ÙØ£Ø± Ø§Ù„ØµØºÙŠØ±Ø£Ø±Ø§Ø¯ Ø£ÙƒÙ„Ù‡ Ø§Ø³ØªÙˆÙ‚ÙÙ‡ Ø§Ù„ÙØ£Ø± Ø§Ù„ØµØºÙŠØ± Ø¨Ø§ÙƒÙŠØ§ ÙŠØªØ±Ø¬Ø§Ù‡ Ù„ÙƒÙŠ Ù„Ø§ÙŠÙƒÙˆÙ†\nÙˆØ¬Ø¨Ø© Ø®ÙÙŠÙØ© Ù„Ù‡ ØªØ±Ø¬Ø§Ù‡ Ø§Ù„ÙØ£Ø± ÙˆÙˆØ¹Ø¯Ù‡ Ø¨Ø£Ù† Ù„Ø§ÙŠØ²Ø¹Ø¬Ù‡ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰\nØ¨Ù„ Ù„Ø±Ø¨Ù…Ø§ ÙŠØ­ØªØ§Ø¬Ù‡ ÙÙŠ ÙˆÙ‚Øª Ù…Ù† Ø§Ù„Ø£ÙˆÙ‚Ø§Øª ØªØ£Ø«Ø± Ø§Ù„Ø£Ø³Ø¯ Ø¨Ù…Ø§ Ø³Ù…Ø¹Ù‡ Ø«Ù… ØªØ±Ùƒ Ø§Ù„ÙØ£Ø± ÙŠØ±Ø­Ù„ ÙˆØ¨Ø¹Ø¯ Ø¨Ø¶Ø¹Ø© Ø£ÙŠØ§Ù… ÙˆÙƒÙƒÙ„ ÙŠÙˆÙ…\nÙ…Ù„Ùƒ Ø§Ù„ØºØ§Ø¨Ø© ÙŠØ£Ø®Ø° Ù‚ÙŠÙ„ÙˆÙ„ØªÙ‡ Ø¥Ø° Ø¨Ø§Ù„ØµÙŠØ§Ø¯ÙŠ ÙŠÙ„Ù‚ÙŠ Ø´Ø¨ÙƒØªÙ‡ Ø¹Ù„ÙŠÙ‡ Ù„ÙŠÙ…Ø³Ùƒ Ø¨Ù‡ ÙØ¹Ù„Ø§ Ù‚Ø¯ ÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„ÙØ®\nØ¨Ø¯Ø£ Ø§Ù„Ø£Ø³Ø¯ Ø¨Ø§Ù„Ø²Ø¦ÙŠØ± Ù„ÙŠØ³Ù…Ø¹Ù‡ ÙƒÙ„ Ù…Ù† ÙÙŠ Ø§Ù„ØºØ§Ø¨Ø© Ø­ØªÙ‰ Ø§Ù„ÙØ£Ø± Ø§Ù„ØµØºÙŠØ± Ø³Ù…Ø¹ Ø²Ø¦ÙŠØ±Ù‡ Ù„ÙŠØªØ°ÙƒØ± Ø£Ù†Ù‡\nÙ…Ø¯ÙŠÙ† Ù„Ù„Ø£Ø³Ø¯ ÙˆØ¹Ù„ÙŠÙ‡ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©ÙˆØ£Ù† ÙŠØ±Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙˆÙ Ø¨Ù…Ø«Ù„Ù‡ Ù„Ù… ÙŠØªØ±Ø¯Ø¯ ØµØ¯ÙŠÙ‚Ù†Ø§\nÙˆØ°Ù‡Ø¨ Ù…Ø³Ø±Ø¹Ø§ Ù„ÙŠØ±Ù‰ Ù…Ø§Ø­ØµÙ„ ÙˆØ¹Ù†Ø¯Ù…Ø§ ÙˆØµÙ„ ÙˆØ¬Ø¯ Ø§Ù„Ø£Ø³Ø¯ ØªØ­Øª Ø§Ù„Ø´Ø¨Ø§Ùƒ\nØªØ³Ù„Ù‚Ù‡Ø§ Ø§Ù„ÙØ£Ø± ÙˆØ¨Ø¯Ø£ Ø¨ØªÙ…Ø²ÙŠÙ‚Ù‡Ø§ Ø¨Ø£Ø³Ù†Ø§Ù†Ù‡ Ø§Ù„Ø­Ø§Ø¯Ø©\nØ­ØªÙ‰ Ù…Ø²Ù‚Ù‡Ø§ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ£Ø®ÙŠØ±Ø§ Ø£Ù†Ù‚Ø° Ø§Ù„Ø£Ø³Ø¯ Ù…Ù† Ø§Ù„ÙØ® ÙˆØ±Ø¯ Ù„Ù‡ ØµÙ†ÙŠØ¹Ù‡ ÙˆÙ…Ù† Ø°Ù„Ùƒ Ø§Ù„Ø­ÙŠÙ† ÙˆØ§Ù„Ø£Ø³Ø¯ ØµØ¯ÙŠÙ‚ Ø§Ù„ÙØ£Ø±.\nÙ‡Ù†Ø§Ùƒ Ø£ØµØ¯Ù‚Ø§Ø¡ ÙŠØ¹Ø±ÙÙˆÙ† Ø¹Ù†Ø¯ Ø§Ù„Ø´Ø¯Ø§Ø¦Ø¯ ÙÙ„Ù†ØªÙ…Ø³Ùƒ Ø¨Ù‡Ù….\n</body><questions>\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimport re\n\ndef parse_custom_xml(file_path):\n    tree = ET.parse(file_path)\n    root = tree.getroot()\n\n    data = []\n    for texte in root.findall(\"texte\"):\n        raw_context = texte.find(\"body\").text or \"\"\n        context = re.sub(r'\\s+', ' ', raw_context).strip()\n        questions_block = texte.find(\"questions\").text\n\n        # Check and split questions using dash\n        if questions_block:\n            questions = [q.strip() for q in questions_block.strip().split(\"-\") if q.strip()]\n            for question in questions:\n                data.append({\"context\": context, \"question\": question})\n\n    return data\ndata = parse_custom_xml(\"/kaggle/input/arabic-text-corpus/corpus-texte-questions.xml\")\nprint(f\"Total examples extracted: {len(data)}\")\nprint(data[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T15:33:18.964276Z","iopub.execute_input":"2025-05-03T15:33:18.964865Z","iopub.status.idle":"2025-05-03T15:33:19.140137Z","shell.execute_reply.started":"2025-05-03T15:33:18.964842Z","shell.execute_reply":"2025-05-03T15:33:19.139417Z"}},"outputs":[{"name":"stdout","text":"Total examples extracted: 1506\n{'context': 'ÙÙŠ ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… ÙˆÙÙŠ Ø£Ø­Ø¯ ØºØ§Ø¨Ø§Øª Ø¥ÙØ±ÙŠÙ‚ÙŠØ§ØŒ Ø¨ÙŠÙ†Ù…Ø§ ÙƒØ§Ù† Ø£Ø­Ø¯ Ø§Ù„ÙÙ‡ÙˆØ¯ ÙŠØªØ¬ÙˆÙ„ Ù‚Ø±Ø¨ Ø¶ÙØ© Ø§Ù„Ù†Ù‡Ø± Ø¨Ø§Ø­Ø«Ø§ Ø¹Ù† ÙØ±ÙŠØ³Ø© ÙŠØ³Ø¯ Ø¨Ù‡Ø§ Ø±Ù…Ù‚Ù‡ØŒ Ù„Ù…Ø­ Ù‚Ø·ÙŠØ¹Ø§ Ù…Ù† Ø§Ù„ØºØ²Ù„Ø§Ù† ÙŠØ±Ø¹Ù‰ Ø§Ù„Ø¹Ø´Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¶ÙØ© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©. ÙÙ‚Ø§Ù„ ÙÙŠ Ù†ÙØ³Ù‡ ÙˆÙ‡Ùˆ ÙŠÙ†Ø¸Ø± Ø¥Ù„ÙŠÙ‡Ø§: \"Ù„ÙŠØªÙ†ÙŠ Ø£Ø¹Ø±Ù Ø§Ù„Ø³Ø¨Ø§Ø­Ø©ØŒ ÙØ£Ø¹Ø¨Ø± Ø§Ù„Ù†Ù‡Ø± ÙˆØ£ÙØªØ±Ø³ ØºØ²Ø§Ù„Ø§ Ø£Ù…Ù„Ø¦ Ø¨Ù‡ Ù…Ø¹Ø¯ØªÙŠ Ø§Ù„Ø®Ø§ÙˆÙŠØ©.\" Ø§Ù„ØªÙØª Ø§Ù„ÙÙ‡Ø¯ ÙŠÙ…Ù†Ø©Ù‹ ÙˆÙŠØ³Ø±Ø©Ù‹ Ø¨Ø§Ø­Ø«Ø§Ù‹ Ø¹Ù† Ø´ÙŠØ¡ ÙŠÙ…ÙƒÙ†Ù‘Ù‡ Ù…Ù† Ø§Ù„Ø¹Ø¨ÙˆØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¶ÙÙ‘Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©ØŒ ÙˆÙ„ÙƒÙ† Ø¯ÙˆÙ† Ø¬Ø¯ÙˆÙ‰ . Ø«Ù… Ù†Ø¸Ø± ÙˆØ³Ø· Ø§Ù„Ù†Ù‡Ø± ÙØ±Ø£Ù‰ ÙØ±Ø³ Ù†Ù‡Ø± ÙŠØ³Ø¨Ø­ ÙÙŠ Ø§Ù„Ù…Ø§Ø¡ ÙˆÙŠØ£ÙƒÙ„ Ù…Ù† Ø§Ù„Ø£Ø¹Ø´Ø§Ø¨ Ø§Ù„ØªÙŠ Ù†Ù…Øª ÙÙŠ Ù‚Ø§Ø¹Ù‡. ÙÙƒØ± Ø§Ù„ÙÙ‡Ø¯ Ù‚Ù„ÙŠÙ„Ø§ Ø«Ù… ØªÙˆØ¬Ù‡ Ø¥Ù„Ù‰ Ø¶ÙØ© Ø§Ù„Ù†Ù‡Ø± ÙˆØ®Ø§Ø·Ø¨ Ø§Ù„ÙØ±Ø³ Ù‚Ø§Ø¦Ù„Ø§: \" Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒ ÙŠØ§ Ø§Ø¨Ù† Ø¹Ù…ÙŠ \" ÙØ£Ø¬Ø§Ø¨ ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙˆÙ‚Ø¯ Ø¨Ø¯Øª Ø¹Ù„ÙŠÙ‡ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¹Ø¬Ø¨: \"ÙˆØ¹Ù„ÙŠÙƒ Ø§Ù„Ø³Ù„Ø§Ù…. ÙƒÙŠÙ ØªÙƒÙˆÙ† Ø§Ø¨Ù† Ø¹Ù…ÙŠ ÙˆØ£Ù†Øª Ù„Ø³Øª Ù…Ù† ÙØµÙŠÙ„ØªÙŠØŸ ÙØ£Ù†Øª ØªÙ…Ù„Ùƒ Ø¬Ø³Ù…Ø§ Ø±Ø´ÙŠÙ‚Ø§ ÙˆÙ…Ø±Ù‚Ø·Ø§ Ø¨ÙŠÙ†Ù…Ø§ Ø¬Ø³Ù…ÙŠ Ù…Ù…ØªÙ„Ø¦ ÙˆØ®Ø§Ù„ Ù…Ù† Ø§Ù„Ø¨Ù‚Ø¹\" ÙØ£Ø¬Ø§Ø¨ Ø§Ù„ÙÙ‡Ø¯ ÙÙŠ Ø®Ø¨Ø«: \" Ø£Ù†Ø§ Ù…Ù† Ø¨Ù„Ø¯ Ø¨Ø¹ÙŠØ¯ Ø­ÙŠØ« ØªÙƒÙˆÙ† Ø£ÙØ±Ø§Ø³ Ø§Ù„Ù†Ù‡Ø± Ù…Ø±Ù‚Ø·Ø© ÙˆÙ†Ø­ÙŠÙ„Ø©.\" ØªØ¸Ø§Ù‡Ø± ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± Ø¨ØªØµØ¯ÙŠÙ‚ ÙƒÙ„Ø§Ù… Ø§Ù„ÙÙ‡Ø¯ Ø«Ù… Ù‚Ø§Ù„: \"Ø­Ø³Ù† ÙŠØ§ Ø§Ø¨Ù† Ø¹Ù…ÙŠ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø®Ø¯Ù…ØªÙƒØŸ\" ÙÙ‚Ø§Ù„ Ø§Ù„ÙÙ‡Ø¯: \"Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø³Ø§Ø¹Ø¯ØªÙŠ ÙˆÙ†Ù‚Ù„ÙŠ Ø¹Ù„Ù‰ Ø¸Ù‡Ø±Ùƒ Ø§Ù„Ù‰ Ø§Ù„Ø¶ÙØ© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‡Ø±ØŸ\" ÙÙƒØ± ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± Ù‚Ù„ÙŠÙ„Ø§ Ø«Ù… ÙˆØ§ÙÙ‚ ÙˆØ­Ù…Ù„ Ø§Ù„ÙÙ‡Ø¯ Ø¹Ù„Ù‰ Ø¶Ù‡Ø±Ù‡ Ù„ÙŠØ¹Ø¨Ø± Ø¨Ù‡ Ø§Ù„Ù†Ù‡Ø±. ÙˆÙÙŠ Ù…Ù†ØªØµÙ Ø§Ù„Ø·Ø±ÙŠÙ‚ ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„Ø³Ø¨Ø§Ø­Ø© Ø«Ù… Ù‚Ø§Ù„: \"Ø¨Ù…Ø§ Ø£Ù†Ùƒ ÙØ±Ø³ Ù†Ù‡Ø± ÙØ¨Ø¥Ù…ÙƒØ§Ù†Ùƒ Ø§Ù„Ø³Ø¨Ø§Ø­Ø© ÙˆØ§Ù„ØºØ·Ø³ Ù…Ø«Ù„ÙŠ. Ø£Ù„ÙŠØ³ ÙƒØ°Ù„ÙƒØŸ\" ÙØ£Ø¬Ø§Ø¨ Ø§Ù„ÙÙ‡Ø¯ Ù…Ø±ØªØ¨ÙƒØ§ : \"Ø¥Ù… Ù… Ù… ... Ø¨Ø§Ù„Ø·Ø¨Ø¹ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø³Ø¨Ø§Ø­Ø©.\" ÙˆØ¨ÙŠÙ†Ù…Ø§ ÙƒØ§Ù† Ø§Ù„ÙÙ‡Ø¯ ÙŠÙ‡Ù…Ù‡Ù… ÙˆÙŠØ¨Ø­Ø« ÙÙŠ Ø±Ø£Ø³Ù‡ Ø¹Ù† ÙƒÙ„Ø§Ù… Ù…Ù‚Ù†Ø¹ØŒ Ø§Ø° Ø¨ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙŠØºØ·Ø³ Ø¨Ù‡ Ø§Ù„Ù‰ Ø§Ø¹Ù…Ø§Ù‚ Ø§Ù„Ù†Ù‡Ø±. ÙÙƒØ§Ù†Øª ØªÙ„Ùƒ Ø§Ù„ØºØ·Ø³Ø© Ø¯Ø±Ø³Ø§ Ù‚Ø§Ø³ÙŠØ§ Ù„Ù„ÙÙ‡Ø¯ Ø§Ù„Ø°ÙŠ Ù†Ø¬Ø§ Ø¨Ø£Ø¹Ø¬ÙˆØ¨Ø© Ù…Ù† Ø§Ù„ØºØ±Ù‚. ÙˆÙ‡ÙƒØ°Ø§ Ù†Ø§Ù„ Ø§Ù„ÙÙ‡Ø¯ Ø§Ù„Ø®Ø¨ÙŠØ« Ø¬Ø²Ø§Ø¡ Ø®Ø¯Ø§Ø¹Ù‡ Ù„ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙˆØ§Ø³ØªØ®ÙØ§ÙÙ‡ Ø¨Ø°ÙƒØ§Ø¦Ù‡.', 'question': 'Ù‡Ù„ Ø§Ù†Ø®Ø¯Ø¹ ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± Ø¨ÙƒØ°Ø¨Ø© Ø§Ù„ÙÙ‡Ø¯ØŸ'}\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"# Idea: Segmenting the context into phrases ","metadata":{}},{"cell_type":"code","source":"import re\n\ndef split_into_phrases(context):\n    # Split on common Arabic sentence-ending punctuation\n    phrases = re.split(r'[ØŸ.!ØŸ]', context)\n    # Remove empty and strip whitespace\n    phrases = [phrase.strip() for phrase in phrases if phrase.strip()]\n    return phrases\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T16:06:48.106074Z","iopub.execute_input":"2025-05-03T16:06:48.106362Z","iopub.status.idle":"2025-05-03T16:06:48.110696Z","shell.execute_reply.started":"2025-05-03T16:06:48.106341Z","shell.execute_reply":"2025-05-03T16:06:48.110092Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"context = data[10]['context']\n\nphrases = split_into_phrases(context)\nprint(phrases)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T16:07:27.866707Z","iopub.execute_input":"2025-05-03T16:07:27.867542Z","iopub.status.idle":"2025-05-03T16:07:27.872318Z","shell.execute_reply.started":"2025-05-03T16:07:27.867508Z","shell.execute_reply":"2025-05-03T16:07:27.871598Z"}},"outputs":[{"name":"stdout","text":"['ÙÙŠ ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… ÙˆÙÙŠ Ø£Ø­Ø¯ ØºØ§Ø¨Ø§Øª Ø¥ÙØ±ÙŠÙ‚ÙŠØ§ØŒ Ø¨ÙŠÙ†Ù…Ø§ ÙƒØ§Ù† Ø£Ø­Ø¯ Ø§Ù„ÙÙ‡ÙˆØ¯ ÙŠØªØ¬ÙˆÙ„ Ù‚Ø±Ø¨ Ø¶ÙØ© Ø§Ù„Ù†Ù‡Ø± Ø¨Ø§Ø­Ø«Ø§ Ø¹Ù† ÙØ±ÙŠØ³Ø© ÙŠØ³Ø¯ Ø¨Ù‡Ø§ Ø±Ù…Ù‚Ù‡ØŒ Ù„Ù…Ø­ Ù‚Ø·ÙŠØ¹Ø§ Ù…Ù† Ø§Ù„ØºØ²Ù„Ø§Ù† ÙŠØ±Ø¹Ù‰ Ø§Ù„Ø¹Ø´Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¶ÙØ© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©', 'ÙÙ‚Ø§Ù„ ÙÙŠ Ù†ÙØ³Ù‡ ÙˆÙ‡Ùˆ ÙŠÙ†Ø¸Ø± Ø¥Ù„ÙŠÙ‡Ø§: \"Ù„ÙŠØªÙ†ÙŠ Ø£Ø¹Ø±Ù Ø§Ù„Ø³Ø¨Ø§Ø­Ø©ØŒ ÙØ£Ø¹Ø¨Ø± Ø§Ù„Ù†Ù‡Ø± ÙˆØ£ÙØªØ±Ø³ ØºØ²Ø§Ù„Ø§ Ø£Ù…Ù„Ø¦ Ø¨Ù‡ Ù…Ø¹Ø¯ØªÙŠ Ø§Ù„Ø®Ø§ÙˆÙŠØ©', '\" Ø§Ù„ØªÙØª Ø§Ù„ÙÙ‡Ø¯ ÙŠÙ…Ù†Ø©Ù‹ ÙˆÙŠØ³Ø±Ø©Ù‹ Ø¨Ø§Ø­Ø«Ø§Ù‹ Ø¹Ù† Ø´ÙŠØ¡ ÙŠÙ…ÙƒÙ†Ù‘Ù‡ Ù…Ù† Ø§Ù„Ø¹Ø¨ÙˆØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¶ÙÙ‘Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©ØŒ ÙˆÙ„ÙƒÙ† Ø¯ÙˆÙ† Ø¬Ø¯ÙˆÙ‰', 'Ø«Ù… Ù†Ø¸Ø± ÙˆØ³Ø· Ø§Ù„Ù†Ù‡Ø± ÙØ±Ø£Ù‰ ÙØ±Ø³ Ù†Ù‡Ø± ÙŠØ³Ø¨Ø­ ÙÙŠ Ø§Ù„Ù…Ø§Ø¡ ÙˆÙŠØ£ÙƒÙ„ Ù…Ù† Ø§Ù„Ø£Ø¹Ø´Ø§Ø¨ Ø§Ù„ØªÙŠ Ù†Ù…Øª ÙÙŠ Ù‚Ø§Ø¹Ù‡', 'ÙÙƒØ± Ø§Ù„ÙÙ‡Ø¯ Ù‚Ù„ÙŠÙ„Ø§ Ø«Ù… ØªÙˆØ¬Ù‡ Ø¥Ù„Ù‰ Ø¶ÙØ© Ø§Ù„Ù†Ù‡Ø± ÙˆØ®Ø§Ø·Ø¨ Ø§Ù„ÙØ±Ø³ Ù‚Ø§Ø¦Ù„Ø§: \" Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒ ÙŠØ§ Ø§Ø¨Ù† Ø¹Ù…ÙŠ \" ÙØ£Ø¬Ø§Ø¨ ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙˆÙ‚Ø¯ Ø¨Ø¯Øª Ø¹Ù„ÙŠÙ‡ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¹Ø¬Ø¨: \"ÙˆØ¹Ù„ÙŠÙƒ Ø§Ù„Ø³Ù„Ø§Ù…', 'ÙƒÙŠÙ ØªÙƒÙˆÙ† Ø§Ø¨Ù† Ø¹Ù…ÙŠ ÙˆØ£Ù†Øª Ù„Ø³Øª Ù…Ù† ÙØµÙŠÙ„ØªÙŠ', 'ÙØ£Ù†Øª ØªÙ…Ù„Ùƒ Ø¬Ø³Ù…Ø§ Ø±Ø´ÙŠÙ‚Ø§ ÙˆÙ…Ø±Ù‚Ø·Ø§ Ø¨ÙŠÙ†Ù…Ø§ Ø¬Ø³Ù…ÙŠ Ù…Ù…ØªÙ„Ø¦ ÙˆØ®Ø§Ù„ Ù…Ù† Ø§Ù„Ø¨Ù‚Ø¹\" ÙØ£Ø¬Ø§Ø¨ Ø§Ù„ÙÙ‡Ø¯ ÙÙŠ Ø®Ø¨Ø«: \" Ø£Ù†Ø§ Ù…Ù† Ø¨Ù„Ø¯ Ø¨Ø¹ÙŠØ¯ Ø­ÙŠØ« ØªÙƒÙˆÙ† Ø£ÙØ±Ø§Ø³ Ø§Ù„Ù†Ù‡Ø± Ù…Ø±Ù‚Ø·Ø© ÙˆÙ†Ø­ÙŠÙ„Ø©', '\" ØªØ¸Ø§Ù‡Ø± ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± Ø¨ØªØµØ¯ÙŠÙ‚ ÙƒÙ„Ø§Ù… Ø§Ù„ÙÙ‡Ø¯ Ø«Ù… Ù‚Ø§Ù„: \"Ø­Ø³Ù† ÙŠØ§ Ø§Ø¨Ù† Ø¹Ù…ÙŠ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø®Ø¯Ù…ØªÙƒ', '\" ÙÙ‚Ø§Ù„ Ø§Ù„ÙÙ‡Ø¯: \"Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø³Ø§Ø¹Ø¯ØªÙŠ ÙˆÙ†Ù‚Ù„ÙŠ Ø¹Ù„Ù‰ Ø¸Ù‡Ø±Ùƒ Ø§Ù„Ù‰ Ø§Ù„Ø¶ÙØ© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‡Ø±', '\" ÙÙƒØ± ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± Ù‚Ù„ÙŠÙ„Ø§ Ø«Ù… ÙˆØ§ÙÙ‚ ÙˆØ­Ù…Ù„ Ø§Ù„ÙÙ‡Ø¯ Ø¹Ù„Ù‰ Ø¶Ù‡Ø±Ù‡ Ù„ÙŠØ¹Ø¨Ø± Ø¨Ù‡ Ø§Ù„Ù†Ù‡Ø±', 'ÙˆÙÙŠ Ù…Ù†ØªØµÙ Ø§Ù„Ø·Ø±ÙŠÙ‚ ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„Ø³Ø¨Ø§Ø­Ø© Ø«Ù… Ù‚Ø§Ù„: \"Ø¨Ù…Ø§ Ø£Ù†Ùƒ ÙØ±Ø³ Ù†Ù‡Ø± ÙØ¨Ø¥Ù…ÙƒØ§Ù†Ùƒ Ø§Ù„Ø³Ø¨Ø§Ø­Ø© ÙˆØ§Ù„ØºØ·Ø³ Ù…Ø«Ù„ÙŠ', 'Ø£Ù„ÙŠØ³ ÙƒØ°Ù„Ùƒ', '\" ÙØ£Ø¬Ø§Ø¨ Ø§Ù„ÙÙ‡Ø¯ Ù…Ø±ØªØ¨ÙƒØ§ : \"Ø¥Ù… Ù… Ù…', 'Ø¨Ø§Ù„Ø·Ø¨Ø¹ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø³Ø¨Ø§Ø­Ø©', '\" ÙˆØ¨ÙŠÙ†Ù…Ø§ ÙƒØ§Ù† Ø§Ù„ÙÙ‡Ø¯ ÙŠÙ‡Ù…Ù‡Ù… ÙˆÙŠØ¨Ø­Ø« ÙÙŠ Ø±Ø£Ø³Ù‡ Ø¹Ù† ÙƒÙ„Ø§Ù… Ù…Ù‚Ù†Ø¹ØŒ Ø§Ø° Ø¨ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙŠØºØ·Ø³ Ø¨Ù‡ Ø§Ù„Ù‰ Ø§Ø¹Ù…Ø§Ù‚ Ø§Ù„Ù†Ù‡Ø±', 'ÙÙƒØ§Ù†Øª ØªÙ„Ùƒ Ø§Ù„ØºØ·Ø³Ø© Ø¯Ø±Ø³Ø§ Ù‚Ø§Ø³ÙŠØ§ Ù„Ù„ÙÙ‡Ø¯ Ø§Ù„Ø°ÙŠ Ù†Ø¬Ø§ Ø¨Ø£Ø¹Ø¬ÙˆØ¨Ø© Ù…Ù† Ø§Ù„ØºØ±Ù‚', 'ÙˆÙ‡ÙƒØ°Ø§ Ù†Ø§Ù„ Ø§Ù„ÙÙ‡Ø¯ Ø§Ù„Ø®Ø¨ÙŠØ« Ø¬Ø²Ø§Ø¡ Ø®Ø¯Ø§Ø¹Ù‡ Ù„ÙØ±Ø³ Ø§Ù„Ù†Ù‡Ø± ÙˆØ§Ø³ØªØ®ÙØ§ÙÙ‡ Ø¨Ø°ÙƒØ§Ø¦Ù‡']\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"print(phrases[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:14:20.456189Z","iopub.execute_input":"2025-05-03T17:14:20.456717Z","iopub.status.idle":"2025-05-03T17:14:20.460603Z","shell.execute_reply.started":"2025-05-03T17:14:20.456692Z","shell.execute_reply":"2025-05-03T17:14:20.459788Z"}},"outputs":[{"name":"stdout","text":"ÙÙŠ ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… ÙˆÙÙŠ Ø£Ø­Ø¯ ØºØ§Ø¨Ø§Øª Ø¥ÙØ±ÙŠÙ‚ÙŠØ§ØŒ Ø¨ÙŠÙ†Ù…Ø§ ÙƒØ§Ù† Ø£Ø­Ø¯ Ø§Ù„ÙÙ‡ÙˆØ¯ ÙŠØªØ¬ÙˆÙ„ Ù‚Ø±Ø¨ Ø¶ÙØ© Ø§Ù„Ù†Ù‡Ø± Ø¨Ø§Ø­Ø«Ø§ Ø¹Ù† ÙØ±ÙŠØ³Ø© ÙŠØ³Ø¯ Ø¨Ù‡Ø§ Ø±Ù…Ù‚Ù‡ØŒ Ù„Ù…Ø­ Ù‚Ø·ÙŠØ¹Ø§ Ù…Ù† Ø§Ù„ØºØ²Ù„Ø§Ù† ÙŠØ±Ø¹Ù‰ Ø§Ù„Ø¹Ø´Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¶ÙØ© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}